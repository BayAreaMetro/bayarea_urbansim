{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bay Area UrbanSim (BAUS) Introduction Bay Area UrbanSim (BAUS) is a land use or urban economic model used to forecast metropolitan growth, study urban policies, and evaluate transportation projects at the Metropolitan Transportation Commission (MTC). It is written in Python and is a customized version of the popular UrbanSim model developed by Professor Paul Waddell over the last few decades. BAUS simulates the movement of households and employees within the region, and the construction of new buildings to hold those households and employees. In this manner, it is used to incrementally forecast potential future urban growth trajectories. Contents [Model Overview]()","title":"Home"},{"location":"#bay-area-urbansim-baus","text":"","title":"Bay Area UrbanSim (BAUS)"},{"location":"#introduction","text":"Bay Area UrbanSim (BAUS) is a land use or urban economic model used to forecast metropolitan growth, study urban policies, and evaluate transportation projects at the Metropolitan Transportation Commission (MTC). It is written in Python and is a customized version of the popular UrbanSim model developed by Professor Paul Waddell over the last few decades. BAUS simulates the movement of households and employees within the region, and the construction of new buildings to hold those households and employees. In this manner, it is used to incrementally forecast potential future urban growth trajectories.","title":"Introduction"},{"location":"#contents","text":"[Model Overview]()","title":"Contents"},{"location":"input/","text":"Inputs Regional Forecast The regional forecast contains infromation on the region\u2019s overall growth trajectory. These tables contain only one value per variable per forecast for the entire region. They are generated by the REMI model and various scripts. The first two tables are standard for all UrbanSim applications, while the third contains a variety of data that is combined with other information using scripts within BAUS in order to produce required inputs to the Travel Model: regional_controls.csv These are regional level controls which give us employed residents and the age distribution, which are used to provide inputs to the travel model which UrabanSim is not natively simulating at this time. employment_controls.csv The total number of jobs forecast to exist in the Bay Area in each forecast year. This means BAUS will ensure that its forecast conforms to these numbers. The values area counts of jobs. The values are segmented into each 5-year intervals (2010 to 2050) and into six sectors. household_controls.csv The total number of households forecast to live in the Bay Area in each forecast year. This means BAUS will ensure that its forecast conforms to these numbers. The values area counts of households. The values are segmented into 5-year intervals (2010 to 2050) and into four categories of approximate household income quartiles. county_forecat_inputs.csv county_employmnet_forecast.csv baseyear_taz_controls.csv Zonal Forecasts zone_forecast_inputs.csv This is closely related to regional_controls.csv. Both are only used in the summary step to create output variables used by the travel model which are not endogenously created in UrbanSim. These are zone level inputs for that process, the other file contains regional-level controls. taz_growth_rates_gov_ed.csv Ratios of gov't and education employment per population (sometimes at the TAZ level, sometimes for each county, and sometimes regionally). This csv actually has two header rows - this first row is what the outcome attribute is, and the second is the geography at which the ratio acts (taz / county / regional). baseyear_taz_controls.csv This contains our expected base year control totals by taz - number of units, vacancy rates, employment by sector (but not households). employment_relocation_rates.csv Relocation rates by sector by zone so we can e.g. leave City Hall populated by civic sector jobs. Base Year Data [moving to BASIS] Parcels, Buildings, Households, Jobs bayarea_v3.h5 Base year database of: households, jobs, buildings, and parcels. These are pre-processed. costar.csv Commercial data for nores hedonic estimation parcels_geography.csv Lookup toble from parcel's geom_id to ids for juris, growth geographies,, exp (expansion area), opp_id (catalyst site), and a concatenation of these used to join to the zoning_mod tables below. Also has perfoot, perfarea, and urbanized. development_projects.csv This is the list of projects that have happened since the base data, or that we think will happen in the future. It is the development pipeline. This file tends to have more attributes than we actually use in UrbanSim. deed_restricted_zone_totals.csv This is the number of deed restricted units per taz. We don't have a great idea of exactly where those units are, but we have an aggregate idea, so we usually do a random assignment within that taz. Existing Planned Land Use zoning_parcels.csv Lookup table from parcel's geom_id to zoning_id, some zoning area info and a nodev flag which seems to be all zeros. zoning_lookup.csv The zoning lookup is the current, baselin zoning for each jurisdiction, and can be assigned to parcels. The lookup is identified by the unique id (\"id\" column), has the city name, city id, and the name of the zoning.The active attributes are max_dua, max_far, and max_height, all of which must be respected by each development, so this means the most constraining constraint has the power. dua is \"Dwelling Units per Acre\", far is \"Floor Area Ratio\" (ratio of square footage in building to square footage on parcel), and height is height. In some cases there is an equivlance between dua and far if they are not both present. This is tricky, and requires knowing things like average unit sizes, as well as net to gross factors for the unit square footage. We make our best guesses on this, but this logic can be configured. There also must be an equivalance between far and height, which generally is made by taking far and multiplying is by a net to gross building footprint factor (e.g. a calculation to figure out the height of a building with FAR 4.0, when the footprint of the building takes up 80% or so of the parcel, when stories are all 12 feet, and where partial stories count as full stories in terms of height). As you are thinking at this point, we are bad building architects, but we're making rough approximations here in order to allocate built space in the region and this feels like the appropriate level of detail. The other columns are building types, and the values are 0 or 1 to indicate whether the type is allowed on this parcel. For instance, HS is single family, HT is townhome (attached), and HM is multi-family (apartments / condos) and so forth. R for retail, OF is office, and M is mixed. Max_du_per_parcel is not currently used because we don't necessarily trust our data, but in theory is used to say, e.g., that only a single unit can be built on each parcel. Note that a blank value in the csv means that there is no constraint for that attribute and the other constraints will be used. If there is no constraint for any of far, height, and dua, a building will NOT be built. By convention a 0 in dua, far, and height is discouraged. It is preferred to use the \"building type not allowed\" columns for this. Lookup tables parcel_to_taz1454sub.csv Lookup table from parcel's parcel_id to parcel_to_maz22.csv Lookup table from parcel's geom_id or parcel_id to maz. census_id_to_name.csv For some reason the current parcels_geography file uses census id instead of name. This is the file that maps those ids to names so we can use it within UrbanSim. taz_geography.csv Mapping of tazs to superdistricts and counties (by id). Plan strategies zoning_mods.csv These are the files which contain scenario-based zoning. They are typically used to upzone dua and far in pdas. Parcels are joined to this file using the field \"zoningmodcat\" which are \"policy zones\" which are the cross product of jurisdiction, tpp, expansion zone, and opportunity site areas. \"dua_up\" and \"far_up\" are used to do the upzoning (these can never result in a downzoning), and building types can also be added. vmt_fee_zonecats.csv These are the res/non-res fee categories, which actually identify the low and high VMT zones (technically there are 4 categories). The VMT zones get mapped to fees in settings.yaml. Adjusters juris_assumptions.csv These are simulation assumptions that apply per jurisdiction. Currently, the only attribute used is \"minimum_forecast_retail_jobs_per_household\" which is used to keep local serving retail appropriate for each jurisdiction. juris_controls.csv This is the revised set of household numbers which we needed to match late in the planning process. A few small cities correctly alerted us to the fact that our TAZ data had the wrong population in some cases (in a few cases the census was even petitioned to be changed). manual_edits.csv A csv of manual edits so we don't have to create a new H5 every time we want to edit a single parcel or building. Simply give the table name, attribute name, and new value, and BAUS will override current data using edits form this file. superdistricts.csv These are superdistrict attributes, including name, subregion (the superdistricts are aggregated even further), and sqft_per_job which varies by superdistrict and is used to create an appropriate vacancy rate. additional_units.csv Additional units is a way to hard code the addition of units by city in order to force capacity. It's a similar model to the \"refiner\" models common for UrbanSim praxis, but doesn't actually affect household/job totals, just the supply side. household_building_id_overrides.csv This is used to move households around to match new city household totals. When we have a new assignment process and a new assignment this file should go away (we needed to update household locations for a small number of households very late in the planning process). abag_targets.csv These are the households and jobs expected per pda and non-pda jurisdiction as agreed upon using ABAG's local knowledge. We use this to compare against UrbanSim output. tpp_id_2016.csv This is a mapping of parcel ids to new tpp_ids, which are used for analyzing output. This can go away when we have a new parcels_geography file with new tpps. rhna_by_juris.csv These are the RHNA numbers by jurisdiction for the time period between 2014 and 2022. Accessibility Files landmarks.csv The lat-lng locations of a few major landmarks in the region, which are avialable for use in the modeling. logsums.csv This is the set of baseyear logsums from the MTC travel model. This is available for use in the modeling and is a key compoenent of the integrated modeling effort. regional_poi_distances.csv These are the distances from each travel model node to each landmark. It's precomputed and stored in this file because it never changes. It could be recomputed every time, with the only cost being performance. tmnet.h5 For use with pandana osm_bayarea4326.h5 Street network bart_stations.csv This is a list of BART stations and their locations so that distance to BART can be used in the modeling.","title":"Input"},{"location":"input/#inputs","text":"","title":"Inputs"},{"location":"input/#regional-forecast","text":"The regional forecast contains infromation on the region\u2019s overall growth trajectory. These tables contain only one value per variable per forecast for the entire region. They are generated by the REMI model and various scripts. The first two tables are standard for all UrbanSim applications, while the third contains a variety of data that is combined with other information using scripts within BAUS in order to produce required inputs to the Travel Model: regional_controls.csv These are regional level controls which give us employed residents and the age distribution, which are used to provide inputs to the travel model which UrabanSim is not natively simulating at this time. employment_controls.csv The total number of jobs forecast to exist in the Bay Area in each forecast year. This means BAUS will ensure that its forecast conforms to these numbers. The values area counts of jobs. The values are segmented into each 5-year intervals (2010 to 2050) and into six sectors. household_controls.csv The total number of households forecast to live in the Bay Area in each forecast year. This means BAUS will ensure that its forecast conforms to these numbers. The values area counts of households. The values are segmented into 5-year intervals (2010 to 2050) and into four categories of approximate household income quartiles. county_forecat_inputs.csv county_employmnet_forecast.csv baseyear_taz_controls.csv","title":"Regional Forecast"},{"location":"input/#zonal-forecasts","text":"zone_forecast_inputs.csv This is closely related to regional_controls.csv. Both are only used in the summary step to create output variables used by the travel model which are not endogenously created in UrbanSim. These are zone level inputs for that process, the other file contains regional-level controls. taz_growth_rates_gov_ed.csv Ratios of gov't and education employment per population (sometimes at the TAZ level, sometimes for each county, and sometimes regionally). This csv actually has two header rows - this first row is what the outcome attribute is, and the second is the geography at which the ratio acts (taz / county / regional). baseyear_taz_controls.csv This contains our expected base year control totals by taz - number of units, vacancy rates, employment by sector (but not households). employment_relocation_rates.csv Relocation rates by sector by zone so we can e.g. leave City Hall populated by civic sector jobs.","title":"Zonal Forecasts"},{"location":"input/#base-year-data-moving-to-basis","text":"","title":"Base Year Data [moving to BASIS]"},{"location":"input/#parcels-buildings-households-jobs","text":"bayarea_v3.h5 Base year database of: households, jobs, buildings, and parcels. These are pre-processed. costar.csv Commercial data for nores hedonic estimation parcels_geography.csv Lookup toble from parcel's geom_id to ids for juris, growth geographies,, exp (expansion area), opp_id (catalyst site), and a concatenation of these used to join to the zoning_mod tables below. Also has perfoot, perfarea, and urbanized. development_projects.csv This is the list of projects that have happened since the base data, or that we think will happen in the future. It is the development pipeline. This file tends to have more attributes than we actually use in UrbanSim. deed_restricted_zone_totals.csv This is the number of deed restricted units per taz. We don't have a great idea of exactly where those units are, but we have an aggregate idea, so we usually do a random assignment within that taz.","title":"Parcels, Buildings, Households, Jobs"},{"location":"input/#existing-planned-land-use","text":"zoning_parcels.csv Lookup table from parcel's geom_id to zoning_id, some zoning area info and a nodev flag which seems to be all zeros. zoning_lookup.csv The zoning lookup is the current, baselin zoning for each jurisdiction, and can be assigned to parcels. The lookup is identified by the unique id (\"id\" column), has the city name, city id, and the name of the zoning.The active attributes are max_dua, max_far, and max_height, all of which must be respected by each development, so this means the most constraining constraint has the power. dua is \"Dwelling Units per Acre\", far is \"Floor Area Ratio\" (ratio of square footage in building to square footage on parcel), and height is height. In some cases there is an equivlance between dua and far if they are not both present. This is tricky, and requires knowing things like average unit sizes, as well as net to gross factors for the unit square footage. We make our best guesses on this, but this logic can be configured. There also must be an equivalance between far and height, which generally is made by taking far and multiplying is by a net to gross building footprint factor (e.g. a calculation to figure out the height of a building with FAR 4.0, when the footprint of the building takes up 80% or so of the parcel, when stories are all 12 feet, and where partial stories count as full stories in terms of height). As you are thinking at this point, we are bad building architects, but we're making rough approximations here in order to allocate built space in the region and this feels like the appropriate level of detail. The other columns are building types, and the values are 0 or 1 to indicate whether the type is allowed on this parcel. For instance, HS is single family, HT is townhome (attached), and HM is multi-family (apartments / condos) and so forth. R for retail, OF is office, and M is mixed. Max_du_per_parcel is not currently used because we don't necessarily trust our data, but in theory is used to say, e.g., that only a single unit can be built on each parcel. Note that a blank value in the csv means that there is no constraint for that attribute and the other constraints will be used. If there is no constraint for any of far, height, and dua, a building will NOT be built. By convention a 0 in dua, far, and height is discouraged. It is preferred to use the \"building type not allowed\" columns for this.","title":"Existing Planned Land Use"},{"location":"input/#lookup-tables","text":"parcel_to_taz1454sub.csv Lookup table from parcel's parcel_id to parcel_to_maz22.csv Lookup table from parcel's geom_id or parcel_id to maz. census_id_to_name.csv For some reason the current parcels_geography file uses census id instead of name. This is the file that maps those ids to names so we can use it within UrbanSim. taz_geography.csv Mapping of tazs to superdistricts and counties (by id).","title":"Lookup tables"},{"location":"input/#plan-strategies","text":"zoning_mods.csv These are the files which contain scenario-based zoning. They are typically used to upzone dua and far in pdas. Parcels are joined to this file using the field \"zoningmodcat\" which are \"policy zones\" which are the cross product of jurisdiction, tpp, expansion zone, and opportunity site areas. \"dua_up\" and \"far_up\" are used to do the upzoning (these can never result in a downzoning), and building types can also be added. vmt_fee_zonecats.csv These are the res/non-res fee categories, which actually identify the low and high VMT zones (technically there are 4 categories). The VMT zones get mapped to fees in settings.yaml.","title":"Plan strategies"},{"location":"input/#adjusters","text":"juris_assumptions.csv These are simulation assumptions that apply per jurisdiction. Currently, the only attribute used is \"minimum_forecast_retail_jobs_per_household\" which is used to keep local serving retail appropriate for each jurisdiction. juris_controls.csv This is the revised set of household numbers which we needed to match late in the planning process. A few small cities correctly alerted us to the fact that our TAZ data had the wrong population in some cases (in a few cases the census was even petitioned to be changed). manual_edits.csv A csv of manual edits so we don't have to create a new H5 every time we want to edit a single parcel or building. Simply give the table name, attribute name, and new value, and BAUS will override current data using edits form this file. superdistricts.csv These are superdistrict attributes, including name, subregion (the superdistricts are aggregated even further), and sqft_per_job which varies by superdistrict and is used to create an appropriate vacancy rate. additional_units.csv Additional units is a way to hard code the addition of units by city in order to force capacity. It's a similar model to the \"refiner\" models common for UrbanSim praxis, but doesn't actually affect household/job totals, just the supply side. household_building_id_overrides.csv This is used to move households around to match new city household totals. When we have a new assignment process and a new assignment this file should go away (we needed to update household locations for a small number of households very late in the planning process). abag_targets.csv These are the households and jobs expected per pda and non-pda jurisdiction as agreed upon using ABAG's local knowledge. We use this to compare against UrbanSim output. tpp_id_2016.csv This is a mapping of parcel ids to new tpp_ids, which are used for analyzing output. This can go away when we have a new parcels_geography file with new tpps. rhna_by_juris.csv These are the RHNA numbers by jurisdiction for the time period between 2014 and 2022.","title":"Adjusters"},{"location":"input/#accessibility-files","text":"landmarks.csv The lat-lng locations of a few major landmarks in the region, which are avialable for use in the modeling. logsums.csv This is the set of baseyear logsums from the MTC travel model. This is available for use in the modeling and is a key compoenent of the integrated modeling effort. regional_poi_distances.csv These are the distances from each travel model node to each landmark. It's precomputed and stored in this file because it never changes. It could be recomputed every time, with the only cost being performance. tmnet.h5 For use with pandana osm_bayarea4326.h5 Street network bart_stations.csv This is a list of BART stations and their locations so that distance to BART can be used in the modeling.","title":"Accessibility Files"},{"location":"model_overview/","text":"Model Overview Approach A forecast with BAUS begins with a basemap. This is a detailed geodatabase containing all of the region\u2019s buildings, households, employees, policies, and transport network for a recent year. This roughly corresponds to tooday\u2019s conditions but is a few years in the past due to data collection lag and formalities related to the modeling framework. The buildings are largely an accurate collection of every structure gathered from assessor\u2019s data, commercial read estate databases, and other sources. The households and employees are represented at the micro level but their characteristics are built through synthesis (i.e., we only have samples of this informations so we build a full representation that is consistent with these samples). Policies such as zoning and growth limits are collected for each jurisdiction and are binding unless they are explicitly changed for a forecast. BAUS is used to forecast the future by advancing through repeated steps that chart out a potential pathway for future urban growth. In BAUS each step represents a five year period. Most steps repeat the same set of sub-steps. In UrbanSim, each of these sub-steps is called a \u201cmodel\u201d. The file used to run BAUS (baus.py) sets the number steps and the order in which the models are are run. The major types of model steps are: (Hazards): This optional model simulates the impact of earthquakes and sea level rise by destroying buildings and displacing their inhabitants. Calculate accessibility: Logsum accessibility measures are brought in from the Travel Model and pedestrian accessibility is calculated within UrbanSim Calculate housing prices and rents: Hedonic regression models are applied to current (to the model time step) conditions to reestimate current prices and rents HH/employee relcation and transition: Some households and employeees are selected to move; additiional households and employees are added or subtracted to reflect the exogenous control totals Add buildings from the Development Projects list: Buildings are forced into the model (as opposed to being explicitly modeled); these represent institutional plans (e.g., universities and hospitals), large approved projects (e.g., Treasure Island), and development that has occurred between the basemap year and the current year (i.e., constructed 2016-2020). Build new market-rate housing units and commercial space: The for-profit real estate development process is simulated and new buildings are built where they are most feasible; this also build deed-restricted unit that are produced through the market-rate process (e.g., inclusionary zoning). Build new deed-restricted affordable units: A similar not-for-profit real estate development process produces affordable housing units based on money available within BAUS Accounts (e.g., bond measures). HH/employee location choices: Households and employees are assigned to new locations based on logistic regresssion models that capture the preferences of particular segments (e.g., lower income households, retail jobs). Produce summary tables: Numerous zonal summaries of the detailed geodatabaase are produced for analysis of urban change and for use in the Travel Model; this step includes additional post-processing to get the data ready for the Travel Model\u2019s population synthesizer. Sub-Models Typically, a set of BAUS inputs or assumptions are modified to produce a scenario. Policies such as zoning or fees can be modified. Control totals can be adjusted. Assumptions about preferences or financical situations can be adjusted. The package of changes is then simulated to forecast its impact on the future urban landscape and these outcomes are often enterered into the travel model to predict future year travel patterns and greenhouse gas emmissions. Application Types BAUS is used for for three typical types of application: Forecasting: UrbanSim produces a complete map for each five year interval into the future. This information is required by statute and useful for planning processes. Policy Studies: BAUS can evaluate the impact of policy changes on, for example, the amount of housing produced, the amount of deed-restricted housing producded, and the locations of future residential or commercial development. Transport Project Evaluation: BAUS provides information on future land use patterns used to evaluate the benefits and costs of large transport infrastructure investments and allows an assessment of how such projects may influence future development. Model System BAUS is the middle model in an interactive suite of three model systems maintained by MTC: Regional economic and demographic information is supplied to BAUS from the REMI CGE model and related demographic processing scripts. BAUS outputs on housing production are used to adjust regional housing prices (and thus other variables) in REMI. Accessibillity information is supplied to BAUS from the Travel Model and influences real estate prices and household and employee location choices. BAUS outputs on the location of various types of households and employees are used to establish origins and destinations in the Travel Model.","title":"Model Overview"},{"location":"model_overview/#model-overview","text":"","title":"Model Overview"},{"location":"model_overview/#approach","text":"A forecast with BAUS begins with a basemap. This is a detailed geodatabase containing all of the region\u2019s buildings, households, employees, policies, and transport network for a recent year. This roughly corresponds to tooday\u2019s conditions but is a few years in the past due to data collection lag and formalities related to the modeling framework. The buildings are largely an accurate collection of every structure gathered from assessor\u2019s data, commercial read estate databases, and other sources. The households and employees are represented at the micro level but their characteristics are built through synthesis (i.e., we only have samples of this informations so we build a full representation that is consistent with these samples). Policies such as zoning and growth limits are collected for each jurisdiction and are binding unless they are explicitly changed for a forecast. BAUS is used to forecast the future by advancing through repeated steps that chart out a potential pathway for future urban growth. In BAUS each step represents a five year period. Most steps repeat the same set of sub-steps. In UrbanSim, each of these sub-steps is called a \u201cmodel\u201d. The file used to run BAUS (baus.py) sets the number steps and the order in which the models are are run. The major types of model steps are: (Hazards): This optional model simulates the impact of earthquakes and sea level rise by destroying buildings and displacing their inhabitants. Calculate accessibility: Logsum accessibility measures are brought in from the Travel Model and pedestrian accessibility is calculated within UrbanSim Calculate housing prices and rents: Hedonic regression models are applied to current (to the model time step) conditions to reestimate current prices and rents HH/employee relcation and transition: Some households and employeees are selected to move; additiional households and employees are added or subtracted to reflect the exogenous control totals Add buildings from the Development Projects list: Buildings are forced into the model (as opposed to being explicitly modeled); these represent institutional plans (e.g., universities and hospitals), large approved projects (e.g., Treasure Island), and development that has occurred between the basemap year and the current year (i.e., constructed 2016-2020). Build new market-rate housing units and commercial space: The for-profit real estate development process is simulated and new buildings are built where they are most feasible; this also build deed-restricted unit that are produced through the market-rate process (e.g., inclusionary zoning). Build new deed-restricted affordable units: A similar not-for-profit real estate development process produces affordable housing units based on money available within BAUS Accounts (e.g., bond measures). HH/employee location choices: Households and employees are assigned to new locations based on logistic regresssion models that capture the preferences of particular segments (e.g., lower income households, retail jobs). Produce summary tables: Numerous zonal summaries of the detailed geodatabaase are produced for analysis of urban change and for use in the Travel Model; this step includes additional post-processing to get the data ready for the Travel Model\u2019s population synthesizer.","title":"Approach"},{"location":"model_overview/#sub-models","text":"Typically, a set of BAUS inputs or assumptions are modified to produce a scenario. Policies such as zoning or fees can be modified. Control totals can be adjusted. Assumptions about preferences or financical situations can be adjusted. The package of changes is then simulated to forecast its impact on the future urban landscape and these outcomes are often enterered into the travel model to predict future year travel patterns and greenhouse gas emmissions.","title":"Sub-Models"},{"location":"model_overview/#application-types","text":"BAUS is used for for three typical types of application: Forecasting: UrbanSim produces a complete map for each five year interval into the future. This information is required by statute and useful for planning processes. Policy Studies: BAUS can evaluate the impact of policy changes on, for example, the amount of housing produced, the amount of deed-restricted housing producded, and the locations of future residential or commercial development. Transport Project Evaluation: BAUS provides information on future land use patterns used to evaluate the benefits and costs of large transport infrastructure investments and allows an assessment of how such projects may influence future development.","title":"Application Types"},{"location":"model_overview/#model-system","text":"BAUS is the middle model in an interactive suite of three model systems maintained by MTC: Regional economic and demographic information is supplied to BAUS from the REMI CGE model and related demographic processing scripts. BAUS outputs on housing production are used to adjust regional housing prices (and thus other variables) in REMI. Accessibillity information is supplied to BAUS from the Travel Model and influences real estate prices and household and employee location choices. BAUS outputs on the location of various types of households and employees are used to establish origins and destinations in the Travel Model.","title":"Model System"},{"location":"models-reference/","text":"Models module baus.models elcm_simulate ( jobs , buildings , aggregations ) testing docstring documentation for automated documentation creation Source code in baus\\models.py 23 24 25 26 27 28 29 30 31 32 @orca . step () def elcm_simulate ( jobs , buildings , aggregations ): \"\"\" testing docstring documentation for automated documentation creation \"\"\" buildings . local [ \"non_residential_rent\" ] = \\ buildings . local . non_residential_rent . fillna ( 0 ) return utils . lcm_simulate ( \"elcm.yaml\" , jobs , buildings , aggregations , \"building_id\" , \"job_spaces\" , \"vacant_job_spaces\" , cast = True )","title":"models"},{"location":"models-reference/#models-module","text":"","title":"Models module"},{"location":"models-reference/#baus.models","text":"","title":"models"},{"location":"models-reference/#baus.models.elcm_simulate","text":"testing docstring documentation for automated documentation creation Source code in baus\\models.py 23 24 25 26 27 28 29 30 31 32 @orca . step () def elcm_simulate ( jobs , buildings , aggregations ): \"\"\" testing docstring documentation for automated documentation creation \"\"\" buildings . local [ \"non_residential_rent\" ] = \\ buildings . local . non_residential_rent . fillna ( 0 ) return utils . lcm_simulate ( \"elcm.yaml\" , jobs , buildings , aggregations , \"building_id\" , \"job_spaces\" , \"vacant_job_spaces\" , cast = True )","title":"elcm_simulate()"},{"location":"output/","text":"Outputs Core Outputs TBD Policy Outputs TBD For Travel Model","title":"Output"},{"location":"output/#outputs","text":"","title":"Outputs"},{"location":"output/#core-outputs","text":"TBD","title":"Core Outputs"},{"location":"output/#policy-outputs","text":"TBD","title":"Policy Outputs"},{"location":"output/#for-travel-model","text":"","title":"For Travel Model"},{"location":"pba50/","text":"Plan Bay Area 2050 Background: Plan Bay Area 2050 project website Scenarios S21: Blueprint Basic This is the \"base\" scenario in the sense that we are doing it first and the others build off of it Uses s21 control total files Uses Blueprint Basic logsums Uses s21 zoning modifications: major upzoning in all growth geogs Has almost all strategies in s20: Baseline for PBA50 This is the \"baseline\" scenario in the sense that it doesn't have any pba50 changes and so it also has far lower control totals Uses s20 control total files (these are minus the additional units built bc of housing policy in pba50) Uses Baseline logsums (somewhat less congestion than others?) Uses s20 zoning modifications: these are minimal in that the do typical No Project treatment (UGB, upzoning within) but may also need UGB expansion to fit control totals Has no new strategies from PBA50 s22: Blueprint Plus Fix It First This is the higher funding scenario Uses s22 control total files Uses Blueprint Plus Fix It First logsums (very similar to s21 logsums) Uses s22 zoning modifications: same as s21 Adds/modifies these strategies (working off of s210: adds incubator strategy increases size of affordable housing fund more slr protection s23: Blueprint Plus Crossing This is the higher funding scenario plus the New Transbay Crossing Uses s23 control total files Uses Blueprint Plus Crossing logsums (moderately different from other scenarios) Uses s23 zoning modifications: slightly higher upzoning than s21 and s22 at a few new/upgraded stations Same strategies as s22 s24: Final Blueprint Builds off of s23 Includes both error correction and policy modifications Strategy Coding Technical Notes Deed-Restricted Units notes Deed-restricted units can now come from many sources. As of Final Blueprint, those sources are: DR = base year DR + pipeline DR + public lands (added via pipeline) + subsidized (production) + preserved + inclusionary Pipeline units cannot be redeveloped, other deed-restricted units can if or when the building is more than 20 years old. In the household location choice models, only Q1 households can enter DR units. However, if the model can't find enough Q1 households for the DR units (due to modeling reasons or over-supply) non-Q1 households are able to enter. Affordable Housing Fund- Preservation (Final Blueprint) Selects buildings to spend preservation funding on, by marking them as deed restricted units. The selection is not tied to price, and housing cost is calculated off model. The buildings are randomly selected based on the total number of buildings to preserve within a geography which are set here . The \"deed restricted\" column is updated in the residential units table, which is used to filter units in the household location choice models and assign Q1 households to deed restricted units. The \"deed restricted units\" and \"preserved units\" columns are updated in the buildings table. These occur here . In some cases, a Q1 household will already occupy a newly preserved unit. If that household moves, only another Q1 will be able to move in. In other cases, a non-Q1 household will occupy a newly preserved unit, and a Q1 household is only able to enter if and when that household moves out. Inclusionary Zoning (Draft Blueprint, Final Blueprint) Inclusionary zoning requirement (x% of new housing development have to be affordable) is set in policy.yalm . The default setting represents the existing requirements without plan strategy interventions. Plan strategies are organized by scenario, with a scenario handler at the top. Inclusionary rate is set at certain geographic level: PBA40 and Horizon: inclusionary percentage by jurisdiction . Draft Blueprint: inclusionary percentage by pba50chcat (i.e. the combination of several growth geography strategies, GG, TRA, PPA, etc.). Final Blueprint: inclusionary percentage by fbpchcat . Coding notes: datasources.py reads inclusionary strategy input and maps it to parcels using the corresponding field: PBA40 and Horizon uses 'jurisdiction' , Draft Blueprint uses 'pba50chcat' , Final Blueprint uses 'fbpchcat'. In subsidies.py , the inclusionary_housing_revenue_reduction function calculates median household AMI , feasible new affordable housing count and revenue_reduction amount of each inclusionary geography. In PBA40 and Horizon, these calculations were conducted at the jurisdiction level. PBA50 uses strategy geographies instead - 'pba50chcat' in Draft Blueprint and 'fbpchcat' in Final Blueprint. The inclusionary statements in summaries.py should be consistent with the inclusionary geography of each plan scenario. Reduce cost for housing development (Draft Blueprint, Final Blueprint) One way to (indirectly) subsidize housing is to reduce housing development cost reduction, for example, SB743 CEQA reform, lowering parking requirements, etc. This is defined in profitability_adjustment_policies . The policies are scenario-based, as noted by \"enable_in_scenarios\". For each policy, profitabiity_adjustment_formula picks the parcels in a certain category (e.g. a certain type of geography) and then decreases the required profitability level needed for the model to build on those parcels, e.g. multiplying by 2.5% or 0.025 means to LOWER the required profit level by 2.5%. When a policy has an alternative version is different scenarios, may use 'alternative_geography_scenarios' and 'alternative_adjustment_formula' to consolidate the scenarios. \"Summaries.py\" summaries these policies. Affordable Housing Fund Lump-sum Account (Draft Blueprint, Final Blueprint) Lump-sum accounts represent direct housing subsidies. Each county has a lump-sum account to hold all the available affordable housing funding for that county. BAUS assumes a constant annual funding amount (an independent input) , for each county during the plan period, doesn't consider inflation or fluctuations in funding availability over time. In each simulation iteration, funding available in each county's account equals the annual amount multiplies by years per iteration (5 years in BAUS) . Residential development projects that are not feasible under market conditions are potentially qualified for subsidy. Final Blueprint requires the projects to be also located within the Growth Geography. A qualified project draws money from the corresponding account to fill the feasibility gap. Not all qualified projects will be subsidized. Lum-sum accounts are scenario-based , having scenario-specific fund amount and project qualification criteria. Coding notes: Set up the account in policy.yaml Calculate each account's subsidy amount for each iteration and add it to coffer Set up the filter in run_subsidized_developer() Update the config in 'summaries.py' Check subsidized_residential_developer_lump_sum_accts() and make sure it is included in the model list in baus.py VMT Fees / Transportation Impact Fees (Draft Blueprint) Apply fees on new commercial or residential development that reflects transportation impacts associated with such development, focusing primarily on new commercial spaces or residential units anticipated to have high employment-related or residence-related vehicle miles traveled (VMT). The fees could be set at county, jurisdiction, or TAZ level, usually on a $/sqft basis for commercial development and $/unit basis for residential development. Draft Blueprint applies VMT on new office development based on the county and associated VMT per worker associated with the TAZ to incentivize development inside low-VMT job centers. This diagram illustrates the modeling steps in BAUS: BAUS has three types of VMT fees - \"com_for_res\" (apply fees on commercial development to subsidize residential development), \"res_for_res\" (apply fees on residential development to subsidize residential development), and \"com_for_com\" (apply fees on commercial development to subsidize commercial development). Each parcel is assigned a \"vmt_res_cat\" value and a \"vmt_nonres_cat\" value based on its categorized VMT-level. This is then mapped to the fee table to decide the fee amount for new residential and commercial development on the parcel. During each model iteration period (currently five years), VMT fees collected from new development go into one of the two accounts - \"vmt_res_acct\" and \"vmt_com_acct\" - for each geography (regional or sub-regional). Policies that aim to support/incentivize certain types of housing development or commercial activities can draw funding from respective account. In Draft Blueprint , VMT fees revenue is not applied into any job/housing incentive, but is accumulated to help to understand how much revenue is raised to support other economy strategies. Jobs-housing Balance Fee (Draft Blueprint) Apply a regional jobs-housing linkage fee to generate funding for affordable housing when new office development occurs in job-rich places, thereby incentivizing more jobs to locate in housing-rich places. The $/sqft fee assigned to each jurisdiction is a composite fee based on the jobs-housing ratio and jobs-housing fit for both cities and counties. Modeling jobs-housing fee in BAUS: Jobs-housing fee is tracked in BAUS under the \"jobs_housing_com_for_res\" account at the county level , which is similar to the \"com_for_res\" account of the VMT strategy. In each model interation period, jobs-housing fees applies to new office development in each county based on the $/sqft level of jurisdiction where the development occurs. The fees collected goes to each county's account. The account then acts similarly to the county-level lump-sum account to subsidize affordable housing in that county. Office Lump Sum Account (Final Blueprint) Similar to the residential funding lump sum account, office lump sum account provides funding to subsidize office development in targeted areas.","title":"PBA50"},{"location":"pba50/#plan-bay-area-2050","text":"Background: Plan Bay Area 2050 project website","title":"Plan Bay Area 2050"},{"location":"pba50/#scenarios","text":"","title":"Scenarios"},{"location":"pba50/#s21-blueprint-basic","text":"This is the \"base\" scenario in the sense that we are doing it first and the others build off of it Uses s21 control total files Uses Blueprint Basic logsums Uses s21 zoning modifications: major upzoning in all growth geogs Has almost all strategies in","title":"S21: Blueprint Basic"},{"location":"pba50/#s20-baseline-for-pba50","text":"This is the \"baseline\" scenario in the sense that it doesn't have any pba50 changes and so it also has far lower control totals Uses s20 control total files (these are minus the additional units built bc of housing policy in pba50) Uses Baseline logsums (somewhat less congestion than others?) Uses s20 zoning modifications: these are minimal in that the do typical No Project treatment (UGB, upzoning within) but may also need UGB expansion to fit control totals Has no new strategies from PBA50","title":"s20: Baseline for PBA50"},{"location":"pba50/#s22-blueprint-plus-fix-it-first","text":"This is the higher funding scenario Uses s22 control total files Uses Blueprint Plus Fix It First logsums (very similar to s21 logsums) Uses s22 zoning modifications: same as s21 Adds/modifies these strategies (working off of s210: adds incubator strategy increases size of affordable housing fund more slr protection","title":"s22: Blueprint Plus Fix It First"},{"location":"pba50/#s23-blueprint-plus-crossing","text":"This is the higher funding scenario plus the New Transbay Crossing Uses s23 control total files Uses Blueprint Plus Crossing logsums (moderately different from other scenarios) Uses s23 zoning modifications: slightly higher upzoning than s21 and s22 at a few new/upgraded stations Same strategies as s22","title":"s23: Blueprint Plus Crossing"},{"location":"pba50/#s24-final-blueprint","text":"Builds off of s23 Includes both error correction and policy modifications","title":"s24: Final Blueprint"},{"location":"pba50/#strategy-coding-technical-notes","text":"","title":"Strategy Coding Technical Notes"},{"location":"pba50/#deed-restricted-units-notes","text":"Deed-restricted units can now come from many sources. As of Final Blueprint, those sources are: DR = base year DR + pipeline DR + public lands (added via pipeline) + subsidized (production) + preserved + inclusionary Pipeline units cannot be redeveloped, other deed-restricted units can if or when the building is more than 20 years old. In the household location choice models, only Q1 households can enter DR units. However, if the model can't find enough Q1 households for the DR units (due to modeling reasons or over-supply) non-Q1 households are able to enter.","title":"Deed-Restricted Units notes"},{"location":"pba50/#affordable-housing-fund-preservation-final-blueprint","text":"Selects buildings to spend preservation funding on, by marking them as deed restricted units. The selection is not tied to price, and housing cost is calculated off model. The buildings are randomly selected based on the total number of buildings to preserve within a geography which are set here . The \"deed restricted\" column is updated in the residential units table, which is used to filter units in the household location choice models and assign Q1 households to deed restricted units. The \"deed restricted units\" and \"preserved units\" columns are updated in the buildings table. These occur here . In some cases, a Q1 household will already occupy a newly preserved unit. If that household moves, only another Q1 will be able to move in. In other cases, a non-Q1 household will occupy a newly preserved unit, and a Q1 household is only able to enter if and when that household moves out.","title":"Affordable Housing Fund- Preservation (Final Blueprint)"},{"location":"pba50/#inclusionary-zoning-draft-blueprint-final-blueprint","text":"Inclusionary zoning requirement (x% of new housing development have to be affordable) is set in policy.yalm . The default setting represents the existing requirements without plan strategy interventions. Plan strategies are organized by scenario, with a scenario handler at the top. Inclusionary rate is set at certain geographic level: PBA40 and Horizon: inclusionary percentage by jurisdiction . Draft Blueprint: inclusionary percentage by pba50chcat (i.e. the combination of several growth geography strategies, GG, TRA, PPA, etc.). Final Blueprint: inclusionary percentage by fbpchcat . Coding notes: datasources.py reads inclusionary strategy input and maps it to parcels using the corresponding field: PBA40 and Horizon uses 'jurisdiction' , Draft Blueprint uses 'pba50chcat' , Final Blueprint uses 'fbpchcat'. In subsidies.py , the inclusionary_housing_revenue_reduction function calculates median household AMI , feasible new affordable housing count and revenue_reduction amount of each inclusionary geography. In PBA40 and Horizon, these calculations were conducted at the jurisdiction level. PBA50 uses strategy geographies instead - 'pba50chcat' in Draft Blueprint and 'fbpchcat' in Final Blueprint. The inclusionary statements in summaries.py should be consistent with the inclusionary geography of each plan scenario.","title":"Inclusionary Zoning (Draft Blueprint, Final Blueprint)"},{"location":"pba50/#reduce-cost-for-housing-development-draft-blueprint-final-blueprint","text":"One way to (indirectly) subsidize housing is to reduce housing development cost reduction, for example, SB743 CEQA reform, lowering parking requirements, etc. This is defined in profitability_adjustment_policies . The policies are scenario-based, as noted by \"enable_in_scenarios\". For each policy, profitabiity_adjustment_formula picks the parcels in a certain category (e.g. a certain type of geography) and then decreases the required profitability level needed for the model to build on those parcels, e.g. multiplying by 2.5% or 0.025 means to LOWER the required profit level by 2.5%. When a policy has an alternative version is different scenarios, may use 'alternative_geography_scenarios' and 'alternative_adjustment_formula' to consolidate the scenarios. \"Summaries.py\" summaries these policies.","title":"Reduce cost for housing development (Draft Blueprint, Final Blueprint)"},{"location":"pba50/#affordable-housing-fund-lump-sum-account-draft-blueprint-final-blueprint","text":"Lump-sum accounts represent direct housing subsidies. Each county has a lump-sum account to hold all the available affordable housing funding for that county. BAUS assumes a constant annual funding amount (an independent input) , for each county during the plan period, doesn't consider inflation or fluctuations in funding availability over time. In each simulation iteration, funding available in each county's account equals the annual amount multiplies by years per iteration (5 years in BAUS) . Residential development projects that are not feasible under market conditions are potentially qualified for subsidy. Final Blueprint requires the projects to be also located within the Growth Geography. A qualified project draws money from the corresponding account to fill the feasibility gap. Not all qualified projects will be subsidized. Lum-sum accounts are scenario-based , having scenario-specific fund amount and project qualification criteria. Coding notes: Set up the account in policy.yaml Calculate each account's subsidy amount for each iteration and add it to coffer Set up the filter in run_subsidized_developer() Update the config in 'summaries.py' Check subsidized_residential_developer_lump_sum_accts() and make sure it is included in the model list in baus.py","title":"Affordable Housing Fund Lump-sum Account (Draft Blueprint, Final Blueprint)"},{"location":"pba50/#vmt-fees-transportation-impact-fees-draft-blueprint","text":"Apply fees on new commercial or residential development that reflects transportation impacts associated with such development, focusing primarily on new commercial spaces or residential units anticipated to have high employment-related or residence-related vehicle miles traveled (VMT). The fees could be set at county, jurisdiction, or TAZ level, usually on a $/sqft basis for commercial development and $/unit basis for residential development. Draft Blueprint applies VMT on new office development based on the county and associated VMT per worker associated with the TAZ to incentivize development inside low-VMT job centers. This diagram illustrates the modeling steps in BAUS: BAUS has three types of VMT fees - \"com_for_res\" (apply fees on commercial development to subsidize residential development), \"res_for_res\" (apply fees on residential development to subsidize residential development), and \"com_for_com\" (apply fees on commercial development to subsidize commercial development). Each parcel is assigned a \"vmt_res_cat\" value and a \"vmt_nonres_cat\" value based on its categorized VMT-level. This is then mapped to the fee table to decide the fee amount for new residential and commercial development on the parcel. During each model iteration period (currently five years), VMT fees collected from new development go into one of the two accounts - \"vmt_res_acct\" and \"vmt_com_acct\" - for each geography (regional or sub-regional). Policies that aim to support/incentivize certain types of housing development or commercial activities can draw funding from respective account. In Draft Blueprint , VMT fees revenue is not applied into any job/housing incentive, but is accumulated to help to understand how much revenue is raised to support other economy strategies.","title":"VMT Fees / Transportation Impact Fees (Draft Blueprint)"},{"location":"pba50/#jobs-housing-balance-fee-draft-blueprint","text":"Apply a regional jobs-housing linkage fee to generate funding for affordable housing when new office development occurs in job-rich places, thereby incentivizing more jobs to locate in housing-rich places. The $/sqft fee assigned to each jurisdiction is a composite fee based on the jobs-housing ratio and jobs-housing fit for both cities and counties. Modeling jobs-housing fee in BAUS: Jobs-housing fee is tracked in BAUS under the \"jobs_housing_com_for_res\" account at the county level , which is similar to the \"com_for_res\" account of the VMT strategy. In each model interation period, jobs-housing fees applies to new office development in each county based on the $/sqft level of jurisdiction where the development occurs. The fees collected goes to each county's account. The account then acts similarly to the county-level lump-sum account to subsidize affordable housing in that county.","title":"Jobs-housing Balance Fee (Draft Blueprint)"},{"location":"pba50/#office-lump-sum-account-final-blueprint","text":"Similar to the residential funding lump sum account, office lump sum account provides funding to subsidize office development in targeted areas.","title":"Office Lump Sum Account (Final Blueprint)"},{"location":"subsidies-reference/","text":"Subsidies module baus.subsidies run_subsidized_developer ( feasibility , parcels , buildings , households , acct_settings , settings , account , year , form_to_btype_func , add_extra_columns_func , summary , create_deed_restricted = False , policy_name = 'Unnamed' ) The subsidized residential developer model. Parameters DataFrame A DataFrame that is returned from run_feasibility for a given form DataFrameWrapper The standard parcels DataFrameWrapper (mostly just for run_developer) DataFrameWrapper The standard buildings DataFrameWrapper (passed to run_developer) DataFrameWrapper The households DataFrameWrapper (passed to run_developer) Dict A dictionary of settings to parameterize the model. Needs these keys: sending_buildings_subaccount_def - maps buildings to subaccounts receiving_buildings_filter - filter for eligible buildings Dict The overall settings Account The Account object to use for subsidization int The current simulation year (will be added as metadata) function Passed through to run_developer function Passed through to run_developer Summary Used to add parcel summary information bool Bool for whether to create deed restricted units with the subsidies or not. The logic at the time of this writing is to keep track of partial units so that when partial units sum to greater than a unit, that unit will be deed restricted. Returns Nothing Subsidized residential developer is designed to run before the normal residential developer - it will prioritize the developments we're subsidizing (although this is not strictly required - running this model after the market rate developer will just create a temporarily larger supply of units, which will probably create less market rate development in the next simulated year). The steps for subsidizing are essentially these: 1 run feasibility with only_built set to false so that the feasibility of unprofitable units are recorded 2 temporarily filter to ONLY unprofitable units to check for possible subsidized units (normal developer takes care of market-rate units) 3 compute the number of units in these developments 4 divide cost by number of units in order to get the subsidy per unit 5 filter developments to parcels in \"receiving zone\" similar to the way we identified \"sending zones\" 6 iterate through subaccounts one at a time as subsidy will be limited to available funds in the subaccount (usually by jurisdiction) 7 sort ascending by subsidy per unit so that we minimize subsidy (but total subsidy is equivalent to total building cost) 8 cumsum the total subsidy in the buildings and locate the development where the subsidy is less than or equal to the amount in the account - filter to only those buildings (these will likely be built) 9 pass the results as \"feasible\" to run_developer - this is sort of a boundary case of developer but should run OK 10 for those developments that get built, make sure to subtract from account and keep a record (on the off chance that demand is less than the subsidized units, run through the standard code path, although it's very unlikely that there would be more subsidized housing than demand) Source code in baus\\subsidies.py 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 def run_subsidized_developer ( feasibility , parcels , buildings , households , acct_settings , settings , account , year , form_to_btype_func , add_extra_columns_func , summary , create_deed_restricted = False , policy_name = \"Unnamed\" ): \"\"\" The subsidized residential developer model. Parameters ---------- feasibility : DataFrame A DataFrame that is returned from run_feasibility for a given form parcels : DataFrameWrapper The standard parcels DataFrameWrapper (mostly just for run_developer) buildings : DataFrameWrapper The standard buildings DataFrameWrapper (passed to run_developer) households : DataFrameWrapper The households DataFrameWrapper (passed to run_developer) acct_settings : Dict A dictionary of settings to parameterize the model. Needs these keys: sending_buildings_subaccount_def - maps buildings to subaccounts receiving_buildings_filter - filter for eligible buildings settings : Dict The overall settings account : Account The Account object to use for subsidization year : int The current simulation year (will be added as metadata) form_to_btype_func : function Passed through to run_developer add_extra_columns_func : function Passed through to run_developer summary : Summary Used to add parcel summary information create_deed_restricted : bool Bool for whether to create deed restricted units with the subsidies or not. The logic at the time of this writing is to keep track of partial units so that when partial units sum to greater than a unit, that unit will be deed restricted. Returns ------- Nothing Subsidized residential developer is designed to run before the normal residential developer - it will prioritize the developments we're subsidizing (although this is not strictly required - running this model after the market rate developer will just create a temporarily larger supply of units, which will probably create less market rate development in the next simulated year). The steps for subsidizing are essentially these: 1 run feasibility with only_built set to false so that the feasibility of unprofitable units are recorded 2 temporarily filter to ONLY unprofitable units to check for possible subsidized units (normal developer takes care of market-rate units) 3 compute the number of units in these developments 4 divide cost by number of units in order to get the subsidy per unit 5 filter developments to parcels in \"receiving zone\" similar to the way we identified \"sending zones\" 6 iterate through subaccounts one at a time as subsidy will be limited to available funds in the subaccount (usually by jurisdiction) 7 sort ascending by subsidy per unit so that we minimize subsidy (but total subsidy is equivalent to total building cost) 8 cumsum the total subsidy in the buildings and locate the development where the subsidy is less than or equal to the amount in the account - filter to only those buildings (these will likely be built) 9 pass the results as \"feasible\" to run_developer - this is sort of a boundary case of developer but should run OK 10 for those developments that get built, make sure to subtract from account and keep a record (on the off chance that demand is less than the subsidized units, run through the standard code path, although it's very unlikely that there would be more subsidized housing than demand) \"\"\" # step 2 feasibility = feasibility . replace ([ np . inf , - np . inf ], np . nan ) feasibility = feasibility [ feasibility . max_profit < 0 ] # step 3 feasibility [ 'ave_sqft_per_unit' ] = parcels . ave_sqft_per_unit feasibility [ 'residential_units' ] = np . floor ( feasibility . residential_sqft / feasibility . ave_sqft_per_unit ) # step 3B # can only add units - don't subtract units - this is an approximation # of the calculation that will be used to do this in the developer model feasibility = feasibility [ feasibility . residential_units > feasibility . total_residential_units ] # step 3C # towards the end, because we're about to sort by subsidy per unit, some # large projects never get built, because it could be a 100 unit project # times a 500k subsidy per unit. thus we're going to try filtering by # the maximum subsidy for a single development here feasibility = feasibility [ feasibility . max_profit > - 50 * 1000000 ] # step 4 feasibility [ 'subsidy_per_unit' ] = - 1 * feasibility [ 'max_profit' ] / feasibility [ 'residential_units' ] # assumption that even if the developer says this property is almost # profitable, even the administration costs are likely to cost at least # 10k / unit feasibility [ 'subsidy_per_unit' ] = feasibility . subsidy_per_unit . clip ( 10000 ) # step 5 if \"receiving_buildings_filter\" in acct_settings : feasibility = feasibility . query ( acct_settings [ \"receiving_buildings_filter\" ]) else : # otherwise all buildings are valid pass new_buildings_list = [] sending_bldgs = acct_settings [ \"sending_buildings_subaccount_def\" ] feasibility [ \"regional\" ] = 1 feasibility [ \"subaccount\" ] = feasibility . eval ( sending_bldgs ) # step 6 for subacct , amount in account . iter_subaccounts (): print ( \"Subaccount: \" , subacct ) df = feasibility [ feasibility . subaccount == subacct ] print ( \"Number of feasible projects in receiving zone:\" , len ( df )) if len ( df ) == 0 : continue # step 7 df = df . sort_values ([ 'subsidy_per_unit' ], ascending = True ) # df.to_csv('subsidized_units_%d_%s_%s.csv' % (orca.get_injectable(\"year\"), account.name, subacct)) # step 8 print ( \"Amount in subaccount: $ {:,.2f} \" . format ( amount )) num_bldgs = int (( - 1 * df . max_profit ) . cumsum () . searchsorted ( amount )) if num_bldgs == 0 : continue # technically we only build these buildings if there's demand # print \"Building {:d} subsidized buildings\".format(num_bldgs) df = df . iloc [: int ( num_bldgs )] df . columns = pd . MultiIndex . from_tuples ( [( \"residential\" , col ) for col in df . columns ]) # disable stdout since developer is a bit verbose for this use case sys . stdout , old_stdout = StringIO (), sys . stdout kwargs = settings [ 'residential_developer' ] # step 9 new_buildings = utils . run_developer ( \"residential\" , households , buildings , \"residential_units\" , parcels . parcel_size , parcels . ave_sqft_per_unit , parcels . total_residential_units , orca . DataFrameWrapper ( \"feasibility\" , df ), year = year , form_to_btype_callback = form_to_btype_func , add_more_columns_callback = add_extra_columns_func , profit_to_prob_func = profit_to_prob_func , ** kwargs ) sys . stdout = old_stdout buildings = orca . get_table ( \"buildings\" ) if new_buildings is None : continue # keep track of partial subsidized untis so that we always get credit # for a partial unit, even if it's not built in this specific building partial_subsidized_units = 0 # step 10 for index , new_building in new_buildings . iterrows (): amt = new_building . max_profit metadata = { \"description\" : \"Developing subsidized building\" , \"year\" : year , \"residential_units\" : new_building . residential_units , \"inclusionary_units\" : new_building . inclusionary_units , \"building_id\" : index } if create_deed_restricted : revenue_per_unit = new_building . building_revenue / new_building . residential_units total_subsidy = abs ( new_building . max_profit ) subsidized_units = total_subsidy / revenue_per_unit + partial_subsidized_units # right now there are inclusionary requirements already_subsidized_units = new_building . deed_restricted_units # get remainder partial_subsidized_units = subsidized_units % 1 # round off for now subsidized_units = int ( subsidized_units ) + already_subsidized_units # cap at number of residential units subsidized_units = min ( subsidized_units , new_building . residential_units ) buildings . local . loc [ index , \"deed_restricted_units\" ] = int ( round ( subsidized_units )) buildings . local . loc [ index , \"subsidized_units\" ] = buildings . local . loc [ index , \"deed_restricted_units\" ] - \\ buildings . local . loc [ index , \"inclusionary_units\" ] # also correct the debug output new_buildings . loc [ index , \"deed_restricted_units\" ] = int ( round ( subsidized_units )) new_buildings . loc [ index , \"subsidized_units\" ] = new_buildings . loc [ index , \"deed_restricted_units\" ] - \\ new_buildings . loc [ index , \"inclusionary_units\" ] metadata [ 'deed_restricted_units' ] = new_buildings . loc [ index , 'deed_restricted_units' ] metadata [ 'subsidized_units' ] = new_buildings . loc [ index , 'subsidized_units' ] account . add_transaction ( amt , subaccount = subacct , metadata = metadata ) # turn off this assertion for the Draft Blueprint affordable housing policy since the number of deed restricted units # vs units from development projects looks reasonable # assert np.all(buildings.local.deed_restricted_units.fillna(0) <= # buildings.local.residential_units.fillna(0)) print ( \"Amount left after subsidy: $ {:,.2f} \" . format ( account . total_transactions_by_subacct ( subacct ))) new_buildings_list . append ( new_buildings ) total_len = reduce ( lambda x , y : x + len ( y ), new_buildings_list , 0 ) if total_len == 0 : print ( \"No subsidized buildings\" ) return new_buildings = pd . concat ( new_buildings_list ) print ( \"Built {} total subsidized buildings\" . format ( len ( new_buildings ))) print ( \" Total subsidy: $ {:,.2f} \" . format ( - 1 * new_buildings . max_profit . sum ())) print ( \" Total subsidized units: {:.0f} \" . format ( new_buildings . residential_units . sum ())) new_buildings [ \"subsidized\" ] = True new_buildings [ \"policy_name\" ] = policy_name summary . add_parcel_output ( new_buildings )","title":"subsidies"},{"location":"subsidies-reference/#subsidies-module","text":"","title":"Subsidies module"},{"location":"subsidies-reference/#baus.subsidies","text":"","title":"subsidies"},{"location":"subsidies-reference/#baus.subsidies.run_subsidized_developer","text":"The subsidized residential developer model.","title":"run_subsidized_developer()"},{"location":"subsidies-reference/#baus.subsidies.run_subsidized_developer--parameters","text":"DataFrame A DataFrame that is returned from run_feasibility for a given form DataFrameWrapper The standard parcels DataFrameWrapper (mostly just for run_developer) DataFrameWrapper The standard buildings DataFrameWrapper (passed to run_developer) DataFrameWrapper The households DataFrameWrapper (passed to run_developer) Dict A dictionary of settings to parameterize the model. Needs these keys: sending_buildings_subaccount_def - maps buildings to subaccounts receiving_buildings_filter - filter for eligible buildings Dict The overall settings Account The Account object to use for subsidization int The current simulation year (will be added as metadata) function Passed through to run_developer function Passed through to run_developer Summary Used to add parcel summary information bool Bool for whether to create deed restricted units with the subsidies or not. The logic at the time of this writing is to keep track of partial units so that when partial units sum to greater than a unit, that unit will be deed restricted.","title":"Parameters"},{"location":"subsidies-reference/#baus.subsidies.run_subsidized_developer--returns","text":"Nothing Subsidized residential developer is designed to run before the normal residential developer - it will prioritize the developments we're subsidizing (although this is not strictly required - running this model after the market rate developer will just create a temporarily larger supply of units, which will probably create less market rate development in the next simulated year). The steps for subsidizing are essentially these: 1 run feasibility with only_built set to false so that the feasibility of unprofitable units are recorded 2 temporarily filter to ONLY unprofitable units to check for possible subsidized units (normal developer takes care of market-rate units) 3 compute the number of units in these developments 4 divide cost by number of units in order to get the subsidy per unit 5 filter developments to parcels in \"receiving zone\" similar to the way we identified \"sending zones\" 6 iterate through subaccounts one at a time as subsidy will be limited to available funds in the subaccount (usually by jurisdiction) 7 sort ascending by subsidy per unit so that we minimize subsidy (but total subsidy is equivalent to total building cost) 8 cumsum the total subsidy in the buildings and locate the development where the subsidy is less than or equal to the amount in the account - filter to only those buildings (these will likely be built) 9 pass the results as \"feasible\" to run_developer - this is sort of a boundary case of developer but should run OK 10 for those developments that get built, make sure to subtract from account and keep a record (on the off chance that demand is less than the subsidized units, run through the standard code path, although it's very unlikely that there would be more subsidized housing than demand) Source code in baus\\subsidies.py 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 def run_subsidized_developer ( feasibility , parcels , buildings , households , acct_settings , settings , account , year , form_to_btype_func , add_extra_columns_func , summary , create_deed_restricted = False , policy_name = \"Unnamed\" ): \"\"\" The subsidized residential developer model. Parameters ---------- feasibility : DataFrame A DataFrame that is returned from run_feasibility for a given form parcels : DataFrameWrapper The standard parcels DataFrameWrapper (mostly just for run_developer) buildings : DataFrameWrapper The standard buildings DataFrameWrapper (passed to run_developer) households : DataFrameWrapper The households DataFrameWrapper (passed to run_developer) acct_settings : Dict A dictionary of settings to parameterize the model. Needs these keys: sending_buildings_subaccount_def - maps buildings to subaccounts receiving_buildings_filter - filter for eligible buildings settings : Dict The overall settings account : Account The Account object to use for subsidization year : int The current simulation year (will be added as metadata) form_to_btype_func : function Passed through to run_developer add_extra_columns_func : function Passed through to run_developer summary : Summary Used to add parcel summary information create_deed_restricted : bool Bool for whether to create deed restricted units with the subsidies or not. The logic at the time of this writing is to keep track of partial units so that when partial units sum to greater than a unit, that unit will be deed restricted. Returns ------- Nothing Subsidized residential developer is designed to run before the normal residential developer - it will prioritize the developments we're subsidizing (although this is not strictly required - running this model after the market rate developer will just create a temporarily larger supply of units, which will probably create less market rate development in the next simulated year). The steps for subsidizing are essentially these: 1 run feasibility with only_built set to false so that the feasibility of unprofitable units are recorded 2 temporarily filter to ONLY unprofitable units to check for possible subsidized units (normal developer takes care of market-rate units) 3 compute the number of units in these developments 4 divide cost by number of units in order to get the subsidy per unit 5 filter developments to parcels in \"receiving zone\" similar to the way we identified \"sending zones\" 6 iterate through subaccounts one at a time as subsidy will be limited to available funds in the subaccount (usually by jurisdiction) 7 sort ascending by subsidy per unit so that we minimize subsidy (but total subsidy is equivalent to total building cost) 8 cumsum the total subsidy in the buildings and locate the development where the subsidy is less than or equal to the amount in the account - filter to only those buildings (these will likely be built) 9 pass the results as \"feasible\" to run_developer - this is sort of a boundary case of developer but should run OK 10 for those developments that get built, make sure to subtract from account and keep a record (on the off chance that demand is less than the subsidized units, run through the standard code path, although it's very unlikely that there would be more subsidized housing than demand) \"\"\" # step 2 feasibility = feasibility . replace ([ np . inf , - np . inf ], np . nan ) feasibility = feasibility [ feasibility . max_profit < 0 ] # step 3 feasibility [ 'ave_sqft_per_unit' ] = parcels . ave_sqft_per_unit feasibility [ 'residential_units' ] = np . floor ( feasibility . residential_sqft / feasibility . ave_sqft_per_unit ) # step 3B # can only add units - don't subtract units - this is an approximation # of the calculation that will be used to do this in the developer model feasibility = feasibility [ feasibility . residential_units > feasibility . total_residential_units ] # step 3C # towards the end, because we're about to sort by subsidy per unit, some # large projects never get built, because it could be a 100 unit project # times a 500k subsidy per unit. thus we're going to try filtering by # the maximum subsidy for a single development here feasibility = feasibility [ feasibility . max_profit > - 50 * 1000000 ] # step 4 feasibility [ 'subsidy_per_unit' ] = - 1 * feasibility [ 'max_profit' ] / feasibility [ 'residential_units' ] # assumption that even if the developer says this property is almost # profitable, even the administration costs are likely to cost at least # 10k / unit feasibility [ 'subsidy_per_unit' ] = feasibility . subsidy_per_unit . clip ( 10000 ) # step 5 if \"receiving_buildings_filter\" in acct_settings : feasibility = feasibility . query ( acct_settings [ \"receiving_buildings_filter\" ]) else : # otherwise all buildings are valid pass new_buildings_list = [] sending_bldgs = acct_settings [ \"sending_buildings_subaccount_def\" ] feasibility [ \"regional\" ] = 1 feasibility [ \"subaccount\" ] = feasibility . eval ( sending_bldgs ) # step 6 for subacct , amount in account . iter_subaccounts (): print ( \"Subaccount: \" , subacct ) df = feasibility [ feasibility . subaccount == subacct ] print ( \"Number of feasible projects in receiving zone:\" , len ( df )) if len ( df ) == 0 : continue # step 7 df = df . sort_values ([ 'subsidy_per_unit' ], ascending = True ) # df.to_csv('subsidized_units_%d_%s_%s.csv' % (orca.get_injectable(\"year\"), account.name, subacct)) # step 8 print ( \"Amount in subaccount: $ {:,.2f} \" . format ( amount )) num_bldgs = int (( - 1 * df . max_profit ) . cumsum () . searchsorted ( amount )) if num_bldgs == 0 : continue # technically we only build these buildings if there's demand # print \"Building {:d} subsidized buildings\".format(num_bldgs) df = df . iloc [: int ( num_bldgs )] df . columns = pd . MultiIndex . from_tuples ( [( \"residential\" , col ) for col in df . columns ]) # disable stdout since developer is a bit verbose for this use case sys . stdout , old_stdout = StringIO (), sys . stdout kwargs = settings [ 'residential_developer' ] # step 9 new_buildings = utils . run_developer ( \"residential\" , households , buildings , \"residential_units\" , parcels . parcel_size , parcels . ave_sqft_per_unit , parcels . total_residential_units , orca . DataFrameWrapper ( \"feasibility\" , df ), year = year , form_to_btype_callback = form_to_btype_func , add_more_columns_callback = add_extra_columns_func , profit_to_prob_func = profit_to_prob_func , ** kwargs ) sys . stdout = old_stdout buildings = orca . get_table ( \"buildings\" ) if new_buildings is None : continue # keep track of partial subsidized untis so that we always get credit # for a partial unit, even if it's not built in this specific building partial_subsidized_units = 0 # step 10 for index , new_building in new_buildings . iterrows (): amt = new_building . max_profit metadata = { \"description\" : \"Developing subsidized building\" , \"year\" : year , \"residential_units\" : new_building . residential_units , \"inclusionary_units\" : new_building . inclusionary_units , \"building_id\" : index } if create_deed_restricted : revenue_per_unit = new_building . building_revenue / new_building . residential_units total_subsidy = abs ( new_building . max_profit ) subsidized_units = total_subsidy / revenue_per_unit + partial_subsidized_units # right now there are inclusionary requirements already_subsidized_units = new_building . deed_restricted_units # get remainder partial_subsidized_units = subsidized_units % 1 # round off for now subsidized_units = int ( subsidized_units ) + already_subsidized_units # cap at number of residential units subsidized_units = min ( subsidized_units , new_building . residential_units ) buildings . local . loc [ index , \"deed_restricted_units\" ] = int ( round ( subsidized_units )) buildings . local . loc [ index , \"subsidized_units\" ] = buildings . local . loc [ index , \"deed_restricted_units\" ] - \\ buildings . local . loc [ index , \"inclusionary_units\" ] # also correct the debug output new_buildings . loc [ index , \"deed_restricted_units\" ] = int ( round ( subsidized_units )) new_buildings . loc [ index , \"subsidized_units\" ] = new_buildings . loc [ index , \"deed_restricted_units\" ] - \\ new_buildings . loc [ index , \"inclusionary_units\" ] metadata [ 'deed_restricted_units' ] = new_buildings . loc [ index , 'deed_restricted_units' ] metadata [ 'subsidized_units' ] = new_buildings . loc [ index , 'subsidized_units' ] account . add_transaction ( amt , subaccount = subacct , metadata = metadata ) # turn off this assertion for the Draft Blueprint affordable housing policy since the number of deed restricted units # vs units from development projects looks reasonable # assert np.all(buildings.local.deed_restricted_units.fillna(0) <= # buildings.local.residential_units.fillna(0)) print ( \"Amount left after subsidy: $ {:,.2f} \" . format ( account . total_transactions_by_subacct ( subacct ))) new_buildings_list . append ( new_buildings ) total_len = reduce ( lambda x , y : x + len ( y ), new_buildings_list , 0 ) if total_len == 0 : print ( \"No subsidized buildings\" ) return new_buildings = pd . concat ( new_buildings_list ) print ( \"Built {} total subsidized buildings\" . format ( len ( new_buildings ))) print ( \" Total subsidy: $ {:,.2f} \" . format ( - 1 * new_buildings . max_profit . sum ())) print ( \" Total subsidized units: {:.0f} \" . format ( new_buildings . residential_units . sum ())) new_buildings [ \"subsidized\" ] = True new_buildings [ \"policy_name\" ] = policy_name summary . add_parcel_output ( new_buildings )","title":"Returns"},{"location":"user_guide/","text":"User Guide This User Guide applies to UrbanSim implementation for the Bay Area. Documentation for the UrbanSim framework is available here. Installation Bay Area UrbanSim is written in Python and runs in a command line environment. It's compatible with Mac, Windows, and Linux, and with Python 2.7 and 3.5+. Python 3 is recommended. Install the Anaconda Python distribution (not strictly required, but makes things easier and more reliable) Clone this repository Download base data from this Box folder and move the files to bayarea_urbansim/data/ (ask an MTC contact for access) Clone the MTC urban_data_internal repository to the same location as this repository (ask an MTC contact for access) Create a Python environment with the current dependencies: conda env create -f baus-env-2020.yml Activate the environment: conda activate baus-env-2020 Pre-process the base data: python baus.py --mode preprocessing (only needed once) Run the model: python baus.py (typical AWS linux run uses nohup python baus.py -s 25 --disable-slack --random-seed & which add no hanging up / specifies scenario 25 / disables slack output / turns OFF random seed / puts in background) More info about the command line arguments: python baus.py --help Optional visualization tool and Slack messenger: Configure Amazon Web Services (AWS) to get s3 permission (you will need an appropriately configured AWS credentials file from your MTC contact) Install AWS SDK for Python -- boto3 using pip install boto3 Install Slacker to use Slack API using pip install slacker (you will need an appropriate slack token to access the slack bot from your MTC contact) Set environment variable URBANSIM_SLACK = TRUE File Structure TBD","title":"User Guide"},{"location":"user_guide/#user-guide","text":"This User Guide applies to UrbanSim implementation for the Bay Area. Documentation for the UrbanSim framework is available here.","title":"User Guide"},{"location":"user_guide/#installation","text":"Bay Area UrbanSim is written in Python and runs in a command line environment. It's compatible with Mac, Windows, and Linux, and with Python 2.7 and 3.5+. Python 3 is recommended. Install the Anaconda Python distribution (not strictly required, but makes things easier and more reliable) Clone this repository Download base data from this Box folder and move the files to bayarea_urbansim/data/ (ask an MTC contact for access) Clone the MTC urban_data_internal repository to the same location as this repository (ask an MTC contact for access) Create a Python environment with the current dependencies: conda env create -f baus-env-2020.yml Activate the environment: conda activate baus-env-2020 Pre-process the base data: python baus.py --mode preprocessing (only needed once) Run the model: python baus.py (typical AWS linux run uses nohup python baus.py -s 25 --disable-slack --random-seed & which add no hanging up / specifies scenario 25 / disables slack output / turns OFF random seed / puts in background) More info about the command line arguments: python baus.py --help Optional visualization tool and Slack messenger: Configure Amazon Web Services (AWS) to get s3 permission (you will need an appropriately configured AWS credentials file from your MTC contact) Install AWS SDK for Python -- boto3 using pip install boto3 Install Slacker to use Slack API using pip install slacker (you will need an appropriate slack token to access the slack bot from your MTC contact) Set environment variable URBANSIM_SLACK = TRUE","title":"Installation"},{"location":"user_guide/#file-structure","text":"TBD","title":"File Structure"}]}