{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bay Area UrbanSim (BAUS) Introduction Bay Area UrbanSim (BAUS) is a land use or urban economic model used to forecast metropolitan growth, study urban policies, and evaluate transportation projects at the Metropolitan Transportation Commission (MTC). It is written in Python and is a customized version of the popular UrbanSim model developed by Professor Paul Waddell over the last few decades. BAUS simulates the movement of households and employees within the region, and the construction of new buildings to hold those households and employees. In this manner, it is used to incrementally forecast potential future urban growth trajectories. Contents [Model Overview]()","title":"Home"},{"location":"#bay-area-urbansim-baus","text":"","title":"Bay Area UrbanSim (BAUS)"},{"location":"#introduction","text":"Bay Area UrbanSim (BAUS) is a land use or urban economic model used to forecast metropolitan growth, study urban policies, and evaluate transportation projects at the Metropolitan Transportation Commission (MTC). It is written in Python and is a customized version of the popular UrbanSim model developed by Professor Paul Waddell over the last few decades. BAUS simulates the movement of households and employees within the region, and the construction of new buildings to hold those households and employees. In this manner, it is used to incrementally forecast potential future urban growth trajectories.","title":"Introduction"},{"location":"#contents","text":"[Model Overview]()","title":"Contents"},{"location":"input/","text":"The inputs structure for Bay Area UrbanSim (BAUS) and a decription of each input. Model input files are run specific: data inputs and model levers. These are stored in an inputs folder to be called by the model. Model configs are longer-term| model estimation constants, assumptions we do not expect to change. These live in the model's repository under the configs folder. inputs accessibility pandana name | use -----|-----| tmnet.h5| Travel model network information for calculating accessibility within the model using Pandana osm_bayarea4326.h5| Street network information for calculating accessibility within the model using Pandana landmarks.csv| Locations of a few major landmarks in the region for accessibility calculations. regional_poi_distances.csv| The pre-computed distances from each travel model node to each landmark. bart_stations.csv| A list of BART stations and their locations so that distance to BART can calculated. logsums.csv| A set of base year logsums from the travel model. travel_model name | use -----|-----| AccessibilityMarkets_YYY.csv| A travel model output file that incorportates travel model run logsums into the forecast, by year. mandatoryAccessibilities_YYY.csv| A travel model output file that incorportates travel model run logsums into the forecast, by year. nonMandatoryAccessibilities_YYY.csv| A travel model output file that incorportates travel model run logsums into the forecast, by year. basis_inputs (under construction) crosswalks name | use -----|-----| parcel_to_maz22.csv| A lookup table from parcels to Travel Model Two MAZs. parcel_to_taz1454sub.csv| A lookup table from parcels to Travel Model One TAZs. parcels_geography.csv| A lookup table from parcels to jurisdiction, growth geographies, UGB areas, greenfield areas, and a concatenation of these used to join these geographies zoning_mods.csv, to apply zoning rules within them. census_id_to_name.csv| Maps census id from parcels_geography to name so it can be used. maz_geography| A lookup between MAZ, TAZ2, and county. maz22_taz1454| A lookup between MAZ and TAZ1. superdistricts_geography.csv| A map of superdistrict numbers, names, and their subregion. taz_geography.csv| A lookup between TAZ1, supedisctrict, and county. edits name | use -----|-----| data_edits.yaml| Settings for editing the input data in the model code, e.g. clipping values. manual_edits.csv| Overrides the current h5 data using the table name, attribute name, and new value, so we don't have to generate a new one each time. household_building_id_overrides.csv| Moves households to match new city household totals during the data preprocessing. tpp_id_2016.csv| Updates tpp_ids after changes were made to the ids. existing_policy name | use -----|-----| development_caps.yaml| Base year job cap policies in place in jurisdictions (TODO: remove the asserted development capsk-factors entangled here.) inclusionary.yaml| Base year inclusionary zoning policies in place in jurisdictions (TODO: have all model runs inherit these, even if an inclusionary stratey is applied). hazards name | use -----|-----| slr_progression.csv| The sea level rise level, for each forecast year. slr_inundation.csv| The sea level rise level at which each inundation parcel becomes inundated, for each forecast year. Rows marked with \"100\" are parcels where sea level rise has been mitigated, either through planned projects or a plan strategy. parcels_buildings-agents name | use -----|-----| bayarea_v3.h5| Base year database of households, jobs, buildings, and parcels. The data is pre-processed in pre-processing.py. costar.csv| Commercial data from CoStar, including non-residential price to inform the price model. development_projects.csv| The list of projects that have happened since the base data, or buildings in the development pipeline. This file tends to have more attributes than we use in the model. deed_restricted_zone_totals.csv| An approximate number of deed restricted units per TAZ to assign randomly within the TAZ. baseyear_taz_controls.csv| Base year control totals by TAZ, to use for checking and refining inputs. The file includes number of units, vacancy rates, and employment by sector (TODO: add households). sfbay_craisglist.csv| Craigslist data to inform rental unit information and model tenure. zoning name | use -----|-----| zoning_parcels.csv| A lookup table from parcels to zoning_id, zoning area information, and a \"nodev\" flag (currently all set to 0). zoning_lookup.csv| The existing zoning for each jurisdiction, assigned to parcels with the \"id\" field. Fields include the city name, city id, and the name of the zoning. The active attributes are max_dua, max_far, and max_height, all of which must be respected by each development. plan_strategies name | use -----|-----| accessory_units.csv| A file to add accessory dwelling units to jurisdictions by year, simulating policy to allow or reduce barriers to ADU construction in jurisdictions (TODO: Make this a default policy). account_strategies.yaml| This files contains the settings for all strategies in a model run that use accounts. The file may include account settings (e.g., how much to spend, where to spend) for| housing development bonds, office development bonds, OBAG funds, and VMT fees (which collect fees and then can spend the subsidies). development_caps_strategy.yaml| A file that specifies a strategy to limit development (generally office development) to a certain number of residential units andor job spaces. inclusionary_strategy.yaml| A file to apply an inclusionary zoning strategy by geography and inclusionary housing requirement percentage. preservation.yaml| A file to apply an affordable housing preservation strategy through specifying geography and target number of units for preservation. profit_adjustment_stratgies.yaml| This file contains the settings for all strategies in a model run which modify the profitability of projects thus altering their feasibility. The file may include profit adjustment settings (e.g., the percent change to profit) for| development streamlining, CEQA streamlining, parking requirements reductions, and profitability changes from SB-743. renter_protections_relocation_rates_overwrites| The rows in this file overwrite the household relocation rates in the model's settings. telecommute_sqft_per_job_adjusters| These are multipliers which adjust the sqft per job setting by superdistrict by year to represent changes from a telework strategy. (TODO: Disentangle the k-factors and the policy application within this file and sqft_per_job_adjusters.csv. In the meantime, use both files as is done in the PBA50 No Project). vmt_fee_zonecats.csv| This file pairs with the VMT Fee and SB-743 strategies. It provides VMT levels by TAZ1, which map to the corresponding price adjustments in the strategies. zoning_mods.csv| A file which allows you to upzone or downzone. If you enter a value in \"dua_up\" or \"far_up\", the model will apply that as the new zoning or maintain the existing zoning if it is higher. If you enter a value in \"dua_down\" or \"far_down\", the model will apply that as the zoning or maintain the existing zoning if it is lower. UGBs are also controlled using this file, using zoning changes to enforce them. This file is mapped to parcels using the field \"zoningmodcat\", which is the concatenated field of growth designations in parcels_geography.csv. regional_controls name | use -----|-----| employment_controls.csv| The total number of jobs in the region for the model to allocate, by year. The controls are provided by 6-sector job category. household_controls.csv| The total number of households in the region for the model to allocate, by year. The controls are provided by household income quartile. zone_forecasts name | use -----|-----| taz_growth_rates_gov_ed.csv| This file has ratios of governement and education employment per population by County and TAZ. The files has two header rows| the first row is what the outcome attribute is and the second is the geography at which the ratio acts (either TAZ, County, or Regional). prportional_retail_jobs_forecast.csv| This contains the field \"minimum_forecast_retail_jobs_per_household\" by jurisdiction, which is used to keep local numbers of retail jobs reasonable through the forecast. tm1_taz1_forecast_inputs.csv| This is closely related to regional_controls.csv. These are zone level inputs used for the process of generating variables for the travel model, while the other file contains regional-level controls. These inputs provide TAZ1454 information, used for Travel Model One summaries. tm2_taz2_forecast_inputs.csv| The same as above, except these inputs provide TAZ2 information, usED for Travel Model Two summaries. tm1_tm2_maz_forecast_inputs.csv| The same as above, except these inputs provide MAZ information, used for btoh Travel Model One and Travel Model Two summaries. tm2_emp27_employment_shares| The forecasted share of jobs by 26 sectors, used to apportion that 6 sectors used in the model into more detailed categories Travel Model Two. The shares are provided by county and by year. tm2_occupation_shares| The forecasted share of jobs by occupation, used for Travel Model Two. The shares are provided by county and by year. tm1_tm2_regional_controls.csv| Controls from the regional forecast which give us employed residents and the age distribution by year, used to forecast variables used by the travel model. tm1_tm2_regional_demographic_forecast| Similar to regional_controls.csv, this file provides regional-level information to produce travel model variables, in this case using forecasts of shares by year. bayarea_urbansim configs adjusters name | use -----|-----| cost_shifters.yaml| Multipliers to cost, currently specified by county, used to calibrate the model. development_caps_asserted.yaml| Caps on development, either residential or office, used to calibrate the model. (TODO: remove any base year existing policy caps entangled here). employment_relocation_rates_overwrites.csv| These overwrite the relocation rates in employment_relocation_rates.csv to calibrate the model, e.g. leave government sector jobs in San Francisco City Hall's TAZ. sqft_per_job_adjusters| Multipliers to the number of sqft used by each job, defined in the model's developer settings, which modify the number of jobs that can occupy a building. This is used to calibrate the model, e.g. reflect CBD job densities or adjust vacancy rates by superdistrict. The inputs file telecommute_sqft_per_job_adjusters.csv uses alternative multipliers for for the forecast years in place of these, if the strategy is enabled. (TODO: Disentangle the k-factors and the policy application in these two files. In the meantime, use both files as is done in the PBA50 No Project). zoning_adjusters.yaml| Adjusters used to modify the model's zoning data. accessibility name | use -----|-----| accessibility_settings.yaml| Settings for Pandana, the model's endogenous accessibility calculations. neighborhood_vars.yaml| Settings for calculating local accessibility variables during the model run. regional_vars.yaml| Settings for calculating regional accessibility variables during the model run. price_vars.yaml| Settings for calculating local accessibility variables on price during the model run. developer name | use -----|-----| developer_settings.yaml| Settings for the model's developer and feasibility models. residential_vacancy_rates.csv| Residential vacancy rates for the residential developer model, separated from the main developer settings into this file to allow them to vary by year. hedonics name | use -----|-----| price_settings.yaml| Settings for the model's price simulation and supplydemand equilibration of price. nrh.yaml| Non-residential hedonic price model specification. rrh.yaml| Residential rent hedonic price model specification. rsh.yaml| Residential sales hedonic price model specification. location_choice name | use -----|-----| elcm.yaml| Employment location choice model specification, segemented by six employment sectors. hlcm_owner.yaml| Household location choice model specification segmented by income quartiles. The models are estimated for owner households. hlcm_owner_lowincome.yaml| This uses the same specification and estimated coefficients as hlcm_owner. The only difference is that it is used to only low income households to choose deed-restricted owner units. hlcm_owner_lowincome_no_unplaced.yaml| This uses the same specification and estimated coefficients as hlcm_owner, but allows owners of all incomes into deed-restricted owner units to cover any gaps in assignment. hlcm_owner_no_unplaced.yaml| This uses the same specification and estimated coefficients as hlcm_owner, but does another round of placements of owners, this time into non-deed-restricted owner units, to cover any gaps in assignment. hlcm_renter.yaml| Household location choice model specification segmented by income quartiles. The models are estimated for rental households. hlcm_renter_lowincome.yaml| This uses the same specification and estimated coefficients as hlcm_renter. The only difference is that it is used to only low income households to choose deed-restricted rental units. hlcm_renter_lowincome_no_unplaced.yaml| This uses the same specification and estimated coefficients as hlcm_renter, but allows renters of all incomes into deed-restricted rental units to cover any gaps in assignment. hlcm_renter_no_unplaced.yaml| This uses the same specification and estimated coefficients as hlcm_renter, but does another round of placement of renters, this time into non-deed-restricted rental units, to cover any gaps in assignment. location choice cont. HLCM Model | Estimation Choosers: Filters | Estimation Alternatives: Filters | Simulation Choosers: Filters | Simulation Alternatives: Filters -----|-----|-----|-----|-----| owner|Owners|-|Owners|Owner Units| owner_lowincome|Owners|-|Low-Income Owners| Affordable Owner Units| owner_lowincome_no_unplaced|-|-|Owners|Affordable Owner Units| owner_no_unplaced|Owners|-|Owners| Market-Rate Owner Units| renter|Renters|-|Renters|Renters Units| renter_lowincome|Renters|-|Low-Income Renters|Affordable Rental Units| renter_lowincome_no_unplaced|-|-|Renters|Affordable Rentual Units| renter_no_unplaced|Renters|-|Renters|Market Rate Rental Units| transition_relocation name | use -----|-----| employment_relocation_rates.csv| A file with the probability of a job relocating during a time step in the forecast, by TAZ and by employment sector. Pairs with employment_relocation_rates.csv which overwrites the model probabilities with calibration factors. household_relocation_rates.csv| A file with the probability of a household relocating during a time step in the forecast, by TAZ, income, and tenure. Pairs with renter_protections_relocation_rates_overwrites.csv which overwrites model probabilities with different relocation rates when the renter protections strategy is enabled. transition_relocation_settings.yaml| Settings for the transition and relocation models. mapping.yaml Mapping used in the model to relate variables to one another. paths.yaml Variables that store file names for use in the model code.","title":"Input"},{"location":"input/#the-inputs-structure-for-bay-area-urbansim-baus-and-a-decription-of-each-input-model-input-files-are-run-specific-data-inputs-and-model-levers-these-are-stored-in-an-inputs-folder-to-be-called-by-the-model-model-configs-are-longer-term-model-estimation-constants-assumptions-we-do-not-expect-to-change-these-live-in-the-models-repository-under-the-configs-folder","text":"","title":"The inputs structure for Bay Area UrbanSim (BAUS) and a decription of each input. Model input files are run specific: data inputs and model levers. These are stored in an inputs folder to be called by the model. Model configs are longer-term| model estimation constants, assumptions we do not expect to change. These live in the model's repository under the configs folder."},{"location":"input/#inputs","text":"","title":"inputs"},{"location":"input/#accessibility","text":"","title":"accessibility"},{"location":"input/#pandana","text":"name | use -----|-----| tmnet.h5| Travel model network information for calculating accessibility within the model using Pandana osm_bayarea4326.h5| Street network information for calculating accessibility within the model using Pandana landmarks.csv| Locations of a few major landmarks in the region for accessibility calculations. regional_poi_distances.csv| The pre-computed distances from each travel model node to each landmark. bart_stations.csv| A list of BART stations and their locations so that distance to BART can calculated. logsums.csv| A set of base year logsums from the travel model.","title":"pandana"},{"location":"input/#travel_model","text":"name | use -----|-----| AccessibilityMarkets_YYY.csv| A travel model output file that incorportates travel model run logsums into the forecast, by year. mandatoryAccessibilities_YYY.csv| A travel model output file that incorportates travel model run logsums into the forecast, by year. nonMandatoryAccessibilities_YYY.csv| A travel model output file that incorportates travel model run logsums into the forecast, by year.","title":"travel_model"},{"location":"input/#basis_inputs-under-construction","text":"","title":"basis_inputs (under construction)"},{"location":"input/#crosswalks","text":"name | use -----|-----| parcel_to_maz22.csv| A lookup table from parcels to Travel Model Two MAZs. parcel_to_taz1454sub.csv| A lookup table from parcels to Travel Model One TAZs. parcels_geography.csv| A lookup table from parcels to jurisdiction, growth geographies, UGB areas, greenfield areas, and a concatenation of these used to join these geographies zoning_mods.csv, to apply zoning rules within them. census_id_to_name.csv| Maps census id from parcels_geography to name so it can be used. maz_geography| A lookup between MAZ, TAZ2, and county. maz22_taz1454| A lookup between MAZ and TAZ1. superdistricts_geography.csv| A map of superdistrict numbers, names, and their subregion. taz_geography.csv| A lookup between TAZ1, supedisctrict, and county.","title":"crosswalks"},{"location":"input/#edits","text":"name | use -----|-----| data_edits.yaml| Settings for editing the input data in the model code, e.g. clipping values. manual_edits.csv| Overrides the current h5 data using the table name, attribute name, and new value, so we don't have to generate a new one each time. household_building_id_overrides.csv| Moves households to match new city household totals during the data preprocessing. tpp_id_2016.csv| Updates tpp_ids after changes were made to the ids.","title":"edits"},{"location":"input/#existing_policy","text":"name | use -----|-----| development_caps.yaml| Base year job cap policies in place in jurisdictions (TODO: remove the asserted development capsk-factors entangled here.) inclusionary.yaml| Base year inclusionary zoning policies in place in jurisdictions (TODO: have all model runs inherit these, even if an inclusionary stratey is applied).","title":"existing_policy"},{"location":"input/#hazards","text":"name | use -----|-----| slr_progression.csv| The sea level rise level, for each forecast year. slr_inundation.csv| The sea level rise level at which each inundation parcel becomes inundated, for each forecast year. Rows marked with \"100\" are parcels where sea level rise has been mitigated, either through planned projects or a plan strategy.","title":"hazards"},{"location":"input/#parcels_buildings-agents","text":"name | use -----|-----| bayarea_v3.h5| Base year database of households, jobs, buildings, and parcels. The data is pre-processed in pre-processing.py. costar.csv| Commercial data from CoStar, including non-residential price to inform the price model. development_projects.csv| The list of projects that have happened since the base data, or buildings in the development pipeline. This file tends to have more attributes than we use in the model. deed_restricted_zone_totals.csv| An approximate number of deed restricted units per TAZ to assign randomly within the TAZ. baseyear_taz_controls.csv| Base year control totals by TAZ, to use for checking and refining inputs. The file includes number of units, vacancy rates, and employment by sector (TODO: add households). sfbay_craisglist.csv| Craigslist data to inform rental unit information and model tenure.","title":"parcels_buildings-agents"},{"location":"input/#zoning","text":"name | use -----|-----| zoning_parcels.csv| A lookup table from parcels to zoning_id, zoning area information, and a \"nodev\" flag (currently all set to 0). zoning_lookup.csv| The existing zoning for each jurisdiction, assigned to parcels with the \"id\" field. Fields include the city name, city id, and the name of the zoning. The active attributes are max_dua, max_far, and max_height, all of which must be respected by each development.","title":"zoning"},{"location":"input/#plan_strategies","text":"name | use -----|-----| accessory_units.csv| A file to add accessory dwelling units to jurisdictions by year, simulating policy to allow or reduce barriers to ADU construction in jurisdictions (TODO: Make this a default policy). account_strategies.yaml| This files contains the settings for all strategies in a model run that use accounts. The file may include account settings (e.g., how much to spend, where to spend) for| housing development bonds, office development bonds, OBAG funds, and VMT fees (which collect fees and then can spend the subsidies). development_caps_strategy.yaml| A file that specifies a strategy to limit development (generally office development) to a certain number of residential units andor job spaces. inclusionary_strategy.yaml| A file to apply an inclusionary zoning strategy by geography and inclusionary housing requirement percentage. preservation.yaml| A file to apply an affordable housing preservation strategy through specifying geography and target number of units for preservation. profit_adjustment_stratgies.yaml| This file contains the settings for all strategies in a model run which modify the profitability of projects thus altering their feasibility. The file may include profit adjustment settings (e.g., the percent change to profit) for| development streamlining, CEQA streamlining, parking requirements reductions, and profitability changes from SB-743. renter_protections_relocation_rates_overwrites| The rows in this file overwrite the household relocation rates in the model's settings. telecommute_sqft_per_job_adjusters| These are multipliers which adjust the sqft per job setting by superdistrict by year to represent changes from a telework strategy. (TODO: Disentangle the k-factors and the policy application within this file and sqft_per_job_adjusters.csv. In the meantime, use both files as is done in the PBA50 No Project). vmt_fee_zonecats.csv| This file pairs with the VMT Fee and SB-743 strategies. It provides VMT levels by TAZ1, which map to the corresponding price adjustments in the strategies. zoning_mods.csv| A file which allows you to upzone or downzone. If you enter a value in \"dua_up\" or \"far_up\", the model will apply that as the new zoning or maintain the existing zoning if it is higher. If you enter a value in \"dua_down\" or \"far_down\", the model will apply that as the zoning or maintain the existing zoning if it is lower. UGBs are also controlled using this file, using zoning changes to enforce them. This file is mapped to parcels using the field \"zoningmodcat\", which is the concatenated field of growth designations in parcels_geography.csv.","title":"plan_strategies"},{"location":"input/#regional_controls","text":"name | use -----|-----| employment_controls.csv| The total number of jobs in the region for the model to allocate, by year. The controls are provided by 6-sector job category. household_controls.csv| The total number of households in the region for the model to allocate, by year. The controls are provided by household income quartile.","title":"regional_controls"},{"location":"input/#zone_forecasts","text":"name | use -----|-----| taz_growth_rates_gov_ed.csv| This file has ratios of governement and education employment per population by County and TAZ. The files has two header rows| the first row is what the outcome attribute is and the second is the geography at which the ratio acts (either TAZ, County, or Regional). prportional_retail_jobs_forecast.csv| This contains the field \"minimum_forecast_retail_jobs_per_household\" by jurisdiction, which is used to keep local numbers of retail jobs reasonable through the forecast. tm1_taz1_forecast_inputs.csv| This is closely related to regional_controls.csv. These are zone level inputs used for the process of generating variables for the travel model, while the other file contains regional-level controls. These inputs provide TAZ1454 information, used for Travel Model One summaries. tm2_taz2_forecast_inputs.csv| The same as above, except these inputs provide TAZ2 information, usED for Travel Model Two summaries. tm1_tm2_maz_forecast_inputs.csv| The same as above, except these inputs provide MAZ information, used for btoh Travel Model One and Travel Model Two summaries. tm2_emp27_employment_shares| The forecasted share of jobs by 26 sectors, used to apportion that 6 sectors used in the model into more detailed categories Travel Model Two. The shares are provided by county and by year. tm2_occupation_shares| The forecasted share of jobs by occupation, used for Travel Model Two. The shares are provided by county and by year. tm1_tm2_regional_controls.csv| Controls from the regional forecast which give us employed residents and the age distribution by year, used to forecast variables used by the travel model. tm1_tm2_regional_demographic_forecast| Similar to regional_controls.csv, this file provides regional-level information to produce travel model variables, in this case using forecasts of shares by year.","title":"zone_forecasts"},{"location":"input/#bayarea_urbansim","text":"","title":"bayarea_urbansim"},{"location":"input/#configs","text":"","title":"configs"},{"location":"input/#adjusters","text":"name | use -----|-----| cost_shifters.yaml| Multipliers to cost, currently specified by county, used to calibrate the model. development_caps_asserted.yaml| Caps on development, either residential or office, used to calibrate the model. (TODO: remove any base year existing policy caps entangled here). employment_relocation_rates_overwrites.csv| These overwrite the relocation rates in employment_relocation_rates.csv to calibrate the model, e.g. leave government sector jobs in San Francisco City Hall's TAZ. sqft_per_job_adjusters| Multipliers to the number of sqft used by each job, defined in the model's developer settings, which modify the number of jobs that can occupy a building. This is used to calibrate the model, e.g. reflect CBD job densities or adjust vacancy rates by superdistrict. The inputs file telecommute_sqft_per_job_adjusters.csv uses alternative multipliers for for the forecast years in place of these, if the strategy is enabled. (TODO: Disentangle the k-factors and the policy application in these two files. In the meantime, use both files as is done in the PBA50 No Project). zoning_adjusters.yaml| Adjusters used to modify the model's zoning data.","title":"adjusters"},{"location":"input/#accessibility_1","text":"name | use -----|-----| accessibility_settings.yaml| Settings for Pandana, the model's endogenous accessibility calculations. neighborhood_vars.yaml| Settings for calculating local accessibility variables during the model run. regional_vars.yaml| Settings for calculating regional accessibility variables during the model run. price_vars.yaml| Settings for calculating local accessibility variables on price during the model run.","title":"accessibility"},{"location":"input/#developer","text":"name | use -----|-----| developer_settings.yaml| Settings for the model's developer and feasibility models. residential_vacancy_rates.csv| Residential vacancy rates for the residential developer model, separated from the main developer settings into this file to allow them to vary by year.","title":"developer"},{"location":"input/#hedonics","text":"name | use -----|-----| price_settings.yaml| Settings for the model's price simulation and supplydemand equilibration of price. nrh.yaml| Non-residential hedonic price model specification. rrh.yaml| Residential rent hedonic price model specification. rsh.yaml| Residential sales hedonic price model specification.","title":"hedonics"},{"location":"input/#location_choice","text":"name | use -----|-----| elcm.yaml| Employment location choice model specification, segemented by six employment sectors. hlcm_owner.yaml| Household location choice model specification segmented by income quartiles. The models are estimated for owner households. hlcm_owner_lowincome.yaml| This uses the same specification and estimated coefficients as hlcm_owner. The only difference is that it is used to only low income households to choose deed-restricted owner units. hlcm_owner_lowincome_no_unplaced.yaml| This uses the same specification and estimated coefficients as hlcm_owner, but allows owners of all incomes into deed-restricted owner units to cover any gaps in assignment. hlcm_owner_no_unplaced.yaml| This uses the same specification and estimated coefficients as hlcm_owner, but does another round of placements of owners, this time into non-deed-restricted owner units, to cover any gaps in assignment. hlcm_renter.yaml| Household location choice model specification segmented by income quartiles. The models are estimated for rental households. hlcm_renter_lowincome.yaml| This uses the same specification and estimated coefficients as hlcm_renter. The only difference is that it is used to only low income households to choose deed-restricted rental units. hlcm_renter_lowincome_no_unplaced.yaml| This uses the same specification and estimated coefficients as hlcm_renter, but allows renters of all incomes into deed-restricted rental units to cover any gaps in assignment. hlcm_renter_no_unplaced.yaml| This uses the same specification and estimated coefficients as hlcm_renter, but does another round of placement of renters, this time into non-deed-restricted rental units, to cover any gaps in assignment.","title":"location_choice"},{"location":"input/#location-choice-cont","text":"HLCM Model | Estimation Choosers: Filters | Estimation Alternatives: Filters | Simulation Choosers: Filters | Simulation Alternatives: Filters -----|-----|-----|-----|-----| owner|Owners|-|Owners|Owner Units| owner_lowincome|Owners|-|Low-Income Owners| Affordable Owner Units| owner_lowincome_no_unplaced|-|-|Owners|Affordable Owner Units| owner_no_unplaced|Owners|-|Owners| Market-Rate Owner Units| renter|Renters|-|Renters|Renters Units| renter_lowincome|Renters|-|Low-Income Renters|Affordable Rental Units| renter_lowincome_no_unplaced|-|-|Renters|Affordable Rentual Units| renter_no_unplaced|Renters|-|Renters|Market Rate Rental Units|","title":"location choice cont."},{"location":"input/#transition_relocation","text":"name | use -----|-----| employment_relocation_rates.csv| A file with the probability of a job relocating during a time step in the forecast, by TAZ and by employment sector. Pairs with employment_relocation_rates.csv which overwrites the model probabilities with calibration factors. household_relocation_rates.csv| A file with the probability of a household relocating during a time step in the forecast, by TAZ, income, and tenure. Pairs with renter_protections_relocation_rates_overwrites.csv which overwrites model probabilities with different relocation rates when the renter protections strategy is enabled. transition_relocation_settings.yaml| Settings for the transition and relocation models.","title":"transition_relocation"},{"location":"input/#mappingyaml","text":"Mapping used in the model to relate variables to one another.","title":"mapping.yaml"},{"location":"input/#pathsyaml","text":"Variables that store file names for use in the model code.","title":"paths.yaml"},{"location":"model_overview/","text":"Model Overview Approach A forecast with BAUS begins with a basemap. This is a detailed geodatabase containing all of the region\u2019s buildings, households, employees, policies, and transport network for a recent year. This roughly corresponds to tooday\u2019s conditions but is a few years in the past due to data collection lag and formalities related to the modeling framework. The buildings are largely an accurate collection of every structure gathered from assessor\u2019s data, commercial read estate databases, and other sources. The households and employees are represented at the micro level but their characteristics are built through synthesis (i.e., we only have samples of this informations so we build a full representation that is consistent with these samples). Policies such as zoning and growth limits are collected for each jurisdiction and are binding unless they are explicitly changed for a forecast. BAUS is used to forecast the future by advancing through repeated steps that chart out a potential pathway for future urban growth. In BAUS each step represents a five year period. Most steps repeat the same set of sub-steps. In UrbanSim, each of these sub-steps is called a \u201cmodel\u201d. The file used to run BAUS (baus.py) sets the number steps and the order in which the models are are run. The major types of model steps are: (Hazards): This optional model simulates the impact of earthquakes and sea level rise by destroying buildings and displacing their inhabitants. Calculate accessibility: Logsum accessibility measures are brought in from the Travel Model and pedestrian accessibility is calculated within UrbanSim Calculate housing prices and rents: Hedonic regression models are applied to current (to the model time step) conditions to reestimate current prices and rents HH/employee relcation and transition: Some households and employeees are selected to move; additiional households and employees are added or subtracted to reflect the exogenous control totals Add buildings from the Development Projects list: Buildings are forced into the model (as opposed to being explicitly modeled); these represent institutional plans (e.g., universities and hospitals), large approved projects (e.g., Treasure Island), and development that has occurred between the basemap year and the current year (i.e., constructed 2016-2020). Build new market-rate housing units and commercial space: The for-profit real estate development process is simulated and new buildings are built where they are most feasible; this also build deed-restricted unit that are produced through the market-rate process (e.g., inclusionary zoning). Build new deed-restricted affordable units: A similar not-for-profit real estate development process produces affordable housing units based on money available within BAUS Accounts (e.g., bond measures). HH/employee location choices: Households and employees are assigned to new locations based on logistic regresssion models that capture the preferences of particular segments (e.g., lower income households, retail jobs). Produce summary tables: Numerous zonal summaries of the detailed geodatabaase are produced for analysis of urban change and for use in the Travel Model; this step includes additional post-processing to get the data ready for the Travel Model\u2019s population synthesizer. Sub-Models Typically, a set of BAUS inputs or assumptions are modified to produce a scenario. Policies such as zoning or fees can be modified. Control totals can be adjusted. Assumptions about preferences or financical situations can be adjusted. The package of changes is then simulated to forecast its impact on the future urban landscape and these outcomes are often enterered into the travel model to predict future year travel patterns and greenhouse gas emmissions. Application Types BAUS is used for for three typical types of application: Forecasting: UrbanSim produces a complete map for each five year interval into the future. This information is required by statute and useful for planning processes. Policy Studies: BAUS can evaluate the impact of policy changes on, for example, the amount of housing produced, the amount of deed-restricted housing producded, and the locations of future residential or commercial development. Transport Project Evaluation: BAUS provides information on future land use patterns used to evaluate the benefits and costs of large transport infrastructure investments and allows an assessment of how such projects may influence future development. Model System BAUS is the middle model in an interactive suite of three model systems maintained by MTC: Regional economic and demographic information is supplied to BAUS from the REMI CGE model and related demographic processing scripts. BAUS outputs on housing production are used to adjust regional housing prices (and thus other variables) in REMI. Accessibillity information is supplied to BAUS from the Travel Model and influences real estate prices and household and employee location choices. BAUS outputs on the location of various types of households and employees are used to establish origins and destinations in the Travel Model. An overview of baus.py baus.py is a command line interface (cli) used to run Bay Area UrbanSim in various modes. These modes currently include: estimation, which runs a series of models to save parameter estimates for all statistical models simulation, which runs all models to create a simulated regional growth forecast fetch_data, which downloads large data files from Amazon S3 as inputs for BAUS preprocessing, which performas long-running data cleaning steps and writes newly cleaned data back to the binary h5 file for use in the other steps baseyearsim which runs a \"base year simulation\" which summarizes the data before the simulation runs (during simulation, summaries are written after each year, so the first year's summaries are after the base year is finished - a base year simulation writes the summaries before any models have run) Urban Analytics Lab (UAL) Improvements Data schemas Builds out the representation of individual housing units to include a semi-persistent tenure status, which is assigned based on characteristics of initial unit occupants Joins additional race/ethnicity PUMS variables to synthetic households [NB: currently missing from the reconciled model, but will be re-added] Adds a representation of market rents alongside market sale prices Model steps Residential hedonics predict market rents and sale prices separately, with rents estimated from Craigslist listings Household move-out choice is conditional on tenure status Household location choice is modeled separately for renters and owners, and includes race/ethnicity measures as explanatory variables Developer models are updated to produce both rental and ownership housing stock Notebooks, work history, code samples, etc are kept in a separate bayarea_urbansim_work repository. Current status (August 2016) All of the UAL alterations have been refactored as modular orca steps This code is contained in baus/ual.py , configs/ual_settings.yaml and individual yaml files as needed for regression models that have been re-estimated There are no changes to urbansim , urbansim_defaults , or MTC's orca initialization and model steps MTC and UAL model steps can be mixed and matched by passing different lists to orca; see run.py for examples The UAL model steps document and test for required data characteristics, using the orca_test library Outputs from Simulation (written to the runs directory) ALL OUTPUT IN THIS DIRECTORY IS NOT OFFICIAL OUTPUT. PLEASE CONTACT MTC FOR OFFICIAL OUTPUTS OF THE LAST PLAN BAY AREA. [num] = a positive integer used to identify each successive run. This number usually starts at 1 and increments each time baus.py is called. Many files are output to the runs/ directory. They are described below. filename description run[num]_topsheet_[year].csv An overall summary of various housing and employment outcomes summarized by very coarse geographies. run[num]_parcel_output.csv A csv of all new built space in the region, not including ADUs added to existing buildings. This has a few thousand rows and dozens of columns which contain various inputs and outputs, as well as debugging information which helps explain why each development was picked by UrbanSim. run[num]_parcel_data_[year].csv A CSV with parcel level output for all parcels with lat, lng and includes change in total_residential_units and change in total_job_spaces, as well as zoned capacity measures. run[num]_building_data_[year].csv The same as above but for buildings. run[num]_taz_summaries_[year].csv A CSV for input to the MTC travel model run[num]_pda_summaries_[year].csv, run[num]_juris_summaries_[year].csv, run[num]_superdistrict_summaries_[year].csv Similar outputs to the taz summaries but for each of these geographies. Used for understanding the UrbanSim forecast at an aggregate level. run[num]_acctlog_[account name]_[year].csv A series of CSVs of each account's funding amount and buildings developed under this acount (if the funding is used to subsidize development) in each iteration. run[runnum]_dropped_buildings.csv A summary of buildings which were redeveloped during the simulated forecast. run[runnum]_simulation_output.json Used by the web output viewer. Directory structure baus/ contains all the Python code which runs the BAUS model. data/ contains BAUS inputs which are small enough to store and render in GitHub (large files are stored on Amazon S3) - this also contains lots of scenario inputs in the form of csv files. See the readme in the data directory for detailed docs on each file. configs/ contains the model configuration files used by UrbanSim. This also contains settings.yaml which provides simulation inputs and settings in a non-tabular form. scripts/ these are one-off scripts which are used to perform various input munging and output analysis tasks. See the docs in that directory for more information. A list of features available in BAUS Data management Add manual_edits.csv to edit individual attributes for each building/parcel in the building and parcel tables An orca step to correct the baseyear vacancies on the job side which happens pre-simulation Do job assignment by starting with baseyear controls and assigning on the fly (should do the same for households) Randomly assign deed restricted units within a zone because that's the most specific data would could get Run management Ability to run different model sets, output to Slack and web maps (in baus.py) Standard (or extensions to) UrbanSim features Houshold and job control totals by year Standard UrbanSim models - hedonic, location choice, transition, relocation models Basic supply and demand interactions to raise prices where demand exceeds supply Separate low and high income hlcms for the deed restricted units 1300 lines of computed columns to support the functionality described above Accessibility variables Accessibility variables including special \"distance to location\" variables Both local (local street network from OSM) and regional (travel model network) networks Network aggregations for prices as well Human input and overrides for specific models Do parcel-by-parcel rejections based on human knowledge to override the model Quite a bit of support by year and by scenario for custom development projects, as well as add vs demolish settings Proportional job model on \"static parcels\". Static parcels are parcels whose jobs do not enter the relocation model and are auto-marked nodev. These are e.g. city hall and Berkeley which would never get newly created by the model Relocation rates by taz Developer model Provide baseline zoning using parcel to zoning lookups and then attributes for all the zones in the region (num zones << num parcels) Do conditional upzoning and downzoning, add and remove building types, all by policy zone Limits - assign all parcels to a \"bucket\" - in this case to a city, but it could be a pda-city intersection. Limits the amount of res and non-res development that comes from each bucket. Make sure to do so for all non-res types. A special retail model which takes into account where demand for retail is high (income x households) but supply is low We still need a better way to determine the uses that get built between office / retail / industrial / whatever else A reprocessing of the developer results which adds job spaces to residential buildings at an appropriate rate, a second part of this adds ground floor retail by policy for tall buildings in order to create retail where people live Tweaks to get more reasonable results A setting which allows a user to disable building a more dense buiding that currently exists in a taz (used when we don't trust zoning much) - we minimize the max_dua or far on each parcel with the max built_dua or far near to that parcel For lack of better land price data, we use land prices proportional to the prevailing price per sqft Add (large) factors to land which is industrial to account for expensive land preparation Price shifters and cost shifters Rules to not consider certain parcels for development, like parcels which contain historical buildings, or have single family homes on small lots Accounts system and subsidies for affordable housing \"Lump sump accounts\" which are regional accounts that get a certain subsidy per year and are used to subsidize development in parcels that pass a certain filter and can create affordable housing or not Inclusionary housing rates which decrease revenues by a certain amount based on the AMI in an area and the inclusionary rate in an area - inclusionary housing rates get set by city Other policies which modify revenue as a percent of profit Impact fees which impose a cost per unit or per sqft Subsidized development on both the residential and office sides (not on retail?) Ad hoc \"land value tax\" revenue adjustment Output summaries, analysis and visualization Create a topsheet which does very basic one line summaries of a number of different outcomes - write as a text file to Slack so it can be read and reviewed from mobile Geographic summaries of households, jobs, and buildings for each 5 year increment, for superdistrict, pda, and juris geographies Write out disaggregate parcel and building data for visualization with ESRI A utility to compare output summary tables and put them in separate tabs of a workbook and color-code large differences Back into some demographic variables needed by the travel model that aren't produced by our UrbanSim model, including age categories, employed residents (by household location), population (we do households) some legacy land use variables from the previous model The travel model output which summarized some basic variables by zone Write out account information (subsididies and fees) Do urbanfootprint accounting - whether development is inside or outside the \"UGB\" Some extra diagnostic accounting including simple capacity calculations, simulated vacancy rates (for debugging, not as a sim output), sqft by building type Compare household and job counts to abag targets at the pda and juris levels","title":"Model Overview"},{"location":"model_overview/#model-overview","text":"","title":"Model Overview"},{"location":"model_overview/#approach","text":"A forecast with BAUS begins with a basemap. This is a detailed geodatabase containing all of the region\u2019s buildings, households, employees, policies, and transport network for a recent year. This roughly corresponds to tooday\u2019s conditions but is a few years in the past due to data collection lag and formalities related to the modeling framework. The buildings are largely an accurate collection of every structure gathered from assessor\u2019s data, commercial read estate databases, and other sources. The households and employees are represented at the micro level but their characteristics are built through synthesis (i.e., we only have samples of this informations so we build a full representation that is consistent with these samples). Policies such as zoning and growth limits are collected for each jurisdiction and are binding unless they are explicitly changed for a forecast. BAUS is used to forecast the future by advancing through repeated steps that chart out a potential pathway for future urban growth. In BAUS each step represents a five year period. Most steps repeat the same set of sub-steps. In UrbanSim, each of these sub-steps is called a \u201cmodel\u201d. The file used to run BAUS (baus.py) sets the number steps and the order in which the models are are run. The major types of model steps are: (Hazards): This optional model simulates the impact of earthquakes and sea level rise by destroying buildings and displacing their inhabitants. Calculate accessibility: Logsum accessibility measures are brought in from the Travel Model and pedestrian accessibility is calculated within UrbanSim Calculate housing prices and rents: Hedonic regression models are applied to current (to the model time step) conditions to reestimate current prices and rents HH/employee relcation and transition: Some households and employeees are selected to move; additiional households and employees are added or subtracted to reflect the exogenous control totals Add buildings from the Development Projects list: Buildings are forced into the model (as opposed to being explicitly modeled); these represent institutional plans (e.g., universities and hospitals), large approved projects (e.g., Treasure Island), and development that has occurred between the basemap year and the current year (i.e., constructed 2016-2020). Build new market-rate housing units and commercial space: The for-profit real estate development process is simulated and new buildings are built where they are most feasible; this also build deed-restricted unit that are produced through the market-rate process (e.g., inclusionary zoning). Build new deed-restricted affordable units: A similar not-for-profit real estate development process produces affordable housing units based on money available within BAUS Accounts (e.g., bond measures). HH/employee location choices: Households and employees are assigned to new locations based on logistic regresssion models that capture the preferences of particular segments (e.g., lower income households, retail jobs). Produce summary tables: Numerous zonal summaries of the detailed geodatabaase are produced for analysis of urban change and for use in the Travel Model; this step includes additional post-processing to get the data ready for the Travel Model\u2019s population synthesizer.","title":"Approach"},{"location":"model_overview/#sub-models","text":"Typically, a set of BAUS inputs or assumptions are modified to produce a scenario. Policies such as zoning or fees can be modified. Control totals can be adjusted. Assumptions about preferences or financical situations can be adjusted. The package of changes is then simulated to forecast its impact on the future urban landscape and these outcomes are often enterered into the travel model to predict future year travel patterns and greenhouse gas emmissions.","title":"Sub-Models"},{"location":"model_overview/#application-types","text":"BAUS is used for for three typical types of application: Forecasting: UrbanSim produces a complete map for each five year interval into the future. This information is required by statute and useful for planning processes. Policy Studies: BAUS can evaluate the impact of policy changes on, for example, the amount of housing produced, the amount of deed-restricted housing producded, and the locations of future residential or commercial development. Transport Project Evaluation: BAUS provides information on future land use patterns used to evaluate the benefits and costs of large transport infrastructure investments and allows an assessment of how such projects may influence future development.","title":"Application Types"},{"location":"model_overview/#model-system","text":"BAUS is the middle model in an interactive suite of three model systems maintained by MTC: Regional economic and demographic information is supplied to BAUS from the REMI CGE model and related demographic processing scripts. BAUS outputs on housing production are used to adjust regional housing prices (and thus other variables) in REMI. Accessibillity information is supplied to BAUS from the Travel Model and influences real estate prices and household and employee location choices. BAUS outputs on the location of various types of households and employees are used to establish origins and destinations in the Travel Model.","title":"Model System"},{"location":"model_overview/#an-overview-of-bauspy","text":"baus.py is a command line interface (cli) used to run Bay Area UrbanSim in various modes. These modes currently include: estimation, which runs a series of models to save parameter estimates for all statistical models simulation, which runs all models to create a simulated regional growth forecast fetch_data, which downloads large data files from Amazon S3 as inputs for BAUS preprocessing, which performas long-running data cleaning steps and writes newly cleaned data back to the binary h5 file for use in the other steps baseyearsim which runs a \"base year simulation\" which summarizes the data before the simulation runs (during simulation, summaries are written after each year, so the first year's summaries are after the base year is finished - a base year simulation writes the summaries before any models have run)","title":"An overview of baus.py"},{"location":"model_overview/#urban-analytics-lab-ual-improvements","text":"","title":"Urban Analytics Lab (UAL) Improvements"},{"location":"model_overview/#data-schemas","text":"Builds out the representation of individual housing units to include a semi-persistent tenure status, which is assigned based on characteristics of initial unit occupants Joins additional race/ethnicity PUMS variables to synthetic households [NB: currently missing from the reconciled model, but will be re-added] Adds a representation of market rents alongside market sale prices","title":"Data schemas"},{"location":"model_overview/#model-steps","text":"Residential hedonics predict market rents and sale prices separately, with rents estimated from Craigslist listings Household move-out choice is conditional on tenure status Household location choice is modeled separately for renters and owners, and includes race/ethnicity measures as explanatory variables Developer models are updated to produce both rental and ownership housing stock Notebooks, work history, code samples, etc are kept in a separate bayarea_urbansim_work repository.","title":"Model steps"},{"location":"model_overview/#current-status-august-2016","text":"All of the UAL alterations have been refactored as modular orca steps This code is contained in baus/ual.py , configs/ual_settings.yaml and individual yaml files as needed for regression models that have been re-estimated There are no changes to urbansim , urbansim_defaults , or MTC's orca initialization and model steps MTC and UAL model steps can be mixed and matched by passing different lists to orca; see run.py for examples The UAL model steps document and test for required data characteristics, using the orca_test library","title":"Current status (August 2016)"},{"location":"model_overview/#outputs-from-simulation-written-to-the-runs-directory","text":"ALL OUTPUT IN THIS DIRECTORY IS NOT OFFICIAL OUTPUT. PLEASE CONTACT MTC FOR OFFICIAL OUTPUTS OF THE LAST PLAN BAY AREA. [num] = a positive integer used to identify each successive run. This number usually starts at 1 and increments each time baus.py is called. Many files are output to the runs/ directory. They are described below. filename description run[num]_topsheet_[year].csv An overall summary of various housing and employment outcomes summarized by very coarse geographies. run[num]_parcel_output.csv A csv of all new built space in the region, not including ADUs added to existing buildings. This has a few thousand rows and dozens of columns which contain various inputs and outputs, as well as debugging information which helps explain why each development was picked by UrbanSim. run[num]_parcel_data_[year].csv A CSV with parcel level output for all parcels with lat, lng and includes change in total_residential_units and change in total_job_spaces, as well as zoned capacity measures. run[num]_building_data_[year].csv The same as above but for buildings. run[num]_taz_summaries_[year].csv A CSV for input to the MTC travel model run[num]_pda_summaries_[year].csv, run[num]_juris_summaries_[year].csv, run[num]_superdistrict_summaries_[year].csv Similar outputs to the taz summaries but for each of these geographies. Used for understanding the UrbanSim forecast at an aggregate level. run[num]_acctlog_[account name]_[year].csv A series of CSVs of each account's funding amount and buildings developed under this acount (if the funding is used to subsidize development) in each iteration. run[runnum]_dropped_buildings.csv A summary of buildings which were redeveloped during the simulated forecast. run[runnum]_simulation_output.json Used by the web output viewer.","title":"Outputs from Simulation (written to the runs directory)"},{"location":"model_overview/#directory-structure","text":"baus/ contains all the Python code which runs the BAUS model. data/ contains BAUS inputs which are small enough to store and render in GitHub (large files are stored on Amazon S3) - this also contains lots of scenario inputs in the form of csv files. See the readme in the data directory for detailed docs on each file. configs/ contains the model configuration files used by UrbanSim. This also contains settings.yaml which provides simulation inputs and settings in a non-tabular form. scripts/ these are one-off scripts which are used to perform various input munging and output analysis tasks. See the docs in that directory for more information.","title":"Directory structure"},{"location":"model_overview/#a-list-of-features-available-in-baus","text":"","title":"A list of features available in BAUS"},{"location":"model_overview/#data-management","text":"Add manual_edits.csv to edit individual attributes for each building/parcel in the building and parcel tables An orca step to correct the baseyear vacancies on the job side which happens pre-simulation Do job assignment by starting with baseyear controls and assigning on the fly (should do the same for households) Randomly assign deed restricted units within a zone because that's the most specific data would could get","title":"Data management"},{"location":"model_overview/#run-management","text":"Ability to run different model sets, output to Slack and web maps (in baus.py)","title":"Run management"},{"location":"model_overview/#standard-or-extensions-to-urbansim-features","text":"Houshold and job control totals by year Standard UrbanSim models - hedonic, location choice, transition, relocation models Basic supply and demand interactions to raise prices where demand exceeds supply Separate low and high income hlcms for the deed restricted units 1300 lines of computed columns to support the functionality described above","title":"Standard (or extensions to) UrbanSim features"},{"location":"model_overview/#accessibility-variables","text":"Accessibility variables including special \"distance to location\" variables Both local (local street network from OSM) and regional (travel model network) networks Network aggregations for prices as well","title":"Accessibility variables"},{"location":"model_overview/#human-input-and-overrides-for-specific-models","text":"Do parcel-by-parcel rejections based on human knowledge to override the model Quite a bit of support by year and by scenario for custom development projects, as well as add vs demolish settings Proportional job model on \"static parcels\". Static parcels are parcels whose jobs do not enter the relocation model and are auto-marked nodev. These are e.g. city hall and Berkeley which would never get newly created by the model Relocation rates by taz","title":"Human input and overrides for specific models"},{"location":"model_overview/#developer-model","text":"Provide baseline zoning using parcel to zoning lookups and then attributes for all the zones in the region (num zones << num parcels) Do conditional upzoning and downzoning, add and remove building types, all by policy zone Limits - assign all parcels to a \"bucket\" - in this case to a city, but it could be a pda-city intersection. Limits the amount of res and non-res development that comes from each bucket. Make sure to do so for all non-res types. A special retail model which takes into account where demand for retail is high (income x households) but supply is low We still need a better way to determine the uses that get built between office / retail / industrial / whatever else A reprocessing of the developer results which adds job spaces to residential buildings at an appropriate rate, a second part of this adds ground floor retail by policy for tall buildings in order to create retail where people live","title":"Developer model"},{"location":"model_overview/#tweaks-to-get-more-reasonable-results","text":"A setting which allows a user to disable building a more dense buiding that currently exists in a taz (used when we don't trust zoning much) - we minimize the max_dua or far on each parcel with the max built_dua or far near to that parcel For lack of better land price data, we use land prices proportional to the prevailing price per sqft Add (large) factors to land which is industrial to account for expensive land preparation Price shifters and cost shifters Rules to not consider certain parcels for development, like parcels which contain historical buildings, or have single family homes on small lots","title":"Tweaks to get more reasonable results"},{"location":"model_overview/#accounts-system-and-subsidies-for-affordable-housing","text":"\"Lump sump accounts\" which are regional accounts that get a certain subsidy per year and are used to subsidize development in parcels that pass a certain filter and can create affordable housing or not Inclusionary housing rates which decrease revenues by a certain amount based on the AMI in an area and the inclusionary rate in an area - inclusionary housing rates get set by city Other policies which modify revenue as a percent of profit Impact fees which impose a cost per unit or per sqft Subsidized development on both the residential and office sides (not on retail?) Ad hoc \"land value tax\" revenue adjustment","title":"Accounts system and subsidies for affordable housing"},{"location":"model_overview/#output-summaries-analysis-and-visualization","text":"Create a topsheet which does very basic one line summaries of a number of different outcomes - write as a text file to Slack so it can be read and reviewed from mobile Geographic summaries of households, jobs, and buildings for each 5 year increment, for superdistrict, pda, and juris geographies Write out disaggregate parcel and building data for visualization with ESRI A utility to compare output summary tables and put them in separate tabs of a workbook and color-code large differences Back into some demographic variables needed by the travel model that aren't produced by our UrbanSim model, including age categories, employed residents (by household location), population (we do households) some legacy land use variables from the previous model The travel model output which summarized some basic variables by zone Write out account information (subsididies and fees) Do urbanfootprint accounting - whether development is inside or outside the \"UGB\" Some extra diagnostic accounting including simple capacity calculations, simulated vacancy rates (for debugging, not as a sim output), sqft by building type Compare household and job counts to abag targets at the pda and juris levels","title":"Output summaries, analysis and visualization"},{"location":"models-reference/","text":"Models module baus.models elcm_simulate ( jobs , buildings , aggregations ) testing docstring documentation for automated documentation creation Source code in baus\\models.py 22 23 24 25 26 27 28 29 30 31 @orca . step () def elcm_simulate ( jobs , buildings , aggregations ): \"\"\" testing docstring documentation for automated documentation creation \"\"\" buildings . local [ \"non_residential_rent\" ] = \\ buildings . local . non_residential_rent . fillna ( 0 ) return utils . lcm_simulate ( \"location_choice/elcm.yaml\" , jobs , buildings , aggregations , \"building_id\" , \"job_spaces\" , \"vacant_job_spaces\" , cast = True ) neighborhood_vars ( net ) Applies pandana to create 226060 network nodes (focusing on pedestrian level), deviding the region into 226060 neighborhoods; key variables that reflect neighborhood characteristics (existing units, hh, income, jobs, etc.) are gathered from various tables (households, buildings, jobs) following certain rules defined in \"neighborhood_vars.yaml\", e.g. referencing radii (e.g. 1500, 3000), aggregation method (75%, average, median, etc.), filter (e.g. residential vs non-residential buildings). The pandana network is based on the base year OSM network from the H5 file. How pandana works: quickly moves along the network, uses the H5 file has openstreet esiting year network to run a mini-travel model (focusing on pedestrian level), get job conuts, etc. along the network. Source code in baus\\models.py 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 @orca . step () def neighborhood_vars ( net ): \"\"\" Applies pandana to create 226060 network nodes (focusing on pedestrian level), deviding the region into 226060 neighborhoods; key variables that reflect neighborhood characteristics (existing units, hh, income, jobs, etc.) are gathered from various tables (households, buildings, jobs) following certain rules defined in \"neighborhood_vars.yaml\", e.g. referencing radii (e.g. 1500, 3000), aggregation method (75%, average, median, etc.), filter (e.g. residential vs non-residential buildings). The pandana network is based on the base year OSM network from the H5 file. How pandana works: quickly moves along the network, uses the H5 file has openstreet esiting year network to run a mini-travel model (focusing on pedestrian level), get job conuts, etc. along the network. \"\"\" nodes = networks . from_yaml ( net [ \"walk\" ], \"accessibility/neighborhood_vars.yaml\" ) nodes = nodes . replace ( - np . inf , np . nan ) nodes = nodes . replace ( np . inf , np . nan ) nodes = nodes . fillna ( 0 ) print ( nodes . describe ()) orca . add_table ( \"nodes\" , nodes ) price_vars ( net ) Adds price variables to neighborhood_nodes, 4 new columns: 'residential', 'retail', 'office', 'industrial'. The 'residential' field feeds into \"parcel_sales_price_sqft_func\" to get an adjusted (the shifters) parcel-level residential price (average among all units on the same parcel): https://github.com/BayAreaMetro/bayarea_urbansim/blob/820554cbabee51725c445b9fd211542db8876c9f/baus/variables.py#L538 https://github.com/BayAreaMetro/bayarea_urbansim/blob/820554cbabee51725c445b9fd211542db8876c9f/baus/variables.py#L333. The adjusted residential price (\"parcel_sales_price_sqft_func\") then is applied in the feasibility model: https://github.com/BayAreaMetro/bayarea_urbansim/blob/900cfd8674be3569ae42cc0afb532ee12581188f/baus/models.py#L452, corresponding to the \"residential_sales_price_sqft\" column. Source code in baus\\models.py 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 @orca . step () def price_vars ( net ): \"\"\" Adds price variables to neighborhood_nodes, 4 new columns: 'residential', 'retail', 'office', 'industrial'. The 'residential' field feeds into \"parcel_sales_price_sqft_func\" to get an adjusted (the shifters) parcel-level residential price (average among all units on the same parcel): https://github.com/BayAreaMetro/bayarea_urbansim/blob/820554cbabee51725c445b9fd211542db8876c9f/baus/variables.py#L538 https://github.com/BayAreaMetro/bayarea_urbansim/blob/820554cbabee51725c445b9fd211542db8876c9f/baus/variables.py#L333. The adjusted residential price (\"parcel_sales_price_sqft_func\") then is applied in the feasibility model: https://github.com/BayAreaMetro/bayarea_urbansim/blob/900cfd8674be3569ae42cc0afb532ee12581188f/baus/models.py#L452, corresponding to the \"residential_sales_price_sqft\" column. \"\"\" nodes2 = networks . from_yaml ( net [ \"walk\" ], \"accessibility/price_vars.yaml\" ) nodes2 = nodes2 . fillna ( 0 ) print ( nodes2 . describe ()) nodes = orca . get_table ( 'nodes' ) nodes = nodes . to_frame () . join ( nodes2 ) orca . add_table ( \"nodes\" , nodes )","title":"models"},{"location":"models-reference/#models-module","text":"","title":"Models module"},{"location":"models-reference/#baus.models","text":"","title":"models"},{"location":"models-reference/#baus.models.elcm_simulate","text":"testing docstring documentation for automated documentation creation Source code in baus\\models.py 22 23 24 25 26 27 28 29 30 31 @orca . step () def elcm_simulate ( jobs , buildings , aggregations ): \"\"\" testing docstring documentation for automated documentation creation \"\"\" buildings . local [ \"non_residential_rent\" ] = \\ buildings . local . non_residential_rent . fillna ( 0 ) return utils . lcm_simulate ( \"location_choice/elcm.yaml\" , jobs , buildings , aggregations , \"building_id\" , \"job_spaces\" , \"vacant_job_spaces\" , cast = True )","title":"elcm_simulate()"},{"location":"models-reference/#baus.models.neighborhood_vars","text":"Applies pandana to create 226060 network nodes (focusing on pedestrian level), deviding the region into 226060 neighborhoods; key variables that reflect neighborhood characteristics (existing units, hh, income, jobs, etc.) are gathered from various tables (households, buildings, jobs) following certain rules defined in \"neighborhood_vars.yaml\", e.g. referencing radii (e.g. 1500, 3000), aggregation method (75%, average, median, etc.), filter (e.g. residential vs non-residential buildings). The pandana network is based on the base year OSM network from the H5 file. How pandana works: quickly moves along the network, uses the H5 file has openstreet esiting year network to run a mini-travel model (focusing on pedestrian level), get job conuts, etc. along the network. Source code in baus\\models.py 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 @orca . step () def neighborhood_vars ( net ): \"\"\" Applies pandana to create 226060 network nodes (focusing on pedestrian level), deviding the region into 226060 neighborhoods; key variables that reflect neighborhood characteristics (existing units, hh, income, jobs, etc.) are gathered from various tables (households, buildings, jobs) following certain rules defined in \"neighborhood_vars.yaml\", e.g. referencing radii (e.g. 1500, 3000), aggregation method (75%, average, median, etc.), filter (e.g. residential vs non-residential buildings). The pandana network is based on the base year OSM network from the H5 file. How pandana works: quickly moves along the network, uses the H5 file has openstreet esiting year network to run a mini-travel model (focusing on pedestrian level), get job conuts, etc. along the network. \"\"\" nodes = networks . from_yaml ( net [ \"walk\" ], \"accessibility/neighborhood_vars.yaml\" ) nodes = nodes . replace ( - np . inf , np . nan ) nodes = nodes . replace ( np . inf , np . nan ) nodes = nodes . fillna ( 0 ) print ( nodes . describe ()) orca . add_table ( \"nodes\" , nodes )","title":"neighborhood_vars()"},{"location":"models-reference/#baus.models.price_vars","text":"Adds price variables to neighborhood_nodes, 4 new columns: 'residential', 'retail', 'office', 'industrial'. The 'residential' field feeds into \"parcel_sales_price_sqft_func\" to get an adjusted (the shifters) parcel-level residential price (average among all units on the same parcel): https://github.com/BayAreaMetro/bayarea_urbansim/blob/820554cbabee51725c445b9fd211542db8876c9f/baus/variables.py#L538 https://github.com/BayAreaMetro/bayarea_urbansim/blob/820554cbabee51725c445b9fd211542db8876c9f/baus/variables.py#L333. The adjusted residential price (\"parcel_sales_price_sqft_func\") then is applied in the feasibility model: https://github.com/BayAreaMetro/bayarea_urbansim/blob/900cfd8674be3569ae42cc0afb532ee12581188f/baus/models.py#L452, corresponding to the \"residential_sales_price_sqft\" column. Source code in baus\\models.py 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 @orca . step () def price_vars ( net ): \"\"\" Adds price variables to neighborhood_nodes, 4 new columns: 'residential', 'retail', 'office', 'industrial'. The 'residential' field feeds into \"parcel_sales_price_sqft_func\" to get an adjusted (the shifters) parcel-level residential price (average among all units on the same parcel): https://github.com/BayAreaMetro/bayarea_urbansim/blob/820554cbabee51725c445b9fd211542db8876c9f/baus/variables.py#L538 https://github.com/BayAreaMetro/bayarea_urbansim/blob/820554cbabee51725c445b9fd211542db8876c9f/baus/variables.py#L333. The adjusted residential price (\"parcel_sales_price_sqft_func\") then is applied in the feasibility model: https://github.com/BayAreaMetro/bayarea_urbansim/blob/900cfd8674be3569ae42cc0afb532ee12581188f/baus/models.py#L452, corresponding to the \"residential_sales_price_sqft\" column. \"\"\" nodes2 = networks . from_yaml ( net [ \"walk\" ], \"accessibility/price_vars.yaml\" ) nodes2 = nodes2 . fillna ( 0 ) print ( nodes2 . describe ()) nodes = orca . get_table ( 'nodes' ) nodes = nodes . to_frame () . join ( nodes2 ) orca . add_table ( \"nodes\" , nodes )","title":"price_vars()"},{"location":"output/","text":"Outputs Core Outputs TBD Policy Outputs TBD For Travel Model TBD Diagnostic Outputs The tables below contains brief descriptions of the disgnostic output tables of BAUS. File name Purpose File type simulation_output.json Two sets of zone-level attributes: one set is the same as the standard Travel Model output, the other set is diagnostic attributes representing development capacity, pricing, logsum, vacancy, development type and quantity, etc., used to help analyze/debug submodels. JSON parcel_output.csv Parcel-level attributes of parcels with development activities during the simulation time period. CSV dropping_buildings.csv XXX CSV simulation_output.json zone-level diagnostic attributes: Attribute Description Data Type Source Sub-model/step gid XXX XXX XXX XXX tract XXX XXX XXX XXX area XXX XXX XXX XXX acres XXX XXX XXX XXX price_shifters XXX XXX XXX XXX unit_residential_price median residential price of all residential units in a TAZ float BAUS \"residential_units\" table rsh_simulate() unit_residential_rent median residential monthly rent of all residential units in a TAZ float BAUS \"residential_units\" table rrh_simulate() unit_residential_price_>_rent 1 or 0 representing if the TAZ-level per-unit residential price is higher than annualized rent divided by cap_rate . int BAUS \"residential_units\" table and \"developer_settings\" summary.py residential_price median per sq.ft. residential price of all residential buildings in a TAZ (based on general building type); currently used only for estimation, not for simulation float \"buildings\" table residential_price() retail_rent median non_residential_rent of all retail buildings in a TAZ float BAUS \"buildings\" table nrh_simulate() office_rent median non_residential_rent of all office buildings in a TAZ float BAUS \"buildings\" table nrh_simulate() industrial_rent median non_residential_rent of all industrial buildings in a TAZ float BAUS \"buildings\" table nrh_simulate() zone_cml zone-level mandatory accessibilities float Travel Model; BAUS \"zones\" table zone_cml() zone_cnml zone-level non-mandatory accessibilities float Travel Model; BAUS \"zones\" table zone_cnml() zone_combo_logsum zone-level total accessibilities float Travel Model; BAUS \"zones\" table zone_combo_logsum() zoned_du maximum number of dwelling units allowed on all parcels in a TAZ int BAUS \"parcels\" table zoned_du() zoned_du_underbuild additional dwelling units allowed on all parcels in a TAZ given existing development conditions, 0 if the additional units are not at least half of existing development int BAUS \"parcels\" table zoned_du_underbuild() zoned_du_underbuild_ratio ratio of additional allowable residential units to maximum allowable residential units int BAUS \"zones\" table zoned_du_build_ratio() building_count total number of residential buildings in a TAZ, based on general building type int BAUS \"buildings\" table XXX residential_units total number of residential units in a TAZ int BAUS \"buildings\" table XXX ave_unit_sqft 0.6 quantile of building-level average residential unit size of all builidings in a TAZ int BAUS \"building\" table ave_unit_sqft() residential_vacancy percentage of residential units in a TAZ that are not occupied by a household float BAUS \"households\" table, BAUS \"buildings\" table BAUS summary.py non_residential_sqft total sq.ft. of all non-residential buildings in a TAZ int BAUS \"buildings\" table XXX job_spaces total number of jobs that can be accommodated by non-residential space in a TAZ int BAUS \"building\" table; sq.ft. per job setting XXX non_residential_vacancy percentage of job_spaces in a TAZ that are not occupied by a job float BAUS \"jobs\" table, BAUS \"buildings\" table XXX retail_sqft total sq.ft. of all retail buildings in a TAZ int BAUS \"buildings\" table XXX retail_to_res_units_ratio ratio of total retail sq.ft. to total residential units in a TAZ int BAUS \"parcels\" table XXX office_sqft total sq.ft. of all office buildings in a TAZ int BAUS \"buildings\" table XXX industrial_sqft total sq.ft. of all industrial buildings in a TAZ int BAUS \"buildings\" table XXX household_size median household size of all households in a TAZ float BAUS \"households\" table; BAUS \"households_preproc\" table XXX average_income median income of all households in a TAZ int BAUS \"households\" table; BAUS \"households_preproc\" table summary.py ; MTC/ABAG household models? parcel_output.csv parcel-level attributes: Attribute Description Data Type Source Sub-model/step development_id XXX XXX XXX XXX SDEM XXX XXX XXX XXX building_type XXX XXX XXX XXX residential XXX XXX XXX XXX building_sqft XXX XXX XXX XXX non_residential_sqft XXX XXX XXX XXX job_spaces XXX XXX XXX XXX residential_sqft XXX XXX XXX XXX residential_units XXX XXX XXX XXX total_residential_units XXX XXX XXX XXX total_sqft XXX XXX XXX XXX source XXX XXX XXX XXX x XXX XXX XXX XXX y XXX XXX XXX XXX year_built XXX XXX XXX XXX dropping_buildings.csv building-level attributes: Attribute Description Data Type Source Sub-model/step XXX XXX XXX XXX XXX Interim table The tables below are interim data as input/output for sub-models. File name Purpose Output of Sub-model(s) Input of Sub-model(s) feasibility Parcel-level data on the development feasibilities of various development types given the zoning, development costs, and expected return. Only parcels where at least one development type is feasible is included. created by alt_feasibility(); modified by subsidized_residential_feasibility() and policy_modifications_of_profit() residential_developer(), office_developer(), retail_developer(), run_subsidized_developer(), subsidized_office_developer() parcel_output.csv Parcel-level attributes of parcels with development activities during the simulation time period. CSV dropping_buildings.csv XXX CSV fesibility attributes feasibility contains two sets of development variables grouped by six development types (coded as form ): retail , industrial , office , residential , mixedresidential , mixedoffice . For every development type, one set of variables are passed through from the parcels table as input for the feasibility evaluation; the other set of variables are the result of the feasibility evaluation. Attribute Description Data Type Source parcel_id Parcel index int oldest_building ? ? pass_through from input parcel frame total_sqft ? ? pass_through from input parcel frame total_residential_units ? ? pass_through from input parcel frame max_far int pass_through from input parcel frame max_dua int pass_through from input parcel frame land_cost int pass_through from input parcel frame residential pass_through from input parcel frame min_max_fars int pass_through from input parcel frame max_height int pass_through from input parcel frame building_purchase_price int pass_through from input parcel frame building_purchase_price_sqft pass_through from input parcel frame residential_sales_price_sqft https://app.asana.com/0/0/1201856230375726/f pass_through from input parcel frame pda_pba40 pass_through from input parcel frame pda_pba50 pass_through from input parcel frame trich_id str pass_through from input parcel frame cat_id pass_through from input parcel frame tra_id pass_through from input parcel frame ppa_id pass_through from input parcel frame sesit_id pass_through from input parcel frame coc_id pass_through from input parcel frame juris pass_through from input parcel frame county pass_through from input parcel frame superdistrict pass_through from input parcel frame geom_id pass_through from input parcel frame vmt_res_cat pass_through from input parcel frame vmt_nonres_cat pass_through from input parcel frame parking_config parking type, e.g. deck, surface string created by run_feasibility() building_sqft The number of square feet for the building to build. Keep in mind this includes parking and common space. Will need a helpful function to convert from gross square feet to actual usable square feet in residential units. float created by run_feasibility() building_cost The cost of constructing the building as given by the ave_cost_per_sqft from the cost model (for this FAR) and the number of square feet. float created by run_feasibility() parking_ratio ? ? ? stories ? ? ? total_cost The cost of constructing the building plus the cost of acquisition of the current parcel/building. float created by run_feasibility() building_revenue The NPV of the revenue for the building to be built, which is the number of square feet times the yearly rent divided by the cap rate (with a few adjustment factors including building efficiency). float created by run_feasibility() max_profit_far The FAR of the maximum profit building (constrained by the max_far and max_height from the input dataframe). float created by run_feasibility() max_profit The profit for the maximum profit building (constrained by the max_far and max_height from the input dataframe). float created by run_feasibility() residential_sqft float created by run_feasibility() non_residential_sqft float created by run_feasibility() fees created by run_feasibility() policy_based_revenue_reduction int created by run_feasibility() deed_restricted_units int created by run_feasibility() inclusionary_units int created by run_feasibility()","title":"Output"},{"location":"output/#outputs","text":"","title":"Outputs"},{"location":"output/#core-outputs","text":"TBD","title":"Core Outputs"},{"location":"output/#policy-outputs","text":"TBD","title":"Policy Outputs"},{"location":"output/#for-travel-model","text":"TBD","title":"For Travel Model"},{"location":"output/#diagnostic-outputs","text":"The tables below contains brief descriptions of the disgnostic output tables of BAUS. File name Purpose File type simulation_output.json Two sets of zone-level attributes: one set is the same as the standard Travel Model output, the other set is diagnostic attributes representing development capacity, pricing, logsum, vacancy, development type and quantity, etc., used to help analyze/debug submodels. JSON parcel_output.csv Parcel-level attributes of parcels with development activities during the simulation time period. CSV dropping_buildings.csv XXX CSV","title":"Diagnostic Outputs"},{"location":"output/#simulation_outputjson-zone-level-diagnostic-attributes","text":"Attribute Description Data Type Source Sub-model/step gid XXX XXX XXX XXX tract XXX XXX XXX XXX area XXX XXX XXX XXX acres XXX XXX XXX XXX price_shifters XXX XXX XXX XXX unit_residential_price median residential price of all residential units in a TAZ float BAUS \"residential_units\" table rsh_simulate() unit_residential_rent median residential monthly rent of all residential units in a TAZ float BAUS \"residential_units\" table rrh_simulate() unit_residential_price_>_rent 1 or 0 representing if the TAZ-level per-unit residential price is higher than annualized rent divided by cap_rate . int BAUS \"residential_units\" table and \"developer_settings\" summary.py residential_price median per sq.ft. residential price of all residential buildings in a TAZ (based on general building type); currently used only for estimation, not for simulation float \"buildings\" table residential_price() retail_rent median non_residential_rent of all retail buildings in a TAZ float BAUS \"buildings\" table nrh_simulate() office_rent median non_residential_rent of all office buildings in a TAZ float BAUS \"buildings\" table nrh_simulate() industrial_rent median non_residential_rent of all industrial buildings in a TAZ float BAUS \"buildings\" table nrh_simulate() zone_cml zone-level mandatory accessibilities float Travel Model; BAUS \"zones\" table zone_cml() zone_cnml zone-level non-mandatory accessibilities float Travel Model; BAUS \"zones\" table zone_cnml() zone_combo_logsum zone-level total accessibilities float Travel Model; BAUS \"zones\" table zone_combo_logsum() zoned_du maximum number of dwelling units allowed on all parcels in a TAZ int BAUS \"parcels\" table zoned_du() zoned_du_underbuild additional dwelling units allowed on all parcels in a TAZ given existing development conditions, 0 if the additional units are not at least half of existing development int BAUS \"parcels\" table zoned_du_underbuild() zoned_du_underbuild_ratio ratio of additional allowable residential units to maximum allowable residential units int BAUS \"zones\" table zoned_du_build_ratio() building_count total number of residential buildings in a TAZ, based on general building type int BAUS \"buildings\" table XXX residential_units total number of residential units in a TAZ int BAUS \"buildings\" table XXX ave_unit_sqft 0.6 quantile of building-level average residential unit size of all builidings in a TAZ int BAUS \"building\" table ave_unit_sqft() residential_vacancy percentage of residential units in a TAZ that are not occupied by a household float BAUS \"households\" table, BAUS \"buildings\" table BAUS summary.py non_residential_sqft total sq.ft. of all non-residential buildings in a TAZ int BAUS \"buildings\" table XXX job_spaces total number of jobs that can be accommodated by non-residential space in a TAZ int BAUS \"building\" table; sq.ft. per job setting XXX non_residential_vacancy percentage of job_spaces in a TAZ that are not occupied by a job float BAUS \"jobs\" table, BAUS \"buildings\" table XXX retail_sqft total sq.ft. of all retail buildings in a TAZ int BAUS \"buildings\" table XXX retail_to_res_units_ratio ratio of total retail sq.ft. to total residential units in a TAZ int BAUS \"parcels\" table XXX office_sqft total sq.ft. of all office buildings in a TAZ int BAUS \"buildings\" table XXX industrial_sqft total sq.ft. of all industrial buildings in a TAZ int BAUS \"buildings\" table XXX household_size median household size of all households in a TAZ float BAUS \"households\" table; BAUS \"households_preproc\" table XXX average_income median income of all households in a TAZ int BAUS \"households\" table; BAUS \"households_preproc\" table summary.py ; MTC/ABAG household models?","title":"simulation_output.json zone-level diagnostic attributes:"},{"location":"output/#parcel_outputcsv-parcel-level-attributes","text":"Attribute Description Data Type Source Sub-model/step development_id XXX XXX XXX XXX SDEM XXX XXX XXX XXX building_type XXX XXX XXX XXX residential XXX XXX XXX XXX building_sqft XXX XXX XXX XXX non_residential_sqft XXX XXX XXX XXX job_spaces XXX XXX XXX XXX residential_sqft XXX XXX XXX XXX residential_units XXX XXX XXX XXX total_residential_units XXX XXX XXX XXX total_sqft XXX XXX XXX XXX source XXX XXX XXX XXX x XXX XXX XXX XXX y XXX XXX XXX XXX year_built XXX XXX XXX XXX","title":"parcel_output.csv parcel-level attributes:"},{"location":"output/#dropping_buildingscsv-building-level-attributes","text":"Attribute Description Data Type Source Sub-model/step XXX XXX XXX XXX XXX","title":"dropping_buildings.csv building-level attributes:"},{"location":"output/#interim-table","text":"The tables below are interim data as input/output for sub-models. File name Purpose Output of Sub-model(s) Input of Sub-model(s) feasibility Parcel-level data on the development feasibilities of various development types given the zoning, development costs, and expected return. Only parcels where at least one development type is feasible is included. created by alt_feasibility(); modified by subsidized_residential_feasibility() and policy_modifications_of_profit() residential_developer(), office_developer(), retail_developer(), run_subsidized_developer(), subsidized_office_developer() parcel_output.csv Parcel-level attributes of parcels with development activities during the simulation time period. CSV dropping_buildings.csv XXX CSV","title":"Interim table"},{"location":"output/#fesibility-attributes","text":"feasibility contains two sets of development variables grouped by six development types (coded as form ): retail , industrial , office , residential , mixedresidential , mixedoffice . For every development type, one set of variables are passed through from the parcels table as input for the feasibility evaluation; the other set of variables are the result of the feasibility evaluation. Attribute Description Data Type Source parcel_id Parcel index int oldest_building ? ? pass_through from input parcel frame total_sqft ? ? pass_through from input parcel frame total_residential_units ? ? pass_through from input parcel frame max_far int pass_through from input parcel frame max_dua int pass_through from input parcel frame land_cost int pass_through from input parcel frame residential pass_through from input parcel frame min_max_fars int pass_through from input parcel frame max_height int pass_through from input parcel frame building_purchase_price int pass_through from input parcel frame building_purchase_price_sqft pass_through from input parcel frame residential_sales_price_sqft https://app.asana.com/0/0/1201856230375726/f pass_through from input parcel frame pda_pba40 pass_through from input parcel frame pda_pba50 pass_through from input parcel frame trich_id str pass_through from input parcel frame cat_id pass_through from input parcel frame tra_id pass_through from input parcel frame ppa_id pass_through from input parcel frame sesit_id pass_through from input parcel frame coc_id pass_through from input parcel frame juris pass_through from input parcel frame county pass_through from input parcel frame superdistrict pass_through from input parcel frame geom_id pass_through from input parcel frame vmt_res_cat pass_through from input parcel frame vmt_nonres_cat pass_through from input parcel frame parking_config parking type, e.g. deck, surface string created by run_feasibility() building_sqft The number of square feet for the building to build. Keep in mind this includes parking and common space. Will need a helpful function to convert from gross square feet to actual usable square feet in residential units. float created by run_feasibility() building_cost The cost of constructing the building as given by the ave_cost_per_sqft from the cost model (for this FAR) and the number of square feet. float created by run_feasibility() parking_ratio ? ? ? stories ? ? ? total_cost The cost of constructing the building plus the cost of acquisition of the current parcel/building. float created by run_feasibility() building_revenue The NPV of the revenue for the building to be built, which is the number of square feet times the yearly rent divided by the cap rate (with a few adjustment factors including building efficiency). float created by run_feasibility() max_profit_far The FAR of the maximum profit building (constrained by the max_far and max_height from the input dataframe). float created by run_feasibility() max_profit The profit for the maximum profit building (constrained by the max_far and max_height from the input dataframe). float created by run_feasibility() residential_sqft float created by run_feasibility() non_residential_sqft float created by run_feasibility() fees created by run_feasibility() policy_based_revenue_reduction int created by run_feasibility() deed_restricted_units int created by run_feasibility() inclusionary_units int created by run_feasibility()","title":"fesibility attributes"},{"location":"pba50/","text":"Plan Bay Area 2050 Background: Plan Bay Area 2050 project website Scenarios S21: Blueprint Basic This is the \"base\" scenario in the sense that we are doing it first and the others build off of it Uses s21 control total files Uses Blueprint Basic logsums Uses s21 zoning modifications: major upzoning in all growth geogs Has almost all strategies in s20: Baseline for PBA50 This is the \"baseline\" scenario in the sense that it doesn't have any pba50 changes and so it also has far lower control totals Uses s20 control total files (these are minus the additional units built bc of housing policy in pba50) Uses Baseline logsums (somewhat less congestion than others?) Uses s20 zoning modifications: these are minimal in that the do typical No Project treatment (UGB, upzoning within) but may also need UGB expansion to fit control totals Has no new strategies from PBA50 s22: Blueprint Plus Fix It First This is the higher funding scenario Uses s22 control total files Uses Blueprint Plus Fix It First logsums (very similar to s21 logsums) Uses s22 zoning modifications: same as s21 Adds/modifies these strategies (working off of s210: adds incubator strategy increases size of affordable housing fund more slr protection s23: Blueprint Plus Crossing This is the higher funding scenario plus the New Transbay Crossing Uses s23 control total files Uses Blueprint Plus Crossing logsums (moderately different from other scenarios) Uses s23 zoning modifications: slightly higher upzoning than s21 and s22 at a few new/upgraded stations Same strategies as s22 s24: Final Blueprint Builds off of s23 Includes both error correction and policy modifications Strategy Coding Technical Notes Deed-Restricted Units notes Deed-restricted units can now come from many sources. As of Final Blueprint, those sources are: DR = base year DR + pipeline DR + public lands (added via pipeline) + subsidized (production) + preserved + inclusionary Pipeline units cannot be redeveloped, other deed-restricted units can if or when the building is more than 20 years old. In the household location choice models, only Q1 households can enter DR units. However, if the model can't find enough Q1 households for the DR units (due to modeling reasons or over-supply) non-Q1 households are able to enter. Affordable Housing Fund- Preservation (Final Blueprint) Selects buildings to spend preservation funding on, by marking them as deed restricted units. The selection is not tied to price, and housing cost is calculated off model. The buildings are randomly selected based on the total number of buildings to preserve within a geography which are set here . The \"deed restricted\" column is updated in the residential units table, which is used to filter units in the household location choice models and assign Q1 households to deed restricted units. The \"deed restricted units\" and \"preserved units\" columns are updated in the buildings table. These occur here . In some cases, a Q1 household will already occupy a newly preserved unit. If that household moves, only another Q1 will be able to move in. In other cases, a non-Q1 household will occupy a newly preserved unit, and a Q1 household is only able to enter if and when that household moves out. Inclusionary Zoning (Draft Blueprint, Final Blueprint) Inclusionary zoning requirement (x% of new housing development have to be affordable) is set in policy.yalm . The default setting represents the existing requirements without plan strategy interventions. Plan strategies are organized by scenario, with a scenario handler at the top. Inclusionary rate is set at certain geographic level: PBA40 and Horizon: inclusionary percentage by jurisdiction . Draft Blueprint: inclusionary percentage by pba50chcat (i.e. the combination of several growth geography strategies, GG, TRA, PPA, etc.). Final Blueprint: inclusionary percentage by fbpchcat . Coding notes: datasources.py reads inclusionary strategy input and maps it to parcels using the corresponding field: PBA40 and Horizon uses 'jurisdiction' , Draft Blueprint uses 'pba50chcat' , Final Blueprint uses 'fbpchcat'. In subsidies.py , the inclusionary_housing_revenue_reduction function calculates median household AMI , feasible new affordable housing count and revenue_reduction amount of each inclusionary geography. In PBA40 and Horizon, these calculations were conducted at the jurisdiction level. PBA50 uses strategy geographies instead - 'pba50chcat' in Draft Blueprint and 'fbpchcat' in Final Blueprint. The inclusionary statements in summaries.py should be consistent with the inclusionary geography of each plan scenario. Reduce cost for housing development (Draft Blueprint, Final Blueprint) One way to (indirectly) subsidize housing is to reduce housing development cost reduction, for example, SB743 CEQA reform, lowering parking requirements, etc. This is defined in profitability_adjustment_policies . The policies are scenario-based, as noted by \"enable_in_scenarios\". For each policy, profitabiity_adjustment_formula picks the parcels in a certain category (e.g. a certain type of geography) and then decreases the required profitability level needed for the model to build on those parcels, e.g. multiplying by 2.5% or 0.025 means to LOWER the required profit level by 2.5%. When a policy has an alternative version is different scenarios, may use 'alternative_geography_scenarios' and 'alternative_adjustment_formula' to consolidate the scenarios. \"Summaries.py\" summaries these policies. Affordable Housing Fund Lump-sum Account (Draft Blueprint, Final Blueprint) Lump-sum accounts represent direct housing subsidies. Each county has a lump-sum account to hold all the available affordable housing funding for that county. BAUS assumes a constant annual funding amount (an independent input) , for each county during the plan period, doesn't consider inflation or fluctuations in funding availability over time. In each simulation iteration, funding available in each county's account equals the annual amount multiplies by years per iteration (5 years in BAUS) . Residential development projects that are not feasible under market conditions are potentially qualified for subsidy. Final Blueprint requires the projects to be also located within the Growth Geography. A qualified project draws money from the corresponding account to fill the feasibility gap. Not all qualified projects will be subsidized. Lum-sum accounts are scenario-based , having scenario-specific fund amount and project qualification criteria. Coding notes: Set up the account in policy.yaml Calculate each account's subsidy amount for each iteration and add it to coffer Set up the filter in run_subsidized_developer() Update the config in 'summaries.py' Check subsidized_residential_developer_lump_sum_accts() and make sure it is included in the model list in baus.py VMT Fees / Transportation Impact Fees (Draft Blueprint) Apply fees on new commercial or residential development that reflects transportation impacts associated with such development, focusing primarily on new commercial spaces or residential units anticipated to have high employment-related or residence-related vehicle miles traveled (VMT). The fees could be set at county, jurisdiction, or TAZ level, usually on a $/sqft basis for commercial development and $/unit basis for residential development. Draft Blueprint applies VMT on new office development based on the county and associated VMT per worker associated with the TAZ to incentivize development inside low-VMT job centers. This diagram illustrates the modeling steps in BAUS: BAUS has three types of VMT fees - \"com_for_res\" (apply fees on commercial development to subsidize residential development), \"res_for_res\" (apply fees on residential development to subsidize residential development), and \"com_for_com\" (apply fees on commercial development to subsidize commercial development). Each parcel is assigned a \"vmt_res_cat\" value and a \"vmt_nonres_cat\" value based on its categorized VMT-level. This is then mapped to the fee table to decide the fee amount for new residential and commercial development on the parcel. During each model iteration period (currently five years), VMT fees collected from new development go into one of the two accounts - \"vmt_res_acct\" and \"vmt_com_acct\" - for each geography (regional or sub-regional). Policies that aim to support/incentivize certain types of housing development or commercial activities can draw funding from respective account. In Draft Blueprint , VMT fees revenue is not applied into any job/housing incentive, but is accumulated to help to understand how much revenue is raised to support other economy strategies. Jobs-housing Balance Fee (Draft Blueprint) Apply a regional jobs-housing linkage fee to generate funding for affordable housing when new office development occurs in job-rich places, thereby incentivizing more jobs to locate in housing-rich places. The $/sqft fee assigned to each jurisdiction is a composite fee based on the jobs-housing ratio and jobs-housing fit for both cities and counties. Modeling jobs-housing fee in BAUS: Jobs-housing fee is tracked in BAUS under the \"jobs_housing_com_for_res\" account at the county level , which is similar to the \"com_for_res\" account of the VMT strategy. In each model interation period, jobs-housing fees applies to new office development in each county based on the $/sqft level of jurisdiction where the development occurs. The fees collected goes to each county's account. The account then acts similarly to the county-level lump-sum account to subsidize affordable housing in that county. Office Lump Sum Account (Final Blueprint) Similar to the residential funding lump sum account, office lump sum account provides funding to subsidize office development in targeted areas.","title":"PBA50"},{"location":"pba50/#plan-bay-area-2050","text":"Background: Plan Bay Area 2050 project website","title":"Plan Bay Area 2050"},{"location":"pba50/#scenarios","text":"","title":"Scenarios"},{"location":"pba50/#s21-blueprint-basic","text":"This is the \"base\" scenario in the sense that we are doing it first and the others build off of it Uses s21 control total files Uses Blueprint Basic logsums Uses s21 zoning modifications: major upzoning in all growth geogs Has almost all strategies in","title":"S21: Blueprint Basic"},{"location":"pba50/#s20-baseline-for-pba50","text":"This is the \"baseline\" scenario in the sense that it doesn't have any pba50 changes and so it also has far lower control totals Uses s20 control total files (these are minus the additional units built bc of housing policy in pba50) Uses Baseline logsums (somewhat less congestion than others?) Uses s20 zoning modifications: these are minimal in that the do typical No Project treatment (UGB, upzoning within) but may also need UGB expansion to fit control totals Has no new strategies from PBA50","title":"s20: Baseline for PBA50"},{"location":"pba50/#s22-blueprint-plus-fix-it-first","text":"This is the higher funding scenario Uses s22 control total files Uses Blueprint Plus Fix It First logsums (very similar to s21 logsums) Uses s22 zoning modifications: same as s21 Adds/modifies these strategies (working off of s210: adds incubator strategy increases size of affordable housing fund more slr protection","title":"s22: Blueprint Plus Fix It First"},{"location":"pba50/#s23-blueprint-plus-crossing","text":"This is the higher funding scenario plus the New Transbay Crossing Uses s23 control total files Uses Blueprint Plus Crossing logsums (moderately different from other scenarios) Uses s23 zoning modifications: slightly higher upzoning than s21 and s22 at a few new/upgraded stations Same strategies as s22","title":"s23: Blueprint Plus Crossing"},{"location":"pba50/#s24-final-blueprint","text":"Builds off of s23 Includes both error correction and policy modifications","title":"s24: Final Blueprint"},{"location":"pba50/#strategy-coding-technical-notes","text":"","title":"Strategy Coding Technical Notes"},{"location":"pba50/#deed-restricted-units-notes","text":"Deed-restricted units can now come from many sources. As of Final Blueprint, those sources are: DR = base year DR + pipeline DR + public lands (added via pipeline) + subsidized (production) + preserved + inclusionary Pipeline units cannot be redeveloped, other deed-restricted units can if or when the building is more than 20 years old. In the household location choice models, only Q1 households can enter DR units. However, if the model can't find enough Q1 households for the DR units (due to modeling reasons or over-supply) non-Q1 households are able to enter.","title":"Deed-Restricted Units notes"},{"location":"pba50/#affordable-housing-fund-preservation-final-blueprint","text":"Selects buildings to spend preservation funding on, by marking them as deed restricted units. The selection is not tied to price, and housing cost is calculated off model. The buildings are randomly selected based on the total number of buildings to preserve within a geography which are set here . The \"deed restricted\" column is updated in the residential units table, which is used to filter units in the household location choice models and assign Q1 households to deed restricted units. The \"deed restricted units\" and \"preserved units\" columns are updated in the buildings table. These occur here . In some cases, a Q1 household will already occupy a newly preserved unit. If that household moves, only another Q1 will be able to move in. In other cases, a non-Q1 household will occupy a newly preserved unit, and a Q1 household is only able to enter if and when that household moves out.","title":"Affordable Housing Fund- Preservation (Final Blueprint)"},{"location":"pba50/#inclusionary-zoning-draft-blueprint-final-blueprint","text":"Inclusionary zoning requirement (x% of new housing development have to be affordable) is set in policy.yalm . The default setting represents the existing requirements without plan strategy interventions. Plan strategies are organized by scenario, with a scenario handler at the top. Inclusionary rate is set at certain geographic level: PBA40 and Horizon: inclusionary percentage by jurisdiction . Draft Blueprint: inclusionary percentage by pba50chcat (i.e. the combination of several growth geography strategies, GG, TRA, PPA, etc.). Final Blueprint: inclusionary percentage by fbpchcat . Coding notes: datasources.py reads inclusionary strategy input and maps it to parcels using the corresponding field: PBA40 and Horizon uses 'jurisdiction' , Draft Blueprint uses 'pba50chcat' , Final Blueprint uses 'fbpchcat'. In subsidies.py , the inclusionary_housing_revenue_reduction function calculates median household AMI , feasible new affordable housing count and revenue_reduction amount of each inclusionary geography. In PBA40 and Horizon, these calculations were conducted at the jurisdiction level. PBA50 uses strategy geographies instead - 'pba50chcat' in Draft Blueprint and 'fbpchcat' in Final Blueprint. The inclusionary statements in summaries.py should be consistent with the inclusionary geography of each plan scenario.","title":"Inclusionary Zoning (Draft Blueprint, Final Blueprint)"},{"location":"pba50/#reduce-cost-for-housing-development-draft-blueprint-final-blueprint","text":"One way to (indirectly) subsidize housing is to reduce housing development cost reduction, for example, SB743 CEQA reform, lowering parking requirements, etc. This is defined in profitability_adjustment_policies . The policies are scenario-based, as noted by \"enable_in_scenarios\". For each policy, profitabiity_adjustment_formula picks the parcels in a certain category (e.g. a certain type of geography) and then decreases the required profitability level needed for the model to build on those parcels, e.g. multiplying by 2.5% or 0.025 means to LOWER the required profit level by 2.5%. When a policy has an alternative version is different scenarios, may use 'alternative_geography_scenarios' and 'alternative_adjustment_formula' to consolidate the scenarios. \"Summaries.py\" summaries these policies.","title":"Reduce cost for housing development (Draft Blueprint, Final Blueprint)"},{"location":"pba50/#affordable-housing-fund-lump-sum-account-draft-blueprint-final-blueprint","text":"Lump-sum accounts represent direct housing subsidies. Each county has a lump-sum account to hold all the available affordable housing funding for that county. BAUS assumes a constant annual funding amount (an independent input) , for each county during the plan period, doesn't consider inflation or fluctuations in funding availability over time. In each simulation iteration, funding available in each county's account equals the annual amount multiplies by years per iteration (5 years in BAUS) . Residential development projects that are not feasible under market conditions are potentially qualified for subsidy. Final Blueprint requires the projects to be also located within the Growth Geography. A qualified project draws money from the corresponding account to fill the feasibility gap. Not all qualified projects will be subsidized. Lum-sum accounts are scenario-based , having scenario-specific fund amount and project qualification criteria. Coding notes: Set up the account in policy.yaml Calculate each account's subsidy amount for each iteration and add it to coffer Set up the filter in run_subsidized_developer() Update the config in 'summaries.py' Check subsidized_residential_developer_lump_sum_accts() and make sure it is included in the model list in baus.py","title":"Affordable Housing Fund Lump-sum Account (Draft Blueprint, Final Blueprint)"},{"location":"pba50/#vmt-fees-transportation-impact-fees-draft-blueprint","text":"Apply fees on new commercial or residential development that reflects transportation impacts associated with such development, focusing primarily on new commercial spaces or residential units anticipated to have high employment-related or residence-related vehicle miles traveled (VMT). The fees could be set at county, jurisdiction, or TAZ level, usually on a $/sqft basis for commercial development and $/unit basis for residential development. Draft Blueprint applies VMT on new office development based on the county and associated VMT per worker associated with the TAZ to incentivize development inside low-VMT job centers. This diagram illustrates the modeling steps in BAUS: BAUS has three types of VMT fees - \"com_for_res\" (apply fees on commercial development to subsidize residential development), \"res_for_res\" (apply fees on residential development to subsidize residential development), and \"com_for_com\" (apply fees on commercial development to subsidize commercial development). Each parcel is assigned a \"vmt_res_cat\" value and a \"vmt_nonres_cat\" value based on its categorized VMT-level. This is then mapped to the fee table to decide the fee amount for new residential and commercial development on the parcel. During each model iteration period (currently five years), VMT fees collected from new development go into one of the two accounts - \"vmt_res_acct\" and \"vmt_com_acct\" - for each geography (regional or sub-regional). Policies that aim to support/incentivize certain types of housing development or commercial activities can draw funding from respective account. In Draft Blueprint , VMT fees revenue is not applied into any job/housing incentive, but is accumulated to help to understand how much revenue is raised to support other economy strategies.","title":"VMT Fees / Transportation Impact Fees (Draft Blueprint)"},{"location":"pba50/#jobs-housing-balance-fee-draft-blueprint","text":"Apply a regional jobs-housing linkage fee to generate funding for affordable housing when new office development occurs in job-rich places, thereby incentivizing more jobs to locate in housing-rich places. The $/sqft fee assigned to each jurisdiction is a composite fee based on the jobs-housing ratio and jobs-housing fit for both cities and counties. Modeling jobs-housing fee in BAUS: Jobs-housing fee is tracked in BAUS under the \"jobs_housing_com_for_res\" account at the county level , which is similar to the \"com_for_res\" account of the VMT strategy. In each model interation period, jobs-housing fees applies to new office development in each county based on the $/sqft level of jurisdiction where the development occurs. The fees collected goes to each county's account. The account then acts similarly to the county-level lump-sum account to subsidize affordable housing in that county.","title":"Jobs-housing Balance Fee (Draft Blueprint)"},{"location":"pba50/#office-lump-sum-account-final-blueprint","text":"Similar to the residential funding lump sum account, office lump sum account provides funding to subsidize office development in targeted areas.","title":"Office Lump Sum Account (Final Blueprint)"},{"location":"subsidies-reference/","text":"Subsidies module baus.subsidies run_subsidized_developer ( feasibility , parcels , buildings , households , acct_settings , developer_settings , account , year , form_to_btype_func , add_extra_columns_func , summary , create_deed_restricted = False , policy_name = 'Unnamed' ) The subsidized residential developer model. Parameters DataFrame A DataFrame that is returned from run_feasibility for a given form DataFrameWrapper The standard parcels DataFrameWrapper (mostly just for run_developer) DataFrameWrapper The standard buildings DataFrameWrapper (passed to run_developer) DataFrameWrapper The households DataFrameWrapper (passed to run_developer) Dict A dictionary of settings to parameterize the model. Needs these keys: sending_buildings_subaccount_def - maps buildings to subaccounts receiving_buildings_filter - filter for eligible buildings Dict The overall settings Account The Account object to use for subsidization int The current simulation year (will be added as metadata) function Passed through to run_developer function Passed through to run_developer Summary Used to add parcel summary information bool Bool for whether to create deed restricted units with the subsidies or not. The logic at the time of this writing is to keep track of partial units so that when partial units sum to greater than a unit, that unit will be deed restricted. Returns Nothing Subsidized residential developer is designed to run before the normal residential developer - it will prioritize the developments we're subsidizing (although this is not strictly required - running this model after the market rate developer will just create a temporarily larger supply of units, which will probably create less market rate development in the next simulated year). The steps for subsidizing are essentially these: 1 run feasibility with only_built set to false so that the feasibility of unprofitable units are recorded 2 temporarily filter to ONLY unprofitable units to check for possible subsidized units (normal developer takes care of market-rate units) 3 compute the number of units in these developments 4 divide cost by number of units in order to get the subsidy per unit 5 filter developments to parcels in \"receiving zone\" similar to the way we identified \"sending zones\" 6 iterate through subaccounts one at a time as subsidy will be limited to available funds in the subaccount (usually by jurisdiction) 7 sort ascending by subsidy per unit so that we minimize subsidy (but total subsidy is equivalent to total building cost) 8 cumsum the total subsidy in the buildings and locate the development where the subsidy is less than or equal to the amount in the account - filter to only those buildings (these will likely be built) 9 pass the results as \"feasible\" to run_developer - this is sort of a boundary case of developer but should run OK 10 for those developments that get built, make sure to subtract from account and keep a record (on the off chance that demand is less than the subsidized units, run through the standard code path, although it's very unlikely that there would be more subsidized housing than demand) Source code in baus\\subsidies.py 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 def run_subsidized_developer ( feasibility , parcels , buildings , households , acct_settings , developer_settings , account , year , form_to_btype_func , add_extra_columns_func , summary , create_deed_restricted = False , policy_name = \"Unnamed\" ): \"\"\" The subsidized residential developer model. Parameters ---------- feasibility : DataFrame A DataFrame that is returned from run_feasibility for a given form parcels : DataFrameWrapper The standard parcels DataFrameWrapper (mostly just for run_developer) buildings : DataFrameWrapper The standard buildings DataFrameWrapper (passed to run_developer) households : DataFrameWrapper The households DataFrameWrapper (passed to run_developer) acct_settings : Dict A dictionary of settings to parameterize the model. Needs these keys: sending_buildings_subaccount_def - maps buildings to subaccounts receiving_buildings_filter - filter for eligible buildings settings : Dict The overall settings account : Account The Account object to use for subsidization year : int The current simulation year (will be added as metadata) form_to_btype_func : function Passed through to run_developer add_extra_columns_func : function Passed through to run_developer summary : Summary Used to add parcel summary information create_deed_restricted : bool Bool for whether to create deed restricted units with the subsidies or not. The logic at the time of this writing is to keep track of partial units so that when partial units sum to greater than a unit, that unit will be deed restricted. Returns ------- Nothing Subsidized residential developer is designed to run before the normal residential developer - it will prioritize the developments we're subsidizing (although this is not strictly required - running this model after the market rate developer will just create a temporarily larger supply of units, which will probably create less market rate development in the next simulated year). The steps for subsidizing are essentially these: 1 run feasibility with only_built set to false so that the feasibility of unprofitable units are recorded 2 temporarily filter to ONLY unprofitable units to check for possible subsidized units (normal developer takes care of market-rate units) 3 compute the number of units in these developments 4 divide cost by number of units in order to get the subsidy per unit 5 filter developments to parcels in \"receiving zone\" similar to the way we identified \"sending zones\" 6 iterate through subaccounts one at a time as subsidy will be limited to available funds in the subaccount (usually by jurisdiction) 7 sort ascending by subsidy per unit so that we minimize subsidy (but total subsidy is equivalent to total building cost) 8 cumsum the total subsidy in the buildings and locate the development where the subsidy is less than or equal to the amount in the account - filter to only those buildings (these will likely be built) 9 pass the results as \"feasible\" to run_developer - this is sort of a boundary case of developer but should run OK 10 for those developments that get built, make sure to subtract from account and keep a record (on the off chance that demand is less than the subsidized units, run through the standard code path, although it's very unlikely that there would be more subsidized housing than demand) \"\"\" # step 2 feasibility = feasibility . replace ([ np . inf , - np . inf ], np . nan ) feasibility = feasibility [ feasibility . max_profit < 0 ] # step 3 feasibility [ 'ave_sqft_per_unit' ] = parcels . ave_sqft_per_unit feasibility [ 'residential_units' ] = np . floor ( feasibility . residential_sqft / feasibility . ave_sqft_per_unit ) # step 3B # can only add units - don't subtract units - this is an approximation # of the calculation that will be used to do this in the developer model feasibility = feasibility [ feasibility . residential_units > feasibility . total_residential_units ] # step 3C # towards the end, because we're about to sort by subsidy per unit, some # large projects never get built, because it could be a 100 unit project # times a 500k subsidy per unit. thus we're going to try filtering by # the maximum subsidy for a single development here feasibility = feasibility [ feasibility . max_profit > - 50 * 1000000 ] # step 4 feasibility [ 'subsidy_per_unit' ] = - 1 * feasibility [ 'max_profit' ] / feasibility [ 'residential_units' ] # assumption that even if the developer says this property is almost # profitable, even the administration costs are likely to cost at least # 10k / unit feasibility [ 'subsidy_per_unit' ] = feasibility . subsidy_per_unit . clip ( 10000 ) # step 5 if \"receiving_buildings_filter\" in acct_settings : feasibility = feasibility . query ( acct_settings [ \"receiving_buildings_filter\" ]) else : # otherwise all buildings are valid pass new_buildings_list = [] sending_bldgs = acct_settings [ \"sending_buildings_subaccount_def\" ] feasibility [ \"regional\" ] = 1 feasibility [ \"subaccount\" ] = feasibility . eval ( sending_bldgs ) # step 6 for subacct , amount in account . iter_subaccounts (): print ( \"Subaccount: \" , subacct ) df = feasibility [ feasibility . subaccount == subacct ] print ( \"Number of feasible projects in receiving zone:\" , len ( df )) if len ( df ) == 0 : continue # step 7 df = df . sort_values ([ 'subsidy_per_unit' ], ascending = True ) # df.to_csv('subsidized_units_%d_%s_%s.csv' % (orca.get_injectable(\"year\"), account.name, subacct)) # step 8 print ( \"Amount in subaccount: $ {:,.2f} \" . format ( amount )) num_bldgs = int (( - 1 * df . max_profit ) . cumsum () . searchsorted ( amount )) if num_bldgs == 0 : continue # technically we only build these buildings if there's demand # print \"Building {:d} subsidized buildings\".format(num_bldgs) df = df . iloc [: int ( num_bldgs )] df . columns = pd . MultiIndex . from_tuples ( [( \"residential\" , col ) for col in df . columns ]) # disable stdout since developer is a bit verbose for this use case sys . stdout , old_stdout = StringIO (), sys . stdout kwargs = developer_settings [ 'residential_developer' ] # step 9 new_buildings = utils . run_developer ( \"residential\" , households , buildings , \"residential_units\" , parcels . parcel_size , parcels . ave_sqft_per_unit , parcels . total_residential_units , orca . DataFrameWrapper ( \"feasibility\" , df ), year = year , form_to_btype_callback = form_to_btype_func , add_more_columns_callback = add_extra_columns_func , profit_to_prob_func = profit_to_prob_func , ** kwargs ) sys . stdout = old_stdout buildings = orca . get_table ( \"buildings\" ) if new_buildings is None : continue # keep track of partial subsidized untis so that we always get credit # for a partial unit, even if it's not built in this specific building partial_subsidized_units = 0 # step 10 for index , new_building in new_buildings . iterrows (): amt = new_building . max_profit metadata = { \"description\" : \"Developing subsidized building\" , \"year\" : year , \"residential_units\" : new_building . residential_units , \"inclusionary_units\" : new_building . inclusionary_units , \"building_id\" : index } if create_deed_restricted : revenue_per_unit = new_building . building_revenue / new_building . residential_units total_subsidy = abs ( new_building . max_profit ) subsidized_units = total_subsidy / revenue_per_unit + partial_subsidized_units # right now there are inclusionary requirements already_subsidized_units = new_building . deed_restricted_units # get remainder partial_subsidized_units = subsidized_units % 1 # round off for now subsidized_units = int ( subsidized_units ) + already_subsidized_units # cap at number of residential units subsidized_units = min ( subsidized_units , new_building . residential_units ) buildings . local . loc [ index , \"deed_restricted_units\" ] = int ( round ( subsidized_units )) buildings . local . loc [ index , \"subsidized_units\" ] = buildings . local . loc [ index , \"deed_restricted_units\" ] - \\ buildings . local . loc [ index , \"inclusionary_units\" ] # also correct the debug output new_buildings . loc [ index , \"deed_restricted_units\" ] = int ( round ( subsidized_units )) new_buildings . loc [ index , \"subsidized_units\" ] = new_buildings . loc [ index , \"deed_restricted_units\" ] - \\ new_buildings . loc [ index , \"inclusionary_units\" ] metadata [ 'deed_restricted_units' ] = new_buildings . loc [ index , 'deed_restricted_units' ] metadata [ 'subsidized_units' ] = new_buildings . loc [ index , 'subsidized_units' ] account . add_transaction ( amt , subaccount = subacct , metadata = metadata ) # turn off this assertion for the Draft Blueprint affordable housing policy since the number of deed restricted units # vs units from development projects looks reasonable # assert np.all(buildings.local.deed_restricted_units.fillna(0) <= # buildings.local.residential_units.fillna(0)) print ( \"Amount left after subsidy: $ {:,.2f} \" . format ( account . total_transactions_by_subacct ( subacct ))) new_buildings_list . append ( new_buildings ) total_len = reduce ( lambda x , y : x + len ( y ), new_buildings_list , 0 ) if total_len == 0 : print ( \"No subsidized buildings\" ) return new_buildings = pd . concat ( new_buildings_list ) print ( \"Built {} total subsidized buildings\" . format ( len ( new_buildings ))) print ( \" Total subsidy: $ {:,.2f} \" . format ( - 1 * new_buildings . max_profit . sum ())) print ( \" Total subsidized units: {:.0f} \" . format ( new_buildings . residential_units . sum ())) new_buildings [ \"subsidized\" ] = True new_buildings [ \"policy_name\" ] = policy_name summary . add_parcel_output ( new_buildings )","title":"subsidies"},{"location":"subsidies-reference/#subsidies-module","text":"","title":"Subsidies module"},{"location":"subsidies-reference/#baus.subsidies","text":"","title":"subsidies"},{"location":"subsidies-reference/#baus.subsidies.run_subsidized_developer","text":"The subsidized residential developer model.","title":"run_subsidized_developer()"},{"location":"subsidies-reference/#baus.subsidies.run_subsidized_developer--parameters","text":"DataFrame A DataFrame that is returned from run_feasibility for a given form DataFrameWrapper The standard parcels DataFrameWrapper (mostly just for run_developer) DataFrameWrapper The standard buildings DataFrameWrapper (passed to run_developer) DataFrameWrapper The households DataFrameWrapper (passed to run_developer) Dict A dictionary of settings to parameterize the model. Needs these keys: sending_buildings_subaccount_def - maps buildings to subaccounts receiving_buildings_filter - filter for eligible buildings Dict The overall settings Account The Account object to use for subsidization int The current simulation year (will be added as metadata) function Passed through to run_developer function Passed through to run_developer Summary Used to add parcel summary information bool Bool for whether to create deed restricted units with the subsidies or not. The logic at the time of this writing is to keep track of partial units so that when partial units sum to greater than a unit, that unit will be deed restricted.","title":"Parameters"},{"location":"subsidies-reference/#baus.subsidies.run_subsidized_developer--returns","text":"Nothing Subsidized residential developer is designed to run before the normal residential developer - it will prioritize the developments we're subsidizing (although this is not strictly required - running this model after the market rate developer will just create a temporarily larger supply of units, which will probably create less market rate development in the next simulated year). The steps for subsidizing are essentially these: 1 run feasibility with only_built set to false so that the feasibility of unprofitable units are recorded 2 temporarily filter to ONLY unprofitable units to check for possible subsidized units (normal developer takes care of market-rate units) 3 compute the number of units in these developments 4 divide cost by number of units in order to get the subsidy per unit 5 filter developments to parcels in \"receiving zone\" similar to the way we identified \"sending zones\" 6 iterate through subaccounts one at a time as subsidy will be limited to available funds in the subaccount (usually by jurisdiction) 7 sort ascending by subsidy per unit so that we minimize subsidy (but total subsidy is equivalent to total building cost) 8 cumsum the total subsidy in the buildings and locate the development where the subsidy is less than or equal to the amount in the account - filter to only those buildings (these will likely be built) 9 pass the results as \"feasible\" to run_developer - this is sort of a boundary case of developer but should run OK 10 for those developments that get built, make sure to subtract from account and keep a record (on the off chance that demand is less than the subsidized units, run through the standard code path, although it's very unlikely that there would be more subsidized housing than demand) Source code in baus\\subsidies.py 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 def run_subsidized_developer ( feasibility , parcels , buildings , households , acct_settings , developer_settings , account , year , form_to_btype_func , add_extra_columns_func , summary , create_deed_restricted = False , policy_name = \"Unnamed\" ): \"\"\" The subsidized residential developer model. Parameters ---------- feasibility : DataFrame A DataFrame that is returned from run_feasibility for a given form parcels : DataFrameWrapper The standard parcels DataFrameWrapper (mostly just for run_developer) buildings : DataFrameWrapper The standard buildings DataFrameWrapper (passed to run_developer) households : DataFrameWrapper The households DataFrameWrapper (passed to run_developer) acct_settings : Dict A dictionary of settings to parameterize the model. Needs these keys: sending_buildings_subaccount_def - maps buildings to subaccounts receiving_buildings_filter - filter for eligible buildings settings : Dict The overall settings account : Account The Account object to use for subsidization year : int The current simulation year (will be added as metadata) form_to_btype_func : function Passed through to run_developer add_extra_columns_func : function Passed through to run_developer summary : Summary Used to add parcel summary information create_deed_restricted : bool Bool for whether to create deed restricted units with the subsidies or not. The logic at the time of this writing is to keep track of partial units so that when partial units sum to greater than a unit, that unit will be deed restricted. Returns ------- Nothing Subsidized residential developer is designed to run before the normal residential developer - it will prioritize the developments we're subsidizing (although this is not strictly required - running this model after the market rate developer will just create a temporarily larger supply of units, which will probably create less market rate development in the next simulated year). The steps for subsidizing are essentially these: 1 run feasibility with only_built set to false so that the feasibility of unprofitable units are recorded 2 temporarily filter to ONLY unprofitable units to check for possible subsidized units (normal developer takes care of market-rate units) 3 compute the number of units in these developments 4 divide cost by number of units in order to get the subsidy per unit 5 filter developments to parcels in \"receiving zone\" similar to the way we identified \"sending zones\" 6 iterate through subaccounts one at a time as subsidy will be limited to available funds in the subaccount (usually by jurisdiction) 7 sort ascending by subsidy per unit so that we minimize subsidy (but total subsidy is equivalent to total building cost) 8 cumsum the total subsidy in the buildings and locate the development where the subsidy is less than or equal to the amount in the account - filter to only those buildings (these will likely be built) 9 pass the results as \"feasible\" to run_developer - this is sort of a boundary case of developer but should run OK 10 for those developments that get built, make sure to subtract from account and keep a record (on the off chance that demand is less than the subsidized units, run through the standard code path, although it's very unlikely that there would be more subsidized housing than demand) \"\"\" # step 2 feasibility = feasibility . replace ([ np . inf , - np . inf ], np . nan ) feasibility = feasibility [ feasibility . max_profit < 0 ] # step 3 feasibility [ 'ave_sqft_per_unit' ] = parcels . ave_sqft_per_unit feasibility [ 'residential_units' ] = np . floor ( feasibility . residential_sqft / feasibility . ave_sqft_per_unit ) # step 3B # can only add units - don't subtract units - this is an approximation # of the calculation that will be used to do this in the developer model feasibility = feasibility [ feasibility . residential_units > feasibility . total_residential_units ] # step 3C # towards the end, because we're about to sort by subsidy per unit, some # large projects never get built, because it could be a 100 unit project # times a 500k subsidy per unit. thus we're going to try filtering by # the maximum subsidy for a single development here feasibility = feasibility [ feasibility . max_profit > - 50 * 1000000 ] # step 4 feasibility [ 'subsidy_per_unit' ] = - 1 * feasibility [ 'max_profit' ] / feasibility [ 'residential_units' ] # assumption that even if the developer says this property is almost # profitable, even the administration costs are likely to cost at least # 10k / unit feasibility [ 'subsidy_per_unit' ] = feasibility . subsidy_per_unit . clip ( 10000 ) # step 5 if \"receiving_buildings_filter\" in acct_settings : feasibility = feasibility . query ( acct_settings [ \"receiving_buildings_filter\" ]) else : # otherwise all buildings are valid pass new_buildings_list = [] sending_bldgs = acct_settings [ \"sending_buildings_subaccount_def\" ] feasibility [ \"regional\" ] = 1 feasibility [ \"subaccount\" ] = feasibility . eval ( sending_bldgs ) # step 6 for subacct , amount in account . iter_subaccounts (): print ( \"Subaccount: \" , subacct ) df = feasibility [ feasibility . subaccount == subacct ] print ( \"Number of feasible projects in receiving zone:\" , len ( df )) if len ( df ) == 0 : continue # step 7 df = df . sort_values ([ 'subsidy_per_unit' ], ascending = True ) # df.to_csv('subsidized_units_%d_%s_%s.csv' % (orca.get_injectable(\"year\"), account.name, subacct)) # step 8 print ( \"Amount in subaccount: $ {:,.2f} \" . format ( amount )) num_bldgs = int (( - 1 * df . max_profit ) . cumsum () . searchsorted ( amount )) if num_bldgs == 0 : continue # technically we only build these buildings if there's demand # print \"Building {:d} subsidized buildings\".format(num_bldgs) df = df . iloc [: int ( num_bldgs )] df . columns = pd . MultiIndex . from_tuples ( [( \"residential\" , col ) for col in df . columns ]) # disable stdout since developer is a bit verbose for this use case sys . stdout , old_stdout = StringIO (), sys . stdout kwargs = developer_settings [ 'residential_developer' ] # step 9 new_buildings = utils . run_developer ( \"residential\" , households , buildings , \"residential_units\" , parcels . parcel_size , parcels . ave_sqft_per_unit , parcels . total_residential_units , orca . DataFrameWrapper ( \"feasibility\" , df ), year = year , form_to_btype_callback = form_to_btype_func , add_more_columns_callback = add_extra_columns_func , profit_to_prob_func = profit_to_prob_func , ** kwargs ) sys . stdout = old_stdout buildings = orca . get_table ( \"buildings\" ) if new_buildings is None : continue # keep track of partial subsidized untis so that we always get credit # for a partial unit, even if it's not built in this specific building partial_subsidized_units = 0 # step 10 for index , new_building in new_buildings . iterrows (): amt = new_building . max_profit metadata = { \"description\" : \"Developing subsidized building\" , \"year\" : year , \"residential_units\" : new_building . residential_units , \"inclusionary_units\" : new_building . inclusionary_units , \"building_id\" : index } if create_deed_restricted : revenue_per_unit = new_building . building_revenue / new_building . residential_units total_subsidy = abs ( new_building . max_profit ) subsidized_units = total_subsidy / revenue_per_unit + partial_subsidized_units # right now there are inclusionary requirements already_subsidized_units = new_building . deed_restricted_units # get remainder partial_subsidized_units = subsidized_units % 1 # round off for now subsidized_units = int ( subsidized_units ) + already_subsidized_units # cap at number of residential units subsidized_units = min ( subsidized_units , new_building . residential_units ) buildings . local . loc [ index , \"deed_restricted_units\" ] = int ( round ( subsidized_units )) buildings . local . loc [ index , \"subsidized_units\" ] = buildings . local . loc [ index , \"deed_restricted_units\" ] - \\ buildings . local . loc [ index , \"inclusionary_units\" ] # also correct the debug output new_buildings . loc [ index , \"deed_restricted_units\" ] = int ( round ( subsidized_units )) new_buildings . loc [ index , \"subsidized_units\" ] = new_buildings . loc [ index , \"deed_restricted_units\" ] - \\ new_buildings . loc [ index , \"inclusionary_units\" ] metadata [ 'deed_restricted_units' ] = new_buildings . loc [ index , 'deed_restricted_units' ] metadata [ 'subsidized_units' ] = new_buildings . loc [ index , 'subsidized_units' ] account . add_transaction ( amt , subaccount = subacct , metadata = metadata ) # turn off this assertion for the Draft Blueprint affordable housing policy since the number of deed restricted units # vs units from development projects looks reasonable # assert np.all(buildings.local.deed_restricted_units.fillna(0) <= # buildings.local.residential_units.fillna(0)) print ( \"Amount left after subsidy: $ {:,.2f} \" . format ( account . total_transactions_by_subacct ( subacct ))) new_buildings_list . append ( new_buildings ) total_len = reduce ( lambda x , y : x + len ( y ), new_buildings_list , 0 ) if total_len == 0 : print ( \"No subsidized buildings\" ) return new_buildings = pd . concat ( new_buildings_list ) print ( \"Built {} total subsidized buildings\" . format ( len ( new_buildings ))) print ( \" Total subsidy: $ {:,.2f} \" . format ( - 1 * new_buildings . max_profit . sum ())) print ( \" Total subsidized units: {:.0f} \" . format ( new_buildings . residential_units . sum ())) new_buildings [ \"subsidized\" ] = True new_buildings [ \"policy_name\" ] = policy_name summary . add_parcel_output ( new_buildings )","title":"Returns"},{"location":"user_guide/","text":"User Guide This User Guide applies to UrbanSim implementation for the Bay Area. Documentation for the UrbanSim framework is available here. Installation Bay Area UrbanSim is written in Python and runs in a command line environment. It's compatible with Mac, Windows, and Linux, and with Python 2.7 and 3.5+. Python 3 is recommended. Install the Anaconda Python distribution (not strictly required, but makes things easier and more reliable) Clone this repository Download base data from this Box folder and move the files to bayarea_urbansim/data/ (ask an MTC contact for access) Clone the MTC urban_data_internal repository to the same location as this repository (ask an MTC contact for access) Create a Python environment with the current dependencies: conda env create -f baus-env-2020.yml Activate the environment: conda activate baus-env-2020 Pre-process the base data: python baus.py --mode preprocessing (only needed once) Run the model: python baus.py (typical AWS linux run uses nohup python baus.py -s 25 --disable-slack --random-seed & which add no hanging up / specifies scenario 25 / disables slack output / turns OFF random seed / puts in background) More info about the command line arguments: python baus.py --help Optional visualization tool and Slack messenger: Configure Amazon Web Services (AWS) to get s3 permission (you will need an appropriately configured AWS credentials file from your MTC contact) Install AWS SDK for Python -- boto3 using pip install boto3 Install Slacker to use Slack API using pip install slacker (you will need an appropriate slack token to access the slack bot from your MTC contact) Set environment variable URBANSIM_SLACK = TRUE File Structure TBD","title":"User Guide"},{"location":"user_guide/#user-guide","text":"This User Guide applies to UrbanSim implementation for the Bay Area. Documentation for the UrbanSim framework is available here.","title":"User Guide"},{"location":"user_guide/#installation","text":"Bay Area UrbanSim is written in Python and runs in a command line environment. It's compatible with Mac, Windows, and Linux, and with Python 2.7 and 3.5+. Python 3 is recommended. Install the Anaconda Python distribution (not strictly required, but makes things easier and more reliable) Clone this repository Download base data from this Box folder and move the files to bayarea_urbansim/data/ (ask an MTC contact for access) Clone the MTC urban_data_internal repository to the same location as this repository (ask an MTC contact for access) Create a Python environment with the current dependencies: conda env create -f baus-env-2020.yml Activate the environment: conda activate baus-env-2020 Pre-process the base data: python baus.py --mode preprocessing (only needed once) Run the model: python baus.py (typical AWS linux run uses nohup python baus.py -s 25 --disable-slack --random-seed & which add no hanging up / specifies scenario 25 / disables slack output / turns OFF random seed / puts in background) More info about the command line arguments: python baus.py --help Optional visualization tool and Slack messenger: Configure Amazon Web Services (AWS) to get s3 permission (you will need an appropriately configured AWS credentials file from your MTC contact) Install AWS SDK for Python -- boto3 using pip install boto3 Install Slacker to use Slack API using pip install slacker (you will need an appropriate slack token to access the slack bot from your MTC contact) Set environment variable URBANSIM_SLACK = TRUE","title":"Installation"},{"location":"user_guide/#file-structure","text":"TBD","title":"File Structure"}]}