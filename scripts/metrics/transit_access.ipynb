{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c356470",
   "metadata": {},
   "source": [
    "# Transit Service Areas - definition and summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0b9e78",
   "metadata": {},
   "source": [
    "Notebook is an implementation of https://github.com/BayAreaMetro/bayarea_urbansim/blob/main/scripts/proximity2transit.py. It will be turned into a standalone script.\n",
    "\n",
    "In words, the process is going from a point layer of transit stops with information on size and headways and build status. Those are to be buffered, and a hierarchy is active, favoring rail over non-rail, and shorter headways over longer headways. Service areas a built by overlays, and parcels are classified by the service area they fall within. Finally model runs are summarized by these service areas, and other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d5e5cd",
   "metadata": {},
   "source": [
    "# Paraphernalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3827f071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aolsen/opt/anaconda3/envs/geo_env_2/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/4184460065.py:9: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9a2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DVUTILS_LOCAL_CLONE_PATH = \"/Users/aolsen/Documents/GitHub/dvutils\"\n",
    "# sys.path.insert(0, DVUTILS_LOCAL_CLONE_PATH)\n",
    "# from utils_io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6b0047d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdb_path = '/Volumes/Data/Models/Scratch/AO/workspace_2024_0315_1017.gdb'\n",
    "gdb_path = '/Volumes/Data/Models/Data/GIS layers/JobsHousingTransitProximity/workspace_2020_1008_2343.gdb'\n",
    "\n",
    "#fiona.listlayers(gdb_path)\n",
    "v2020_fbp_classes = gpd.read_file(gdb_path,layer='trn_bp_cat5')\n",
    "v2020_cur_classes = gpd.read_file(gdb_path,layer='trn_cur_cat5')\n",
    "v2020_np_classes = gpd.read_file(gdb_path,layer='trn_np_cat5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c99519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2020_fbp_classes = gpd.read_file(gdb_path,layer='trn_bp_cat5')\n",
    "v2020_cur_classes = gpd.read_file(gdb_path,layer='trn_cur_cat5')\n",
    "v2020_np_classes = gpd.read_file(gdb_path,layer='trn_np_cat5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a44580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "6d97e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiona.listlayers(gdb_path)\n",
    "v2020_transit_current = gpd.read_file(gdb_path,layer='transit_current')\n",
    "v2020_transit_potential = gpd.read_file(gdb_path,layer='transit_potential')\n",
    "v2020_transit_cur_major = gpd.read_file(gdb_path,layer='trn_cur_major')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "50ac881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transit_areas_current_dissolved.explore(column='cat5',cmap='Set3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "06634024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2020_fbp_classes.explore(column='Service_Level',cmap='Set3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835ae42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e06324b",
   "metadata": {},
   "source": [
    "## Paths\n",
    "### AGOL URLs, and local versions until we get utils working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43e844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYSIS_CRS = 'EPSG:26910'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5d3878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = os.path.abspath(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "172331fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MTC_ONLINE_TRANSIT_URL = 'https://services3.arcgis.com/i2dkYWmb4wHvYPda/arcgis/rest/services/transitstops_existing_planned_2021/FeatureServer/0'\n",
    "\n",
    "MTC_ONLINE_BACOUNTY_URL = 'https://services3.arcgis.com/i2dkYWmb4wHvYPda/ArcGIS/rest/services/region_county/FeatureServer/0'\n",
    "\n",
    "MTC_ONLINE_TAZ_URL = 'https://services3.arcgis.com/i2dkYWmb4wHvYPda/ArcGIS/rest/services/transportation_analysis_zones_1454/FeatureServer/0'\n",
    "\n",
    "#MTC_ONLINE_TRACT_URL = 'https://services3.arcgis.com/i2dkYWmb4wHvYPda/ArcGIS/rest/services/Bay_Area_Census_Tracts_2010/FeatureServer/0'\n",
    "MTC_ONLINE_TRACT_URL = 'https://services3.arcgis.com/i2dkYWmb4wHvYPda/ArcGIS/rest/services/cocs_ACS2014_2018/FeatureServer/0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "9d80bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_epc_path = '/Users/aolsen/Dropbox/My Mac (AOLSEN-MBP.local)/Downloads/proximity/communities_of_concern_2020_acs2018_-5728172521147435275.gpkg'\n",
    "tract_epc21_path = '/Volumes/Data/Models/Data/Equity Priority Communities/PBA50/EPCs_ACS2018_tbl.csv'\n",
    "tract_epc25_path = '/Volumes/Data/Models/Data/Equity Priority Communities/PBA50Plus/epc_acs2022.csv'\n",
    "county_path = '/Users/aolsen/Dropbox/My Mac (AOLSEN-MBP.local)/Downloads/proximity/region_county_-6301486166122500334.gpkg'\n",
    "transit_path = '/Users/aolsen/Dropbox/My Mac (AOLSEN-MBP.local)/Downloads/proximity/transitstops_existing_planned_2021_2777787894694541529.gpkg'\n",
    "taz_path = '/Users/aolsen/Dropbox/My Mac (AOLSEN-MBP.local)/Downloads/proximity/transportation_analysis_zones_1454_5961535026220395633.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3f8b5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_epc21_file = pd.read_csv(tract_epc21_path)\n",
    "tract_epc25_file = pd.read_csv(tract_epc25_path)\n",
    "#tract_epc_file = tract_epc_file.to_crs(ANALYSIS_CRS)\n",
    "\n",
    "county_file = gpd.read_file(county_path)\n",
    "county_file = county_file.to_crs(ANALYSIS_CRS)\n",
    "\n",
    "transit_file = gpd.read_file(transit_path)\n",
    "transit_file = transit_file.to_crs(ANALYSIS_CRS)\n",
    "\n",
    "taz_file = gpd.read_file(taz_path)\n",
    "taz_file = taz_file.to_crs(ANALYSIS_CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8318c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "1e6675d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_epc21_file['geoid10'] = tract_epc21_file.geoid.map(lambda x: f'{x:011d}')\n",
    "tract_epc25_file['geoid20'] = tract_epc25_file.tract_geoid.map(lambda x: f'{x:011d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c415b4",
   "metadata": {},
   "source": [
    "### Crosswalks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9918c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "parcel_x_taz_file = '/Volumes/Data/Models/urban_modeling/baus/BAUS Inputs/basis_inputs/crosswalks/2020_08_17_parcel_to_taz1454sub.csv'\n",
    "parcel_x_tract10_file = '/Volumes/Data/Models/urban_modeling/baus/BAUS Inputs/basis_inputs/crosswalks/parcel_tract_crosswalk.csv'\n",
    "parcel_x_tracts_file = '/Volumes/Data/Models/urban_modeling/baus/BAUS Inputs/basis_inputs/crosswalks/p10_census.csv'\n",
    "parcel_topo_file = '/Users/aolsen/Box/Modeling and Surveys/Urban Modeling/Bay Area UrbanSim/PBA50/Policies/Base zoning/inputs/p10_geo.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d552ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_x_taz = pd.read_csv(parcel_x_taz_file,\n",
    "                           usecols=['PARCEL_ID', 'ZONE_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a77c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_x_tract10 = pd.read_csv(parcel_x_tract10_file,\n",
    "                               usecols=[\n",
    "                                   'parcel_id', 'zone_id', 'GEOID10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d054c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9662e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_x_tracts = pd.read_csv(parcel_x_tracts_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f27fc7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load p10 parcels\n",
    "\n",
    "p10_topofix = gpd.read_feather(parcel_topo_file)\n",
    "p10_topofix['geom_pt'] = p10_topofix.representative_point()\n",
    "p10_topofix_pt = p10_topofix.set_geometry('geom_pt')[['PARCEL_ID', 'geom_pt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c695434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rowid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MULTIPOLYGON (((634946.795 4149225.520, 634876...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                           geometry\n",
       "rowid                                                         \n",
       "0         0  MULTIPOLYGON (((634946.795 4149225.520, 634876..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_bdry = gpd.GeoDataFrame(data={'name':[0]},geometry=county_file.dissolve()['geometry'])\n",
    "region_bdry.index = region_bdry.index.set_names('rowid')\n",
    "region_bdry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407d07dd",
   "metadata": {},
   "source": [
    "## Constants and mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bf68644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EIR runs/Baseline Large (s25) runs/NP_v8_FINAL/run314',\n",
       " 'EIR runs/Alt1 (s26) runs/Alt1_v3_test_far_tiers_FINAL_EIR_ALT/run375',\n",
       " 'EIR runs/Alt2 (s28) runs/Alt2_v1_FINAL_EIR_ALT/run374',\n",
       " 'Final Blueprint runs/Final Blueprint (s24)/BAUS v2.25 - FINAL VERSION/run182']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Urbansim Setup\n",
    "urbansim_run_location = '/Users/{}/Box/Modeling and Surveys/Urban Modeling/Bay Area UrbanSim/PBA50/'.format(\n",
    "    os.getlogin())\n",
    "\n",
    "# keep DBP for future\n",
    "us_2050_DBP_Final = 'Draft Blueprint runs/Blueprint Plus Crossing (s23)/v1.7.1- FINAL DRAFT BLUEPRINT/run98'\n",
    "us_2050_FBP_Final = 'Final Blueprint runs/Final Blueprint (s24)/BAUS v2.25 - FINAL VERSION/run182'\n",
    "us_2050_NP_EIR = 'EIR runs/Baseline Large (s25) runs/NP_v8_FINAL/run314'\n",
    "us_2050_ALT1_EIR = 'EIR runs/Alt1 (s26) runs/Alt1_v3_test_far_tiers_FINAL_EIR_ALT/run375'\n",
    "us_2050_ALT2_EIR = 'EIR runs/Alt2 (s28) runs/Alt2_v1_FINAL_EIR_ALT/run374'\n",
    "\n",
    "list_us_runid = [us_2050_NP_EIR, us_2050_ALT1_EIR, us_2050_ALT2_EIR,\n",
    "                 us_2050_FBP_Final]  # , us_2050_FBP_Final, us_2050_DBP_Final]\n",
    "list_us_runid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fac6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KM_TO_MILES = 1.609344\n",
    "\n",
    "# get the inverse\n",
    "MILES_TO_KM = 1/KM_TO_MILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbb4bece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "804.672"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def miles_to_m(miles):\n",
    "    return 1000 * miles / MILES_TO_KM\n",
    "\n",
    "\n",
    "# test: half mile to meters: should be ~805\n",
    "miles_to_m(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee1d04ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combination_names(group):\n",
    "\n",
    "    combination_names = []\n",
    "    for col_name, value in group.iteritems():\n",
    "        if value.any():\n",
    "            # if there are any true values - keep the corresponding column name\n",
    "            combination_names.append(col_name)\n",
    "    return '-'.join(combination_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "255746e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combination_names_hierarchy(group):\n",
    "    \n",
    "    # loop through values in tuple - ordering matters. So\n",
    "    # we stop at the first case of a True value - the \n",
    "    # first one takes primacy - like major stops buffer\n",
    "    for col, val in group.iteritems():\n",
    "        # print(col,val)\n",
    "        if val.all():\n",
    "            return f'{col}_only' if col!='reg' else 'none'\n",
    "\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a4c46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_and_buffer(source_df, qry_str, buf_dist):\n",
    "    source_subset = source_df.query(qry_str)\n",
    "\n",
    "    source_subset_buf = source_subset.buffer(miles_to_m(buf_dist))\n",
    "\n",
    "    output = (gpd.GeoDataFrame(  # data=source_subset[passthrough_cols],\n",
    "        geometry=source_subset_buf.values)\n",
    "        .reset_index()\n",
    "        .rename(columns={'index': 'rowid'}))\n",
    "\n",
    "    return output.dissolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d042a",
   "metadata": {},
   "source": [
    "# Create buffer for transit layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302bc965",
   "metadata": {},
   "source": [
    "## Set up logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4bd324f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logger\n",
    "NOW = datetime.datetime.now()\n",
    "LOG_FILE = os.path.join(WORKING_DIR, \"proximity2transit_{}.log\".format(NOW))\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel('DEBUG')\n",
    "\n",
    "# console handler\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel('INFO')\n",
    "ch.setFormatter(logging.Formatter(\n",
    "    '%(asctime)s - %(levelname)s - %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p'))\n",
    "logger.addHandler(ch)\n",
    "\n",
    "# file handler\n",
    "fh = logging.FileHandler(LOG_FILE, mode='w')\n",
    "fh.setLevel('DEBUG')\n",
    "fh.setFormatter(logging.Formatter(\n",
    "    '%(asctime)s - %(levelname)s - %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p'))\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb335da3",
   "metadata": {},
   "source": [
    "## Step 0: Subset transit data to relevant universes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "cac35409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40237, 18)\n",
      "(40577, 18)\n",
      "(40232, 18)\n"
     ]
    }
   ],
   "source": [
    "# we use status criteria OR major_stop here -\n",
    "# following logic here: https://github.com/BayAreaMetro/petrale/blob/c4b96a98b291ada58e065375beccd5bf11e2da1b/scripts/proximity2transit.py#L128\n",
    "\n",
    "# subset to existing, under construction, open or FBP\n",
    "# this is really just everything\n",
    "\n",
    "qry_fbp = 'status.isin([\"Under Construction\",\"Open\",\"Final Blueprint\",\"Existing/Built\"]) ' #| major_stop==1\n",
    "\n",
    "transit_fbp = transit_file.query(\n",
    "    qry_fbp)\n",
    "\n",
    "# subset to existing major stop, and under construction or open\n",
    "qry_np = 'status.isin([\"Under Construction\",\"Open\",\"Existing/Built\"]) ' # | (major_stop==1 & status!=\"Final Blueprint\")\n",
    "\n",
    "transit_np = transit_file.query(\n",
    "    qry_np)\n",
    "\n",
    "# subset to existing transit infrastructure (per 2015 or so, pre-plan)\n",
    "\n",
    "qry_current = ' status==\"Existing/Built\"'\n",
    "#qry_current = 'major_stop==1 '\n",
    "transit_current = transit_file.query(\n",
    "    qry_current)\n",
    "\n",
    "print(transit_np.shape)\n",
    "print(transit_fbp.shape)\n",
    "print(transit_current.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "db9c27c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Existing/Built    40232\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transit_file.query(qry_current).status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "01deb9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Existing/Built        40232\n",
       "Under Construction        5\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transit_file.query(qry_np).status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f6c11836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Existing/Built        40232\n",
       "Final Blueprint         340\n",
       "Under Construction        5\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transit_file.query(qry_fbp).status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34a3a4",
   "metadata": {},
   "source": [
    "## Step 1: create transit buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "26d439dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiple_transit_areas(transit_stop_gdf, scenario='current', write_to_disk=False):\n",
    "\n",
    "    logger.info(\n",
    "        f\"Running create_transit_areas function for variant: {scenario}\")\n",
    "    logger.info(f\"transit_stop_gdf has shape: {transit_stop_gdf.shape}\")\n",
    "\n",
    "    buf_dist_half = .5\n",
    "\n",
    "    qry_str_major = \"(major_stop == 1)\"\n",
    "    logger.info(\n",
    "        f\"Subsetting stops to {qry_str_major}, and adding {buf_dist_half} mile buffer\")\n",
    "    major_buf = subset_and_buffer(\n",
    "        transit_stop_gdf, qry_str_major, buf_dist_half)\n",
    "\n",
    "    buf_dist_qtr = .25\n",
    "\n",
    "    qry_str_hdwy_lt15 = \"(am_av_hdwy <= 15) & (pm_av_hdwy <= 15)\"\n",
    "    logger.info(\n",
    "        f\"Subsetting stops to {qry_str_hdwy_lt15}, and adding {buf_dist_qtr} mile buffer\")\n",
    "    hdwy15_buf = subset_and_buffer(\n",
    "        transit_stop_gdf, qry_str_hdwy_lt15, buf_dist_qtr)\n",
    "\n",
    "    qry_str_hdwy_15_to_30 = \"( am_av_hdwy >15 ) & (am_av_hdwy <=30) & ( pm_av_hdwy >15 ) & (pm_av_hdwy <=30)  \"\n",
    "    logger.info(\n",
    "        f\"Subsetting stops to {qry_str_hdwy_15_to_30}, and adding {buf_dist_qtr} mile buffer\")\n",
    "    hdwy30_buf = subset_and_buffer(\n",
    "        transit_stop_gdf, qry_str_hdwy_15_to_30, buf_dist_qtr)\n",
    "\n",
    "    qry_str_hdwy_gt30 = \"(am_av_hdwy > 30) | (pm_av_hdwy > 30)\"\n",
    "    logger.info(\n",
    "        f\"Subsetting stops to {qry_str_hdwy_gt30}, and adding {buf_dist_qtr} mile buffer\")\n",
    "    hdwy30plus_buf = subset_and_buffer(\n",
    "        transit_stop_gdf, qry_str_hdwy_gt30, buf_dist_qtr)\n",
    "\n",
    "    ## Union and classify\n",
    "\n",
    "    # these are the frames we are interested in for the union. We will denote in the\n",
    "    # union process whether a geometry is covered by a particular spatial frame\n",
    "\n",
    "    # the ordering here matters - reflecting a hierarchy of interest: we will use\n",
    "    # to classify areas based on the highest order category in this list\n",
    "    source_frames_ordered = ['major_buf', 'hdwy15buf', 'hdwy30buf', 'hdwy30plusbuf',\n",
    "                             'reg']\n",
    "\n",
    "    # geopandas can only handle two input layers at a time when unioning. We do it step-wise.\n",
    "\n",
    "    logger.info(\n",
    "        f\"Beginning a series of unions, to get all buffers to fully define regional space\")\n",
    "\n",
    "    logger.info(f\"Unioning hdwy15_buf and hdwy30_buf\")\n",
    "\n",
    "    # row_ids are in the source frames; we disambiguate to denote whether a particular\n",
    "    # area is \"covered\" by either of the source files.\n",
    "    # As we are dealing with dissolved geometries for the source geometries, it means\n",
    "    # each source DF has just 1 row with multipart geoms - and that row_id then just\n",
    "    # has the index value of 0 carried forward. So in the resulting union, a row_id value\n",
    "    # of 0 means that a given area was represented in the relevant source dataframe;\n",
    "    # a value of NaN means there was no corresponding match for a particular dataframe\n",
    "    # this is useful for classifying areas based on the \"source\" buffer geometries present\n",
    "    # for a particular location\n",
    "\n",
    "    union_1 = gpd.overlay(hdwy15_buf, hdwy30_buf, how='union').reset_index().rename(\n",
    "        columns={'index': 'df_1', 'rowid_1': 'hdwy15buf', 'rowid_2': 'hdwy30buf'})\n",
    "\n",
    "    logger.info(f'union_1 shape: {union_1.shape}')\n",
    "\n",
    "    logger.info(f\"Adding hdwy30plus_buf...\")\n",
    "    union_2 = gpd.overlay(union_1, hdwy30plus_buf, how='union').reset_index().rename(\n",
    "        columns={'index': 'df_2', 'rowid': 'hdwy30plusbuf'})\n",
    "\n",
    "    # return union_1,hdwy15_buf, hdwy30_buf,union_2,hdwy30plus_buf\n",
    "\n",
    "    logger.info(f'union_2 shape: {union_2.shape}')\n",
    "\n",
    "    logger.info(f\"Adding major stops buffer...\")\n",
    "\n",
    "    union_3 = gpd.overlay(union_2, major_buf, how='union').reset_index(\n",
    "    ).rename(columns={'index': 'df_3', 'rowid': 'major_buf'})\n",
    "\n",
    "    logger.info(f'union_3 shape: {union_3.shape}')\n",
    "    logger.info(\n",
    "        f\"Adding regional boundary so we can get wall to wall coverage\")\n",
    "\n",
    "    # added small (here 10cm) geometry simplification to avoid a TopologyException: found non-noded intersection\n",
    "    union_3['geometry'] = union_3.simplify(.1)\n",
    "\n",
    "    union_4 = gpd.overlay(union_3, region_bdry, how='union').reset_index(\n",
    "    ).rename(columns={'index': 'df_4', 'name': 'reg'})\n",
    "    logger.info(f'union_4 shape: {union_4.shape}')\n",
    "    logger.info('-'*80)\n",
    "    logger.info(f'union_4 head: {union_4.head().T}')\n",
    "    logger.info('-'*80)\n",
    "\n",
    "    # except:\n",
    "#     logger.error(\"Traceback info:\\n{}\\nError Info:\\n{}\".format(\n",
    "#         'unions', str(sys.exc_info()[1])))\n",
    "\n",
    "    # fill nas with -1 - those are values where a particular transit buffer layer doesn't cover something\n",
    "    union_4 = union_4.fillna(-1)\n",
    "\n",
    "    # we need boolean values to grab the group names\n",
    "    logger.info(\n",
    "        f\"With the full region unioned, we now focus on classifying the different combinations\")\n",
    "    union_4[source_frames_ordered] = union_4[source_frames_ordered].replace(\n",
    "        {0: True, -1: False})\n",
    "\n",
    "    # get an integer encoding the unique combination of union components.\n",
    "    # e.g. some areas will be in the buffer of a major stop and a 15 min headway\n",
    "    # but not a 30 min headway. Others will only be in a 15 min headway buffer\n",
    "    # we group areas that share the same combination. We then use that in the\n",
    "    # naming of those groups just downstream; naming them based on\n",
    "    # the boolean True values (indicating a particular buffer is represented)\n",
    "\n",
    "    union_4['ngroup'] = union_4.groupby(source_frames_ordered).ngroup()\n",
    "\n",
    "    # Then, for each combination of overlapping areas, get the most important\n",
    "    # where rail (major stop) trumps 15min headway; 15min headway trumps 30 min headway etc\n",
    "\n",
    "    union_4['cat5'] = union_4.ngroup.map(union_4.groupby(['ngroup'])[source_frames_ordered].apply(\n",
    "        get_combination_names_hierarchy))\n",
    "\n",
    "    # get the full string list of components in any given unioned area\n",
    "    union_4['ngroup'] = union_4.ngroup.map(union_4.groupby(['ngroup'])[source_frames_ordered].apply(\n",
    "        get_combination_names))\n",
    "\n",
    "    if write_to_disk:\n",
    "        union_4.to_file(f'/Users/aolsen/Downloads/union_4_{scenario}.geojson',driver='GeoJSON')\n",
    "\n",
    "    return union_4, union_4.dissolve('cat5', as_index=False)[['cat5', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ef2e4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buf_dist_qtr = .25\n",
    "# transit_stop_gdf = transit_current\n",
    "# transit_stop_gdf = transit_fbp\n",
    "\n",
    "\n",
    "# qry_str_hdwy_lt15 = \"(am_av_hdwy <= 15) & (pm_av_hdwy <= 15)\"\n",
    "# logger.info(\n",
    "#     f\"Subsetting stops to {qry_str_hdwy_lt15}, and adding {buf_dist_qtr} mile buffer\")\n",
    "# hdwy15_buf_np = subset_and_buffer(\n",
    "#     transit_current, qry_str_hdwy_lt15, buf_dist_qtr)\n",
    "\n",
    "# hdwy15_buf_fbp = subset_and_buffer(\n",
    "#     transit_fbp, qry_str_hdwy_lt15, buf_dist_qtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "1555c195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/19/2024 08:11:45 AM - INFO - Running create_transit_areas function for variant: current\n",
      "03/19/2024 08:11:45 AM - INFO - Running create_transit_areas function for variant: current\n",
      "03/19/2024 08:11:45 AM - INFO - transit_stop_gdf has shape: (40232, 18)\n",
      "03/19/2024 08:11:45 AM - INFO - transit_stop_gdf has shape: (40232, 18)\n",
      "03/19/2024 08:11:45 AM - INFO - Subsetting stops to (major_stop == 1), and adding 0.5 mile buffer\n",
      "03/19/2024 08:11:45 AM - INFO - Subsetting stops to (major_stop == 1), and adding 0.5 mile buffer\n",
      "03/19/2024 08:11:46 AM - INFO - Subsetting stops to (am_av_hdwy <= 15) & (pm_av_hdwy <= 15), and adding 0.25 mile buffer\n",
      "03/19/2024 08:11:46 AM - INFO - Subsetting stops to (am_av_hdwy <= 15) & (pm_av_hdwy <= 15), and adding 0.25 mile buffer\n",
      "03/19/2024 08:11:47 AM - INFO - Subsetting stops to ( am_av_hdwy >15 ) & (am_av_hdwy <=30) & ( pm_av_hdwy >15 ) & (pm_av_hdwy <=30)  , and adding 0.25 mile buffer\n",
      "03/19/2024 08:11:47 AM - INFO - Subsetting stops to ( am_av_hdwy >15 ) & (am_av_hdwy <=30) & ( pm_av_hdwy >15 ) & (pm_av_hdwy <=30)  , and adding 0.25 mile buffer\n",
      "03/19/2024 08:11:47 AM - INFO - Subsetting stops to (am_av_hdwy > 30) | (pm_av_hdwy > 30), and adding 0.25 mile buffer\n",
      "03/19/2024 08:11:47 AM - INFO - Subsetting stops to (am_av_hdwy > 30) | (pm_av_hdwy > 30), and adding 0.25 mile buffer\n",
      "03/19/2024 08:11:49 AM - INFO - Beginning a series of unions, to get all buffers to fully define regional space\n",
      "03/19/2024 08:11:49 AM - INFO - Beginning a series of unions, to get all buffers to fully define regional space\n",
      "03/19/2024 08:11:49 AM - INFO - Unioning hdwy15_buf and hdwy30_buf\n",
      "03/19/2024 08:11:49 AM - INFO - Unioning hdwy15_buf and hdwy30_buf\n",
      "03/19/2024 08:11:50 AM - INFO - union_1 shape: (3, 4)\n",
      "03/19/2024 08:11:50 AM - INFO - union_1 shape: (3, 4)\n",
      "03/19/2024 08:11:50 AM - INFO - Adding hdwy30plus_buf...\n",
      "03/19/2024 08:11:50 AM - INFO - Adding hdwy30plus_buf...\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/2272224740.py:68: UserWarning: `keep_geom_type=True` in overlay resulted in 1269 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  union_2 = gpd.overlay(union_1, hdwy30plus_buf, how='union').reset_index().rename(\n",
      "03/19/2024 08:11:52 AM - INFO - union_2 shape: (7, 6)\n",
      "03/19/2024 08:11:52 AM - INFO - union_2 shape: (7, 6)\n",
      "03/19/2024 08:11:52 AM - INFO - Adding major stops buffer...\n",
      "03/19/2024 08:11:52 AM - INFO - Adding major stops buffer...\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/2272224740.py:77: UserWarning: `keep_geom_type=True` in overlay resulted in 358 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  union_3 = gpd.overlay(union_2, major_buf, how='union').reset_index(\n",
      "03/19/2024 08:12:24 AM - INFO - union_3 shape: (15, 8)\n",
      "03/19/2024 08:12:24 AM - INFO - union_3 shape: (15, 8)\n",
      "03/19/2024 08:12:24 AM - INFO - Adding regional boundary so we can get wall to wall coverage\n",
      "03/19/2024 08:12:24 AM - INFO - Adding regional boundary so we can get wall to wall coverage\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/2272224740.py:87: UserWarning: `keep_geom_type=True` in overlay resulted in 402 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  union_4 = gpd.overlay(union_3, region_bdry, how='union').reset_index(\n",
      "03/19/2024 08:15:55 AM - INFO - union_4 shape: (17, 10)\n",
      "03/19/2024 08:15:55 AM - INFO - union_4 shape: (17, 10)\n",
      "03/19/2024 08:15:55 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:15:55 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:15:55 AM - INFO - union_4 head:                                                                0  \\\n",
      "df_4                                                           0   \n",
      "df_3                                                         0.0   \n",
      "df_2                                                         0.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((607274.2070056344 4206359.9801...   \n",
      "\n",
      "                                                               1  \\\n",
      "df_4                                                           1   \n",
      "df_3                                                         1.0   \n",
      "df_2                                                         1.0   \n",
      "df_1                                                         1.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    NaN   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((627223.7184509137 4096009.9419...   \n",
      "\n",
      "                                                               2  \\\n",
      "df_4                                                           2   \n",
      "df_3                                                         2.0   \n",
      "df_2                                                         2.0   \n",
      "df_1                                                         2.0   \n",
      "hdwy15buf                                                    NaN   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((607395.557061891 4205749.91226...   \n",
      "\n",
      "                                                               3  \\\n",
      "df_4                                                           3   \n",
      "df_3                                                         3.0   \n",
      "df_2                                                         3.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                NaN   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((606840.2754177054 4122184.2163...   \n",
      "\n",
      "                                                               4  \n",
      "df_4                                                           4  \n",
      "df_3                                                         4.0  \n",
      "df_2                                                         4.0  \n",
      "df_1                                                         1.0  \n",
      "hdwy15buf                                                    0.0  \n",
      "hdwy30buf                                                    NaN  \n",
      "hdwy30plusbuf                                                NaN  \n",
      "major_buf                                                    0.0  \n",
      "reg                                                          0.0  \n",
      "geometry       MULTIPOLYGON (((627589.4272867099 4096993.7269...  \n",
      "03/19/2024 08:15:55 AM - INFO - union_4 head:                                                                0  \\\n",
      "df_4                                                           0   \n",
      "df_3                                                         0.0   \n",
      "df_2                                                         0.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((607274.2070056344 4206359.9801...   \n",
      "\n",
      "                                                               1  \\\n",
      "df_4                                                           1   \n",
      "df_3                                                         1.0   \n",
      "df_2                                                         1.0   \n",
      "df_1                                                         1.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    NaN   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((627223.7184509137 4096009.9419...   \n",
      "\n",
      "                                                               2  \\\n",
      "df_4                                                           2   \n",
      "df_3                                                         2.0   \n",
      "df_2                                                         2.0   \n",
      "df_1                                                         2.0   \n",
      "hdwy15buf                                                    NaN   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((607395.557061891 4205749.91226...   \n",
      "\n",
      "                                                               3  \\\n",
      "df_4                                                           3   \n",
      "df_3                                                         3.0   \n",
      "df_2                                                         3.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                NaN   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((606840.2754177054 4122184.2163...   \n",
      "\n",
      "                                                               4  \n",
      "df_4                                                           4  \n",
      "df_3                                                         4.0  \n",
      "df_2                                                         4.0  \n",
      "df_1                                                         1.0  \n",
      "hdwy15buf                                                    0.0  \n",
      "hdwy30buf                                                    NaN  \n",
      "hdwy30plusbuf                                                NaN  \n",
      "major_buf                                                    0.0  \n",
      "reg                                                          0.0  \n",
      "geometry       MULTIPOLYGON (((627589.4272867099 4096993.7269...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/19/2024 08:15:55 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:15:55 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:15:55 AM - INFO - With the full region unioned, we now focus on classifying the different combinations\n",
      "03/19/2024 08:15:55 AM - INFO - With the full region unioned, we now focus on classifying the different combinations\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/1584606566.py:6: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col, val in group.iteritems():\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/1077116334.py:4: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col_name, value in group.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 9s, sys: 965 ms, total: 4min 10s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "transit_areas_current, transit_areas_current_dissolved = create_multiple_transit_areas(\n",
    "    transit_current,'current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c2e2f4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/19/2024 08:15:57 AM - INFO - Running create_transit_areas function for variant: np\n",
      "03/19/2024 08:15:57 AM - INFO - Running create_transit_areas function for variant: np\n",
      "03/19/2024 08:15:57 AM - INFO - transit_stop_gdf has shape: (40237, 18)\n",
      "03/19/2024 08:15:57 AM - INFO - transit_stop_gdf has shape: (40237, 18)\n",
      "03/19/2024 08:15:57 AM - INFO - Subsetting stops to (major_stop == 1), and adding 0.5 mile buffer\n",
      "03/19/2024 08:15:57 AM - INFO - Subsetting stops to (major_stop == 1), and adding 0.5 mile buffer\n",
      "03/19/2024 08:15:57 AM - INFO - Subsetting stops to (am_av_hdwy <= 15) & (pm_av_hdwy <= 15), and adding 0.25 mile buffer\n",
      "03/19/2024 08:15:57 AM - INFO - Subsetting stops to (am_av_hdwy <= 15) & (pm_av_hdwy <= 15), and adding 0.25 mile buffer\n",
      "03/19/2024 08:15:59 AM - INFO - Subsetting stops to ( am_av_hdwy >15 ) & (am_av_hdwy <=30) & ( pm_av_hdwy >15 ) & (pm_av_hdwy <=30)  , and adding 0.25 mile buffer\n",
      "03/19/2024 08:15:59 AM - INFO - Subsetting stops to ( am_av_hdwy >15 ) & (am_av_hdwy <=30) & ( pm_av_hdwy >15 ) & (pm_av_hdwy <=30)  , and adding 0.25 mile buffer\n",
      "03/19/2024 08:15:59 AM - INFO - Subsetting stops to (am_av_hdwy > 30) | (pm_av_hdwy > 30), and adding 0.25 mile buffer\n",
      "03/19/2024 08:15:59 AM - INFO - Subsetting stops to (am_av_hdwy > 30) | (pm_av_hdwy > 30), and adding 0.25 mile buffer\n",
      "03/19/2024 08:16:01 AM - INFO - Beginning a series of unions, to get all buffers to fully define regional space\n",
      "03/19/2024 08:16:01 AM - INFO - Beginning a series of unions, to get all buffers to fully define regional space\n",
      "03/19/2024 08:16:01 AM - INFO - Unioning hdwy15_buf and hdwy30_buf\n",
      "03/19/2024 08:16:01 AM - INFO - Unioning hdwy15_buf and hdwy30_buf\n",
      "03/19/2024 08:16:02 AM - INFO - union_1 shape: (3, 4)\n",
      "03/19/2024 08:16:02 AM - INFO - union_1 shape: (3, 4)\n",
      "03/19/2024 08:16:02 AM - INFO - Adding hdwy30plus_buf...\n",
      "03/19/2024 08:16:02 AM - INFO - Adding hdwy30plus_buf...\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/2272224740.py:68: UserWarning: `keep_geom_type=True` in overlay resulted in 1269 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  union_2 = gpd.overlay(union_1, hdwy30plus_buf, how='union').reset_index().rename(\n",
      "03/19/2024 08:16:04 AM - INFO - union_2 shape: (7, 6)\n",
      "03/19/2024 08:16:04 AM - INFO - union_2 shape: (7, 6)\n",
      "03/19/2024 08:16:04 AM - INFO - Adding major stops buffer...\n",
      "03/19/2024 08:16:04 AM - INFO - Adding major stops buffer...\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/2272224740.py:77: UserWarning: `keep_geom_type=True` in overlay resulted in 361 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  union_3 = gpd.overlay(union_2, major_buf, how='union').reset_index(\n",
      "03/19/2024 08:16:40 AM - INFO - union_3 shape: (15, 8)\n",
      "03/19/2024 08:16:40 AM - INFO - union_3 shape: (15, 8)\n",
      "03/19/2024 08:16:40 AM - INFO - Adding regional boundary so we can get wall to wall coverage\n",
      "03/19/2024 08:16:40 AM - INFO - Adding regional boundary so we can get wall to wall coverage\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/2272224740.py:87: UserWarning: `keep_geom_type=True` in overlay resulted in 402 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  union_4 = gpd.overlay(union_3, region_bdry, how='union').reset_index(\n",
      "03/19/2024 08:20:04 AM - INFO - union_4 shape: (17, 10)\n",
      "03/19/2024 08:20:04 AM - INFO - union_4 shape: (17, 10)\n",
      "03/19/2024 08:20:04 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:20:04 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:20:04 AM - INFO - union_4 head:                                                                0  \\\n",
      "df_4                                                           0   \n",
      "df_3                                                         0.0   \n",
      "df_2                                                         0.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((607274.2070056344 4206359.9801...   \n",
      "\n",
      "                                                               1  \\\n",
      "df_4                                                           1   \n",
      "df_3                                                         1.0   \n",
      "df_2                                                         1.0   \n",
      "df_1                                                         1.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    NaN   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((627223.7184509137 4096009.9419...   \n",
      "\n",
      "                                                               2  \\\n",
      "df_4                                                           2   \n",
      "df_3                                                         2.0   \n",
      "df_2                                                         2.0   \n",
      "df_1                                                         2.0   \n",
      "hdwy15buf                                                    NaN   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((607395.557061891 4205749.91226...   \n",
      "\n",
      "                                                               3  \\\n",
      "df_4                                                           3   \n",
      "df_3                                                         3.0   \n",
      "df_2                                                         3.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                NaN   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((606840.2754177054 4122184.2163...   \n",
      "\n",
      "                                                               4  \n",
      "df_4                                                           4  \n",
      "df_3                                                         4.0  \n",
      "df_2                                                         4.0  \n",
      "df_1                                                         1.0  \n",
      "hdwy15buf                                                    0.0  \n",
      "hdwy30buf                                                    NaN  \n",
      "hdwy30plusbuf                                                NaN  \n",
      "major_buf                                                    0.0  \n",
      "reg                                                          0.0  \n",
      "geometry       MULTIPOLYGON (((627589.4272867099 4096993.7269...  \n",
      "03/19/2024 08:20:04 AM - INFO - union_4 head:                                                                0  \\\n",
      "df_4                                                           0   \n",
      "df_3                                                         0.0   \n",
      "df_2                                                         0.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((607274.2070056344 4206359.9801...   \n",
      "\n",
      "                                                               1  \\\n",
      "df_4                                                           1   \n",
      "df_3                                                         1.0   \n",
      "df_2                                                         1.0   \n",
      "df_1                                                         1.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    NaN   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((627223.7184509137 4096009.9419...   \n",
      "\n",
      "                                                               2  \\\n",
      "df_4                                                           2   \n",
      "df_3                                                         2.0   \n",
      "df_2                                                         2.0   \n",
      "df_1                                                         2.0   \n",
      "hdwy15buf                                                    NaN   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((607395.557061891 4205749.91226...   \n",
      "\n",
      "                                                               3  \\\n",
      "df_4                                                           3   \n",
      "df_3                                                         3.0   \n",
      "df_2                                                         3.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                NaN   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((606840.2754177054 4122184.2163...   \n",
      "\n",
      "                                                               4  \n",
      "df_4                                                           4  \n",
      "df_3                                                         4.0  \n",
      "df_2                                                         4.0  \n",
      "df_1                                                         1.0  \n",
      "hdwy15buf                                                    0.0  \n",
      "hdwy30buf                                                    NaN  \n",
      "hdwy30plusbuf                                                NaN  \n",
      "major_buf                                                    0.0  \n",
      "reg                                                          0.0  \n",
      "geometry       MULTIPOLYGON (((627589.4272867099 4096993.7269...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/19/2024 08:20:04 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:20:04 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:20:04 AM - INFO - With the full region unioned, we now focus on classifying the different combinations\n",
      "03/19/2024 08:20:04 AM - INFO - With the full region unioned, we now focus on classifying the different combinations\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/1584606566.py:6: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col, val in group.iteritems():\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/1077116334.py:4: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col_name, value in group.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 7s, sys: 570 ms, total: 4min 8s\n",
      "Wall time: 4min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "transit_areas_np, transit_areas_np_dissolved = create_multiple_transit_areas(\n",
    "    transit_np,'np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "1bf22b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/19/2024 08:20:06 AM - INFO - Running create_transit_areas function for variant: fbp\n",
      "03/19/2024 08:20:06 AM - INFO - Running create_transit_areas function for variant: fbp\n",
      "03/19/2024 08:20:06 AM - INFO - transit_stop_gdf has shape: (40577, 18)\n",
      "03/19/2024 08:20:06 AM - INFO - transit_stop_gdf has shape: (40577, 18)\n",
      "03/19/2024 08:20:06 AM - INFO - Subsetting stops to (major_stop == 1), and adding 0.5 mile buffer\n",
      "03/19/2024 08:20:06 AM - INFO - Subsetting stops to (major_stop == 1), and adding 0.5 mile buffer\n",
      "03/19/2024 08:20:07 AM - INFO - Subsetting stops to (am_av_hdwy <= 15) & (pm_av_hdwy <= 15), and adding 0.25 mile buffer\n",
      "03/19/2024 08:20:07 AM - INFO - Subsetting stops to (am_av_hdwy <= 15) & (pm_av_hdwy <= 15), and adding 0.25 mile buffer\n",
      "03/19/2024 08:20:08 AM - INFO - Subsetting stops to ( am_av_hdwy >15 ) & (am_av_hdwy <=30) & ( pm_av_hdwy >15 ) & (pm_av_hdwy <=30)  , and adding 0.25 mile buffer\n",
      "03/19/2024 08:20:08 AM - INFO - Subsetting stops to ( am_av_hdwy >15 ) & (am_av_hdwy <=30) & ( pm_av_hdwy >15 ) & (pm_av_hdwy <=30)  , and adding 0.25 mile buffer\n",
      "03/19/2024 08:20:08 AM - INFO - Subsetting stops to (am_av_hdwy > 30) | (pm_av_hdwy > 30), and adding 0.25 mile buffer\n",
      "03/19/2024 08:20:08 AM - INFO - Subsetting stops to (am_av_hdwy > 30) | (pm_av_hdwy > 30), and adding 0.25 mile buffer\n",
      "03/19/2024 08:20:10 AM - INFO - Beginning a series of unions, to get all buffers to fully define regional space\n",
      "03/19/2024 08:20:10 AM - INFO - Beginning a series of unions, to get all buffers to fully define regional space\n",
      "03/19/2024 08:20:10 AM - INFO - Unioning hdwy15_buf and hdwy30_buf\n",
      "03/19/2024 08:20:10 AM - INFO - Unioning hdwy15_buf and hdwy30_buf\n",
      "03/19/2024 08:20:10 AM - INFO - union_1 shape: (3, 4)\n",
      "03/19/2024 08:20:10 AM - INFO - union_1 shape: (3, 4)\n",
      "03/19/2024 08:20:10 AM - INFO - Adding hdwy30plus_buf...\n",
      "03/19/2024 08:20:10 AM - INFO - Adding hdwy30plus_buf...\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/2272224740.py:68: UserWarning: `keep_geom_type=True` in overlay resulted in 1269 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  union_2 = gpd.overlay(union_1, hdwy30plus_buf, how='union').reset_index().rename(\n",
      "03/19/2024 08:20:12 AM - INFO - union_2 shape: (7, 6)\n",
      "03/19/2024 08:20:12 AM - INFO - union_2 shape: (7, 6)\n",
      "03/19/2024 08:20:12 AM - INFO - Adding major stops buffer...\n",
      "03/19/2024 08:20:12 AM - INFO - Adding major stops buffer...\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/2272224740.py:77: UserWarning: `keep_geom_type=True` in overlay resulted in 432 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  union_3 = gpd.overlay(union_2, major_buf, how='union').reset_index(\n",
      "03/19/2024 08:21:14 AM - INFO - union_3 shape: (15, 8)\n",
      "03/19/2024 08:21:14 AM - INFO - union_3 shape: (15, 8)\n",
      "03/19/2024 08:21:14 AM - INFO - Adding regional boundary so we can get wall to wall coverage\n",
      "03/19/2024 08:21:14 AM - INFO - Adding regional boundary so we can get wall to wall coverage\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/2272224740.py:87: UserWarning: `keep_geom_type=True` in overlay resulted in 402 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  union_4 = gpd.overlay(union_3, region_bdry, how='union').reset_index(\n",
      "03/19/2024 08:24:48 AM - INFO - union_4 shape: (19, 10)\n",
      "03/19/2024 08:24:48 AM - INFO - union_4 shape: (19, 10)\n",
      "03/19/2024 08:24:48 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:24:48 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:24:48 AM - INFO - union_4 head:                                                                0  \\\n",
      "df_4                                                           0   \n",
      "df_3                                                         0.0   \n",
      "df_2                                                         0.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((607274.2070056344 4206359.9801...   \n",
      "\n",
      "                                                               1  \\\n",
      "df_4                                                           1   \n",
      "df_3                                                         1.0   \n",
      "df_2                                                         1.0   \n",
      "df_1                                                         1.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    NaN   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((627223.7184509137 4096009.9419...   \n",
      "\n",
      "                                                               2  \\\n",
      "df_4                                                           2   \n",
      "df_3                                                         2.0   \n",
      "df_2                                                         2.0   \n",
      "df_1                                                         2.0   \n",
      "hdwy15buf                                                    NaN   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((612448.9424964967 4206028.2876...   \n",
      "\n",
      "                                                               3  \\\n",
      "df_4                                                           3   \n",
      "df_3                                                         3.0   \n",
      "df_2                                                         3.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                NaN   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((606840.2754177054 4122184.2163...   \n",
      "\n",
      "                                                               4  \n",
      "df_4                                                           4  \n",
      "df_3                                                         4.0  \n",
      "df_2                                                         4.0  \n",
      "df_1                                                         1.0  \n",
      "hdwy15buf                                                    0.0  \n",
      "hdwy30buf                                                    NaN  \n",
      "hdwy30plusbuf                                                NaN  \n",
      "major_buf                                                    0.0  \n",
      "reg                                                          0.0  \n",
      "geometry       MULTIPOLYGON (((627589.4272867099 4096993.7269...  \n",
      "03/19/2024 08:24:48 AM - INFO - union_4 head:                                                                0  \\\n",
      "df_4                                                           0   \n",
      "df_3                                                         0.0   \n",
      "df_2                                                         0.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((607274.2070056344 4206359.9801...   \n",
      "\n",
      "                                                               1  \\\n",
      "df_4                                                           1   \n",
      "df_3                                                         1.0   \n",
      "df_2                                                         1.0   \n",
      "df_1                                                         1.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    NaN   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((627223.7184509137 4096009.9419...   \n",
      "\n",
      "                                                               2  \\\n",
      "df_4                                                           2   \n",
      "df_3                                                         2.0   \n",
      "df_2                                                         2.0   \n",
      "df_1                                                         2.0   \n",
      "hdwy15buf                                                    NaN   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                0.0   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((612448.9424964967 4206028.2876...   \n",
      "\n",
      "                                                               3  \\\n",
      "df_4                                                           3   \n",
      "df_3                                                         3.0   \n",
      "df_2                                                         3.0   \n",
      "df_1                                                         0.0   \n",
      "hdwy15buf                                                    0.0   \n",
      "hdwy30buf                                                    0.0   \n",
      "hdwy30plusbuf                                                NaN   \n",
      "major_buf                                                    0.0   \n",
      "reg                                                          0.0   \n",
      "geometry       MULTIPOLYGON (((606840.2754177054 4122184.2163...   \n",
      "\n",
      "                                                               4  \n",
      "df_4                                                           4  \n",
      "df_3                                                         4.0  \n",
      "df_2                                                         4.0  \n",
      "df_1                                                         1.0  \n",
      "hdwy15buf                                                    0.0  \n",
      "hdwy30buf                                                    NaN  \n",
      "hdwy30plusbuf                                                NaN  \n",
      "major_buf                                                    0.0  \n",
      "reg                                                          0.0  \n",
      "geometry       MULTIPOLYGON (((627589.4272867099 4096993.7269...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/19/2024 08:24:48 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:24:48 AM - INFO - --------------------------------------------------------------------------------\n",
      "03/19/2024 08:24:48 AM - INFO - With the full region unioned, we now focus on classifying the different combinations\n",
      "03/19/2024 08:24:48 AM - INFO - With the full region unioned, we now focus on classifying the different combinations\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/1584606566.py:6: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col, val in group.iteritems():\n",
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/1077116334.py:4: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col_name, value in group.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 43s, sys: 442 ms, total: 4min 43s\n",
      "Wall time: 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "transit_areas_fbp, transit_areas_fbp_dissolved = create_multiple_transit_areas(\n",
    "    transit_fbp,'fbp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "fd4f04b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_areas_fbp_dissolved.to_file('/Users/aolsen/Downloads/transit_areas_fbp_dissolved.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "15a7974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_areas_current_dissolved.to_file('/Users/aolsen/Downloads/transit_areas_current_dissolved.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "6706b138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/2050997278.py:1: UserWarning: `keep_geom_type=True` in overlay resulted in 17046 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  mine_vs_bobbys_fbp = gpd.overlay(v2020_fbp_classes.to_crs(ANALYSIS_CRS),transit_areas_fbp_dissolved)\n"
     ]
    }
   ],
   "source": [
    "mine_vs_bobbys_fbp = gpd.overlay(v2020_fbp_classes.to_crs(ANALYSIS_CRS),transit_areas_fbp_dissolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73144453",
   "metadata": {},
   "outputs": [],
   "source": [
    "mine_vs_bobbys_fbp['area'] = mine_vs_bobbys_fbp.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "2b5ad47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/3_n775lx7zq1nv3mddc7vmlh0000gp/T/ipykernel_32079/615562494.py:2: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  mine_vs_bobbys_fbp.groupby(['Service_Level','cat5']).area.sum().groupby(level=0,observed=True).apply(pct).round(2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Service_Level       cat5              \n",
       "hdwy15buf_only      hdwy15buf_only        0.64\n",
       "                    hdwy30buf_only        0.06\n",
       "                    hdwy30plusbuf_only    0.03\n",
       "                    major_buf_only        0.21\n",
       "                    none                  0.06\n",
       "hdwy30buf_only      hdwy15buf_only        0.03\n",
       "                    hdwy30buf_only        0.70\n",
       "                    hdwy30plusbuf_only    0.16\n",
       "                    major_buf_only        0.07\n",
       "                    none                  0.04\n",
       "hdwy30plusbuf_only  hdwy15buf_only        0.00\n",
       "                    hdwy30buf_only        0.03\n",
       "                    hdwy30plusbuf_only    0.80\n",
       "                    major_buf_only        0.02\n",
       "                    none                  0.15\n",
       "majorbuf            hdwy15buf_only        0.07\n",
       "                    hdwy30buf_only        0.01\n",
       "                    hdwy30plusbuf_only    0.02\n",
       "                    major_buf_only        0.82\n",
       "                    none                  0.09\n",
       "none                hdwy15buf_only        0.00\n",
       "                    hdwy30buf_only        0.00\n",
       "                    hdwy30plusbuf_only    0.00\n",
       "                    major_buf_only        0.00\n",
       "                    none                  1.00\n",
       "Name: area, dtype: float64"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct = lambda x: x/x.sum()\n",
    "mine_vs_bobbys_fbp.groupby(['Service_Level','cat5']).area.sum().groupby(level=0,observed=True).apply(pct).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "017eec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transit_areas_current.explore(column='cat5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "cded5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transit_areas_fbp.explore(column='cat5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f63e782",
   "metadata": {},
   "source": [
    "## Step 2 - relate transit proximities to parcels (before adding any run specific data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "38fa8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_parcels(parcels_geo, transit_areas, scenario='current'):\n",
    "\n",
    "    logger.info(f'Joining transit areas ({scenario}) to parcels')\n",
    "\n",
    "    # core assignment, per sjoin\n",
    "    p10_x_transit_areas = gpd.sjoin(parcels_geo, transit_areas)\n",
    "\n",
    "    # check for unassigned\n",
    "    unassigned_parcel_ids = set(\n",
    "        parcels_geo.PARCEL_ID)-set(p10_x_transit_areas.PARCEL_ID)\n",
    "\n",
    "    logger.info(\n",
    "        f'There were {len(unassigned_parcel_ids)} parcels without an assignment to a transit area.\\nWe assign to nearest area.')\n",
    "\n",
    "    p10_x_transit_areas_remainder = gpd.sjoin_nearest(parcels_geo.query(\n",
    "        'PARCEL_ID.isin(@unassigned_parcel_ids)'), transit_areas)\n",
    "\n",
    "    # combine the two\n",
    "    combo_assignments = pd.concat(\n",
    "        [p10_x_transit_areas, p10_x_transit_areas_remainder])\n",
    "\n",
    "    if (combo_assignments.PARCEL_ID.value_counts().sort_values() > 1).any():\n",
    "\n",
    "        # if there are parcel duplicates - get the fist classification\n",
    "        mapping = combo_assignments.groupby(\n",
    "            'PARCEL_ID').cat5.first()\n",
    "    else:\n",
    "        # return the original mapping\n",
    "\n",
    "        mapping = combo_assignments.set_index('PARCEL_ID').cat5\n",
    "\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c5b0a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/19/2024 08:28:23 AM - INFO - Joining transit areas (np) to parcels\n",
      "03/19/2024 08:28:23 AM - INFO - Joining transit areas (np) to parcels\n",
      "03/19/2024 08:36:41 AM - INFO - There were 72 parcels without an assignment to a transit area.\n",
      "We assign to nearest area.\n",
      "03/19/2024 08:36:41 AM - INFO - There were 72 parcels without an assignment to a transit area.\n",
      "We assign to nearest area.\n"
     ]
    }
   ],
   "source": [
    "p10_x_transit_area_np = classify_parcels(p10_topofix_pt, transit_areas_np_dissolved, 'np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "21c8c660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/19/2024 08:36:42 AM - INFO - Joining transit areas (fbp) to parcels\n",
      "03/19/2024 08:36:42 AM - INFO - Joining transit areas (fbp) to parcels\n",
      "03/19/2024 08:45:21 AM - INFO - There were 72 parcels without an assignment to a transit area.\n",
      "We assign to nearest area.\n",
      "03/19/2024 08:45:21 AM - INFO - There were 72 parcels without an assignment to a transit area.\n",
      "We assign to nearest area.\n"
     ]
    }
   ],
   "source": [
    "p10_x_transit_area_fbp = classify_parcels(p10_topofix_pt, transit_areas_fbp_dissolved, 'fbp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "689b4184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/19/2024 08:45:22 AM - INFO - Joining transit areas (current) to parcels\n",
      "03/19/2024 08:45:22 AM - INFO - Joining transit areas (current) to parcels\n",
      "03/19/2024 08:54:08 AM - INFO - There were 72 parcels without an assignment to a transit area.\n",
      "We assign to nearest area.\n",
      "03/19/2024 08:54:08 AM - INFO - There were 72 parcels without an assignment to a transit area.\n",
      "We assign to nearest area.\n"
     ]
    }
   ],
   "source": [
    "p10_x_transit_area_current = classify_parcels(p10_topofix_pt, transit_areas_current_dissolved, 'current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "9ae04490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none                  750973\n",
       "major_buf_only        420949\n",
       "hdwy30plusbuf_only    344821\n",
       "hdwy30buf_only        286332\n",
       "hdwy15buf_only        153132\n",
       "Name: cat5, dtype: int64"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p10_x_transit_area_np.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "7207e306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none                  728135\n",
       "major_buf_only        504425\n",
       "hdwy30plusbuf_only    334198\n",
       "hdwy30buf_only        263644\n",
       "hdwy15buf_only        125805\n",
       "Name: cat5, dtype: int64"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p10_x_transit_area_fbp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "aca6b8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none                  750984\n",
       "major_buf_only        419789\n",
       "hdwy30plusbuf_only    345460\n",
       "hdwy30buf_only        286842\n",
       "hdwy15buf_only        153132\n",
       "Name: cat5, dtype: int64"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p10_x_transit_area_current.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21349ce5",
   "metadata": {},
   "source": [
    "## Step 3 load run data and classify based on parcel_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead6390",
   "metadata": {},
   "source": [
    "## Step 4: run the summaries\n",
    "Note that we want to do the proper matching:\n",
    "* 2015 should always be \"current\"\n",
    "* 2050 blueprint should be matched with 2050 blueprint transit buffers\n",
    "* 2050 no project should be matched with 2050 no project transit buffers\n",
    "\n",
    "We are looking for output as follows [metrics_proximity.csv](https://mtcdrive.app.box.com/file/837349294434)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "2d5339bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_proximity_target_schema = pd.read_csv('/Users/aolsen/Box/Horizon and Plan Bay Area 2050/Equity and Performance/7_Analysis/Metrics/Metrics_Outputs_FinalBlueprint/Intermediate Metrics/Archive Draft Plan Mar 2021/metrics_proximity.csv')\n",
    "schema_iteration_vars = ['Service_Level', 'year', 'modelrunID', 'transit', 'area', 'blueprint']\n",
    "#metrics_proximity_target_schema.groupby(schema_iteration_vars).size().unstack('modelrunID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "0681b9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Service_Level</th>\n",
       "      <th>tothh</th>\n",
       "      <th>hhq1</th>\n",
       "      <th>totemp</th>\n",
       "      <th>RETEMPN</th>\n",
       "      <th>MWTEMPN</th>\n",
       "      <th>tothh_share</th>\n",
       "      <th>hhq1_share</th>\n",
       "      <th>totemp_share</th>\n",
       "      <th>RETEMPN_share</th>\n",
       "      <th>MWTEMPN_share</th>\n",
       "      <th>year</th>\n",
       "      <th>modelrunID</th>\n",
       "      <th>transit</th>\n",
       "      <th>area</th>\n",
       "      <th>blueprint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bus_15_30min</td>\n",
       "      <td>210239</td>\n",
       "      <td>53589</td>\n",
       "      <td>327518</td>\n",
       "      <td>34854</td>\n",
       "      <td>63036</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2015</td>\n",
       "      <td>EIR runs/Baseline Large (s25) runs/NP_v8_FINAL...</td>\n",
       "      <td>trn_cur_cat5</td>\n",
       "      <td>Region</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bus_31plus_min</td>\n",
       "      <td>252087</td>\n",
       "      <td>60293</td>\n",
       "      <td>313339</td>\n",
       "      <td>30186</td>\n",
       "      <td>64931</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2015</td>\n",
       "      <td>EIR runs/Baseline Large (s25) runs/NP_v8_FINAL...</td>\n",
       "      <td>trn_cur_cat5</td>\n",
       "      <td>Region</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bus_&lt;15min</td>\n",
       "      <td>734378</td>\n",
       "      <td>182796</td>\n",
       "      <td>1013274</td>\n",
       "      <td>105929</td>\n",
       "      <td>141030</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2015</td>\n",
       "      <td>EIR runs/Baseline Large (s25) runs/NP_v8_FINAL...</td>\n",
       "      <td>trn_cur_cat5</td>\n",
       "      <td>Region</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Major_Transit_Stop</td>\n",
       "      <td>834542</td>\n",
       "      <td>284096</td>\n",
       "      <td>1814001</td>\n",
       "      <td>147104</td>\n",
       "      <td>194061</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2015</td>\n",
       "      <td>EIR runs/Baseline Large (s25) runs/NP_v8_FINAL...</td>\n",
       "      <td>trn_cur_cat5</td>\n",
       "      <td>Region</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No_Fixed_Route_Transit</td>\n",
       "      <td>645330</td>\n",
       "      <td>125662</td>\n",
       "      <td>537186</td>\n",
       "      <td>39997</td>\n",
       "      <td>120531</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2015</td>\n",
       "      <td>EIR runs/Baseline Large (s25) runs/NP_v8_FINAL...</td>\n",
       "      <td>trn_cur_cat5</td>\n",
       "      <td>Region</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Bus_15_30min</td>\n",
       "      <td>120397</td>\n",
       "      <td>18778</td>\n",
       "      <td>165588</td>\n",
       "      <td>14482</td>\n",
       "      <td>23283</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2050</td>\n",
       "      <td>Final Blueprint runs/Final Blueprint (s24)/BAU...</td>\n",
       "      <td>trn_fp_cat5</td>\n",
       "      <td>urban</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Bus_31plus_min</td>\n",
       "      <td>94916</td>\n",
       "      <td>15699</td>\n",
       "      <td>160529</td>\n",
       "      <td>8605</td>\n",
       "      <td>21330</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2050</td>\n",
       "      <td>Final Blueprint runs/Final Blueprint (s24)/BAU...</td>\n",
       "      <td>trn_fp_cat5</td>\n",
       "      <td>urban</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Bus_&lt;15min</td>\n",
       "      <td>359033</td>\n",
       "      <td>73603</td>\n",
       "      <td>590057</td>\n",
       "      <td>50399</td>\n",
       "      <td>56175</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2050</td>\n",
       "      <td>Final Blueprint runs/Final Blueprint (s24)/BAU...</td>\n",
       "      <td>trn_fp_cat5</td>\n",
       "      <td>urban</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Major_Transit_Stop</td>\n",
       "      <td>1661800</td>\n",
       "      <td>629793</td>\n",
       "      <td>2481872</td>\n",
       "      <td>186682</td>\n",
       "      <td>159490</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2050</td>\n",
       "      <td>Final Blueprint runs/Final Blueprint (s24)/BAU...</td>\n",
       "      <td>trn_fp_cat5</td>\n",
       "      <td>urban</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>No_Fixed_Route_Transit</td>\n",
       "      <td>149242</td>\n",
       "      <td>21209</td>\n",
       "      <td>223456</td>\n",
       "      <td>10617</td>\n",
       "      <td>42897</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2050</td>\n",
       "      <td>Final Blueprint runs/Final Blueprint (s24)/BAU...</td>\n",
       "      <td>trn_fp_cat5</td>\n",
       "      <td>urban</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Service_Level    tothh    hhq1   totemp  RETEMPN  MWTEMPN  \\\n",
       "0              Bus_15_30min   210239   53589   327518    34854    63036   \n",
       "1            Bus_31plus_min   252087   60293   313339    30186    64931   \n",
       "2                Bus_<15min   734378  182796  1013274   105929   141030   \n",
       "3        Major_Transit_Stop   834542  284096  1814001   147104   194061   \n",
       "4    No_Fixed_Route_Transit   645330  125662   537186    39997   120531   \n",
       "..                      ...      ...     ...      ...      ...      ...   \n",
       "355            Bus_15_30min   120397   18778   165588    14482    23283   \n",
       "356          Bus_31plus_min    94916   15699   160529     8605    21330   \n",
       "357              Bus_<15min   359033   73603   590057    50399    56175   \n",
       "358      Major_Transit_Stop  1661800  629793  2481872   186682   159490   \n",
       "359  No_Fixed_Route_Transit   149242   21209   223456    10617    42897   \n",
       "\n",
       "     tothh_share  hhq1_share  totemp_share  RETEMPN_share  MWTEMPN_share  \\\n",
       "0           0.08        0.08          0.08           0.10           0.11   \n",
       "1           0.09        0.09          0.08           0.08           0.11   \n",
       "2           0.27        0.26          0.25           0.30           0.24   \n",
       "3           0.31        0.40          0.45           0.41           0.33   \n",
       "4           0.24        0.18          0.13           0.11           0.21   \n",
       "..           ...         ...           ...            ...            ...   \n",
       "355         0.03        0.02          0.03           0.03           0.04   \n",
       "356         0.02        0.02          0.03           0.02           0.04   \n",
       "357         0.09        0.07          0.11           0.11           0.09   \n",
       "358         0.41        0.63          0.46           0.42           0.26   \n",
       "359         0.04        0.02          0.04           0.02           0.07   \n",
       "\n",
       "     year                                         modelrunID       transit  \\\n",
       "0    2015  EIR runs/Baseline Large (s25) runs/NP_v8_FINAL...  trn_cur_cat5   \n",
       "1    2015  EIR runs/Baseline Large (s25) runs/NP_v8_FINAL...  trn_cur_cat5   \n",
       "2    2015  EIR runs/Baseline Large (s25) runs/NP_v8_FINAL...  trn_cur_cat5   \n",
       "3    2015  EIR runs/Baseline Large (s25) runs/NP_v8_FINAL...  trn_cur_cat5   \n",
       "4    2015  EIR runs/Baseline Large (s25) runs/NP_v8_FINAL...  trn_cur_cat5   \n",
       "..    ...                                                ...           ...   \n",
       "355  2050  Final Blueprint runs/Final Blueprint (s24)/BAU...   trn_fp_cat5   \n",
       "356  2050  Final Blueprint runs/Final Blueprint (s24)/BAU...   trn_fp_cat5   \n",
       "357  2050  Final Blueprint runs/Final Blueprint (s24)/BAU...   trn_fp_cat5   \n",
       "358  2050  Final Blueprint runs/Final Blueprint (s24)/BAU...   trn_fp_cat5   \n",
       "359  2050  Final Blueprint runs/Final Blueprint (s24)/BAU...   trn_fp_cat5   \n",
       "\n",
       "       area blueprint  \n",
       "0    Region       NaN  \n",
       "1    Region       NaN  \n",
       "2    Region       NaN  \n",
       "3    Region       NaN  \n",
       "4    Region       NaN  \n",
       "..      ...       ...  \n",
       "355   urban      Plus  \n",
       "356   urban      Plus  \n",
       "357   urban      Plus  \n",
       "358   urban      Plus  \n",
       "359   urban      Plus  \n",
       "\n",
       "[360 rows x 16 columns]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_proximity_target_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "49be9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_scenario_crosswalk = {'trn_cur_cat5': p10_x_transit_area_current,\n",
    "                              'trn_fp_cat5': p10_x_transit_area_fbp,\n",
    "                              'trn_np_cat5': p10_x_transit_area_np}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "95ec1267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['none', 'major_buf_only', 'hdwy30plusbuf_only', 'hdwy30buf_only',\n",
       "       'hdwy15buf_only'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p10_x_transit_area_current.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "d277917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/19/2024 01:28:54 PM - INFO - trt records with no value assigned: 17\n",
      "03/19/2024 01:28:54 PM - INFO - trt records with no value assigned: 17\n"
     ]
    }
   ],
   "source": [
    "def col_values(s, colname):\n",
    "    #msg = f'values for {colname}\\n n{s.value_counts()}'\n",
    "    msg2 = f'{colname} records with no value assigned: {len(s[s.isna()])}'\n",
    "    #logger.info(msg)\n",
    "    logger.info(msg2)\n",
    "    \n",
    "\n",
    "col_values(parcel_x_tracts.tract10,'trt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "a790cb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/19/2024 01:38:37 PM - INFO -   Read 1956212 rows\n",
      "03/19/2024 01:38:37 PM - INFO -   Read 1956212 rows\n",
      "03/19/2024 01:38:37 PM - INFO - Head:\n",
      "   Unnamed: 0  parcel_id           x          y                  juris  \\\n",
      "0           0     229116 -121.795620  37.655379              livermore   \n",
      "1           1     244166 -121.713004  37.717277              livermore   \n",
      "2           2     202378 -122.014199  37.655260                hayward   \n",
      "3           3    2004420 -122.771868  38.727893  unincorporated_sonoma   \n",
      "4           4     340332 -121.974508  37.546277                fremont   \n",
      "\n",
      "          fbpchcat  hhq1  hhq2  hhq3  hhq4  ...      tract10      coc  \\\n",
      "0   NANAHRADISNAin   NaN   NaN   NaN   NaN  ...  06001451102  Not EPC   \n",
      "1    NAtra3DISNAin   NaN   NaN   NaN   NaN  ...  06001451101  Not EPC   \n",
      "2       NANANANAin   2.0   5.0  10.0  16.0  ...  06001435103  Not EPC   \n",
      "3  NANAHRADISNAout   NaN   NaN   NaN   NaN  ...  06097154100  Not EPC   \n",
      "4   NANAHRADISNAin   NaN   NaN   NaN   NaN  ...  06001441927  Not EPC   \n",
      "\n",
      "        service_level      service_level_desc      tract20    epc21    epc25  \\\n",
      "0                none  No_Fixed_Route_Transit  06001451102  Not EPC  Not EPC   \n",
      "1                none  No_Fixed_Route_Transit  06001451104  Not EPC  Not EPC   \n",
      "2  hdwy30plusbuf_only          Bus_31plus_min  06001435103  Not EPC  Not EPC   \n",
      "3                none  No_Fixed_Route_Transit  06097154100  Not EPC  Not EPC   \n",
      "4  hdwy30plusbuf_only          Bus_31plus_min  06001441927  Not EPC  Not EPC   \n",
      "\n",
      "            Service_Level  is_epc21  is_epc25  \n",
      "0  No_Fixed_Route_Transit     False     False  \n",
      "1  No_Fixed_Route_Transit     False     False  \n",
      "2          Bus_31plus_min     False     False  \n",
      "3  No_Fixed_Route_Transit     False     False  \n",
      "4          Bus_31plus_min     False     False  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "03/19/2024 01:38:37 PM - INFO - Head:\n",
      "   Unnamed: 0  parcel_id           x          y                  juris  \\\n",
      "0           0     229116 -121.795620  37.655379              livermore   \n",
      "1           1     244166 -121.713004  37.717277              livermore   \n",
      "2           2     202378 -122.014199  37.655260                hayward   \n",
      "3           3    2004420 -122.771868  38.727893  unincorporated_sonoma   \n",
      "4           4     340332 -121.974508  37.546277                fremont   \n",
      "\n",
      "          fbpchcat  hhq1  hhq2  hhq3  hhq4  ...      tract10      coc  \\\n",
      "0   NANAHRADISNAin   NaN   NaN   NaN   NaN  ...  06001451102  Not EPC   \n",
      "1    NAtra3DISNAin   NaN   NaN   NaN   NaN  ...  06001451101  Not EPC   \n",
      "2       NANANANAin   2.0   5.0  10.0  16.0  ...  06001435103  Not EPC   \n",
      "3  NANAHRADISNAout   NaN   NaN   NaN   NaN  ...  06097154100  Not EPC   \n",
      "4   NANAHRADISNAin   NaN   NaN   NaN   NaN  ...  06001441927  Not EPC   \n",
      "\n",
      "        service_level      service_level_desc      tract20    epc21    epc25  \\\n",
      "0                none  No_Fixed_Route_Transit  06001451102  Not EPC  Not EPC   \n",
      "1                none  No_Fixed_Route_Transit  06001451104  Not EPC  Not EPC   \n",
      "2  hdwy30plusbuf_only          Bus_31plus_min  06001435103  Not EPC  Not EPC   \n",
      "3                none  No_Fixed_Route_Transit  06097154100  Not EPC  Not EPC   \n",
      "4  hdwy30plusbuf_only          Bus_31plus_min  06001441927  Not EPC  Not EPC   \n",
      "\n",
      "            Service_Level  is_epc21  is_epc25  \n",
      "0  No_Fixed_Route_Transit     False     False  \n",
      "1  No_Fixed_Route_Transit     False     False  \n",
      "2          Bus_31plus_min     False     False  \n",
      "3  No_Fixed_Route_Transit     False     False  \n",
      "4          Bus_31plus_min     False     False  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "03/19/2024 01:38:40 PM - INFO - tract10 records with no value assigned: 5\n",
      "03/19/2024 01:38:40 PM - INFO - tract10 records with no value assigned: 5\n",
      "03/19/2024 01:38:43 PM - INFO - tract20 records with no value assigned: 5\n",
      "03/19/2024 01:38:43 PM - INFO - tract20 records with no value assigned: 5\n",
      "03/19/2024 01:38:44 PM - INFO - epc21 records with no value assigned: 22\n",
      "03/19/2024 01:38:44 PM - INFO - epc21 records with no value assigned: 22\n",
      "03/19/2024 01:38:44 PM - INFO - is_epc21 records with no value assigned: 0\n",
      "03/19/2024 01:38:44 PM - INFO - is_epc21 records with no value assigned: 0\n",
      "03/19/2024 01:38:44 PM - INFO - epc25 records with no value assigned: 18\n",
      "03/19/2024 01:38:44 PM - INFO - epc25 records with no value assigned: 18\n",
      "03/19/2024 01:38:45 PM - INFO - is_epc25 records with no value assigned: 0\n",
      "03/19/2024 01:38:45 PM - INFO - is_epc25 records with no value assigned: 0\n",
      "03/19/2024 01:38:45 PM - INFO - service_level records with no value assigned: 5\n",
      "03/19/2024 01:38:45 PM - INFO - service_level records with no value assigned: 5\n",
      "03/19/2024 01:38:45 PM - INFO - Service_Level records with no value assigned: 5\n",
      "03/19/2024 01:38:45 PM - INFO - Service_Level records with no value assigned: 5\n"
     ]
    }
   ],
   "source": [
    "def summarize_parcels(year, transit_scenario):\n",
    "\n",
    "    #parcel_output = pd.read_csv(parcel_file, engine='python')\n",
    "\n",
    "    logger.info('  Read {} rows'.format(len(parcel_output)))\n",
    "\n",
    "    # keep essential columns\n",
    "#     parcel_output.drop(['geom_id', 'total_job_spaces', 'zoned_du',\n",
    "#                         'zoned_du_underbuild', 'zoned_du_underbuild_nodev', 'first_building_type'], axis=1, inplace=True)\n",
    "    logger.info(\"Head:\\n{}\".format(parcel_output.head()))\n",
    "\n",
    "    parcel_output['totemp'] = parcel_output['totemp'].fillna(0)\n",
    "    parcel_output['totemp'] = parcel_output['totemp'].round(\n",
    "        0).astype('int')\n",
    "    parcel_output['RETEMPN'] = parcel_output['RETEMPN'].fillna(0)\n",
    "    parcel_output['RETEMPN'] = parcel_output['RETEMPN'].round(\n",
    "        0).astype('int')\n",
    "    parcel_output['MWTEMPN'] = parcel_output['MWTEMPN'].fillna(0)\n",
    "    parcel_output['MWTEMPN'] = parcel_output['MWTEMPN'].round(\n",
    "        0).astype('int')\n",
    "\n",
    "    parcel_output['taz'] = parcel_output.parcel_id.map(\n",
    "        parcel_x_taz.set_index('PARCEL_ID').ZONE_ID)\n",
    "\n",
    "    # add tractid to parcels\n",
    "    \n",
    "    # vintage 2010\n",
    "    parcel_output['tract10'] = parcel_output.parcel_id.map(\n",
    "        parcel_x_tracts.set_index('parcel_id').tract10.map(lambda x: f'{x:011.0f}'))\n",
    "    col_values(parcel_output['tract10'],'tract10')\n",
    "    \n",
    "    # vintage 2020\n",
    "    parcel_output['tract20'] = parcel_output.parcel_id.map(\n",
    "        parcel_x_tracts.set_index('parcel_id').tract20.map(lambda x: f'{x:011.0f}'))\n",
    "    col_values(parcel_output['tract20'],'tract20')\n",
    "    \n",
    "    # add epc (RTP2021 version) to parcels using tract10\n",
    "    parcel_output['epc21'] = parcel_output.tract10.map(\n",
    "        tract_epc21_file.set_index('geoid10').epc_class.fillna('Not EPC'))\n",
    "    col_values(parcel_output['epc21'],'epc21')\n",
    "    \n",
    "    parcel_output['is_epc21'] = parcel_output.epc21!='Not EPC'\n",
    "    col_values(parcel_output['is_epc21'],'is_epc21')\n",
    "\n",
    "    \n",
    "    # add epc (RTP2025 version) to parcels using tract10\n",
    "    parcel_output['epc25'] = parcel_output.tract20.map(\n",
    "        tract_epc25_file.set_index('geoid20').epc_class.fillna('Not EPC'))\n",
    "    col_values(parcel_output['epc25'],'epc25')\n",
    "    \n",
    "    parcel_output['is_epc25'] = parcel_output.epc25!='Not EPC'\n",
    "    col_values(parcel_output['is_epc25'],'is_epc25')\n",
    "\n",
    "\n",
    "    # map the cat5 service level names to more descriptive ones used in Tableau\n",
    "    parcel_output['service_level'] = parcel_output.parcel_id.map(\n",
    "        transit_scenario_crosswalk[transit_scenario])\n",
    "    col_values(parcel_output['service_level'],'service_level')\n",
    "    \n",
    "    service_level_map = {'none': 'No_Fixed_Route_Transit',\n",
    "                         'hdwy30plusbuf_only': 'Bus_31plus_min',\n",
    "                         'hdwy30buf_only': 'Bus_15_30min',\n",
    "                         'hdwy15buf_only': 'Bus_<15min',\n",
    "                         'major_buf_only': 'Major_Transit_Stop'}\n",
    "\n",
    "    parcel_output['Service_Level'] = parcel_output['service_level'].map(\n",
    "        service_level_map)\n",
    "    col_values(parcel_output['Service_Level'],'Service_Level')\n",
    "    \n",
    "    def groupby_summaries(df, group_vars):\n",
    "\n",
    "        grp_summary = (df\n",
    "                       .groupby(group_vars)\n",
    "                       .agg({'tothh': 'sum', 'hhq1': 'sum',\n",
    "                             'totemp': 'sum', 'RETEMPN': 'sum',\n",
    "                             'MWTEMPN': 'sum'})\n",
    "                       )\n",
    "\n",
    "        grp_summary_shares = grp_summary.div(\n",
    "            grp_summary.sum()).round(3)\n",
    "\n",
    "        grp_summary_combo = pd.concat([grp_summary,\n",
    "                                       grp_summary_shares.add_suffix('_share')\n",
    "                                       ], axis=1\n",
    "                                      )\n",
    "        return grp_summary_combo\n",
    "\n",
    "    parcel_output_summary = groupby_summaries(\n",
    "        parcel_output, [ 'Service_Level'])\n",
    "\n",
    "    return parcel_output_summary\n",
    "\n",
    "\n",
    "parcel_output_summary = summarize_parcels(2050, 'trn_fp_cat5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed504d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "dd10944f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tothh</th>\n",
       "      <th>hhq1</th>\n",
       "      <th>totemp</th>\n",
       "      <th>RETEMPN</th>\n",
       "      <th>MWTEMPN</th>\n",
       "      <th>tothh_share</th>\n",
       "      <th>hhq1_share</th>\n",
       "      <th>totemp_share</th>\n",
       "      <th>RETEMPN_share</th>\n",
       "      <th>MWTEMPN_share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Service_Level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bus_15_30min</th>\n",
       "      <td>446593.0</td>\n",
       "      <td>58616.0</td>\n",
       "      <td>700044</td>\n",
       "      <td>71128</td>\n",
       "      <td>94200</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bus_31plus_min</th>\n",
       "      <td>471834.0</td>\n",
       "      <td>51835.0</td>\n",
       "      <td>711485</td>\n",
       "      <td>56763</td>\n",
       "      <td>98146</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bus_&lt;15min</th>\n",
       "      <td>258283.0</td>\n",
       "      <td>63388.0</td>\n",
       "      <td>354708</td>\n",
       "      <td>46591</td>\n",
       "      <td>39294</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major_Transit_Stop</th>\n",
       "      <td>1970302.0</td>\n",
       "      <td>748626.0</td>\n",
       "      <td>2780424</td>\n",
       "      <td>221462</td>\n",
       "      <td>192787</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No_Fixed_Route_Transit</th>\n",
       "      <td>894545.0</td>\n",
       "      <td>87186.0</td>\n",
       "      <td>860152</td>\n",
       "      <td>45611</td>\n",
       "      <td>183222</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            tothh      hhq1   totemp  RETEMPN  MWTEMPN  \\\n",
       "Service_Level                                                            \n",
       "Bus_15_30min             446593.0   58616.0   700044    71128    94200   \n",
       "Bus_31plus_min           471834.0   51835.0   711485    56763    98146   \n",
       "Bus_<15min               258283.0   63388.0   354708    46591    39294   \n",
       "Major_Transit_Stop      1970302.0  748626.0  2780424   221462   192787   \n",
       "No_Fixed_Route_Transit   894545.0   87186.0   860152    45611   183222   \n",
       "\n",
       "                        tothh_share  hhq1_share  totemp_share  RETEMPN_share  \\\n",
       "Service_Level                                                                  \n",
       "Bus_15_30min                  0.111       0.058         0.129          0.161   \n",
       "Bus_31plus_min                0.117       0.051         0.132          0.129   \n",
       "Bus_<15min                    0.064       0.063         0.066          0.106   \n",
       "Major_Transit_Stop            0.488       0.741         0.514          0.502   \n",
       "No_Fixed_Route_Transit        0.221       0.086         0.159          0.103   \n",
       "\n",
       "                        MWTEMPN_share  \n",
       "Service_Level                          \n",
       "Bus_15_30min                    0.155  \n",
       "Bus_31plus_min                  0.162  \n",
       "Bus_<15min                      0.065  \n",
       "Major_Transit_Stop              0.317  \n",
       "No_Fixed_Route_Transit          0.302  "
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcel_output_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "ee1faa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Service_Level</th>\n",
       "      <th>tothh</th>\n",
       "      <th>hhq1</th>\n",
       "      <th>totemp</th>\n",
       "      <th>RETEMPN</th>\n",
       "      <th>MWTEMPN</th>\n",
       "      <th>tothh_share</th>\n",
       "      <th>hhq1_share</th>\n",
       "      <th>totemp_share</th>\n",
       "      <th>RETEMPN_share</th>\n",
       "      <th>MWTEMPN_share</th>\n",
       "      <th>year</th>\n",
       "      <th>modelrunID</th>\n",
       "      <th>transit</th>\n",
       "      <th>area</th>\n",
       "      <th>blueprint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Bus_15_30min</td>\n",
       "      <td>241445</td>\n",
       "      <td>30886</td>\n",
       "      <td>415937</td>\n",
       "      <td>36569</td>\n",
       "      <td>68977</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2050</td>\n",
       "      <td>Final Blueprint runs/Final Blueprint (s24)/BAU...</td>\n",
       "      <td>trn_fp_cat5</td>\n",
       "      <td>Region</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Bus_31plus_min</td>\n",
       "      <td>281742</td>\n",
       "      <td>31131</td>\n",
       "      <td>379888</td>\n",
       "      <td>31432</td>\n",
       "      <td>60476</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2050</td>\n",
       "      <td>Final Blueprint runs/Final Blueprint (s24)/BAU...</td>\n",
       "      <td>trn_fp_cat5</td>\n",
       "      <td>Region</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Bus_&lt;15min</td>\n",
       "      <td>786845</td>\n",
       "      <td>127837</td>\n",
       "      <td>1083359</td>\n",
       "      <td>115284</td>\n",
       "      <td>114261</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2050</td>\n",
       "      <td>Final Blueprint runs/Final Blueprint (s24)/BAU...</td>\n",
       "      <td>trn_fp_cat5</td>\n",
       "      <td>Region</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Major_Transit_Stop</td>\n",
       "      <td>1971306</td>\n",
       "      <td>749222</td>\n",
       "      <td>2785232</td>\n",
       "      <td>221557</td>\n",
       "      <td>194184</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2050</td>\n",
       "      <td>Final Blueprint runs/Final Blueprint (s24)/BAU...</td>\n",
       "      <td>trn_fp_cat5</td>\n",
       "      <td>Region</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>No_Fixed_Route_Transit</td>\n",
       "      <td>761974</td>\n",
       "      <td>70889</td>\n",
       "      <td>744044</td>\n",
       "      <td>36717</td>\n",
       "      <td>169760</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2050</td>\n",
       "      <td>Final Blueprint runs/Final Blueprint (s24)/BAU...</td>\n",
       "      <td>trn_fp_cat5</td>\n",
       "      <td>Region</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Service_Level    tothh    hhq1   totemp  RETEMPN  MWTEMPN  \\\n",
       "165            Bus_15_30min   241445   30886   415937    36569    68977   \n",
       "166          Bus_31plus_min   281742   31131   379888    31432    60476   \n",
       "167              Bus_<15min   786845  127837  1083359   115284   114261   \n",
       "168      Major_Transit_Stop  1971306  749222  2785232   221557   194184   \n",
       "169  No_Fixed_Route_Transit   761974   70889   744044    36717   169760   \n",
       "\n",
       "     tothh_share  hhq1_share  totemp_share  RETEMPN_share  MWTEMPN_share  \\\n",
       "165         0.06        0.03          0.08           0.08           0.11   \n",
       "166         0.07        0.03          0.07           0.07           0.10   \n",
       "167         0.19        0.13          0.20           0.26           0.19   \n",
       "168         0.49        0.74          0.51           0.50           0.32   \n",
       "169         0.19        0.07          0.14           0.08           0.28   \n",
       "\n",
       "     year                                         modelrunID      transit  \\\n",
       "165  2050  Final Blueprint runs/Final Blueprint (s24)/BAU...  trn_fp_cat5   \n",
       "166  2050  Final Blueprint runs/Final Blueprint (s24)/BAU...  trn_fp_cat5   \n",
       "167  2050  Final Blueprint runs/Final Blueprint (s24)/BAU...  trn_fp_cat5   \n",
       "168  2050  Final Blueprint runs/Final Blueprint (s24)/BAU...  trn_fp_cat5   \n",
       "169  2050  Final Blueprint runs/Final Blueprint (s24)/BAU...  trn_fp_cat5   \n",
       "\n",
       "       area blueprint  \n",
       "165  Region      Plus  \n",
       "166  Region      Plus  \n",
       "167  Region      Plus  \n",
       "168  Region      Plus  \n",
       "169  Region      Plus  "
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_proximity_target_schema.query('blueprint==\"Plus\" & year==2050 & transit==\"trn_fp_cat5\" & area==\"Region\"') #& area==\"CoCs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "a96f44d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['none', 'hdwy30plusbuf_only', 'hdwy30buf_only', 'major_buf_only',\n",
       "       'hdwy15buf_only', nan], dtype=object)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcel_output['service_level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "54ab09a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          No_Fixed_Route_Transit\n",
       "1          No_Fixed_Route_Transit\n",
       "2                  Bus_31plus_min\n",
       "3          No_Fixed_Route_Transit\n",
       "4                  Bus_31plus_min\n",
       "                    ...          \n",
       "1956207                Bus_<15min\n",
       "1956208                       NaN\n",
       "1956209                       NaN\n",
       "1956210                       NaN\n",
       "1956211                       NaN\n",
       "Name: service_level_desc, Length: 1956212, dtype: object"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "51d36523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coc</th>\n",
       "      <th>service_level_desc</th>\n",
       "      <th>tothh</th>\n",
       "      <th>hhq1</th>\n",
       "      <th>totemp</th>\n",
       "      <th>RETEMPN</th>\n",
       "      <th>MWTEMPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>Bus_15_30min</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>7523.0</td>\n",
       "      <td>96471</td>\n",
       "      <td>10924</td>\n",
       "      <td>12983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High</td>\n",
       "      <td>Bus_31plus_min</td>\n",
       "      <td>52970.0</td>\n",
       "      <td>8322.0</td>\n",
       "      <td>85376</td>\n",
       "      <td>5974</td>\n",
       "      <td>12955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High</td>\n",
       "      <td>Bus_&lt;15min</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>7084.0</td>\n",
       "      <td>45339</td>\n",
       "      <td>4119</td>\n",
       "      <td>7683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High</td>\n",
       "      <td>No_Fixed_Route_Transit</td>\n",
       "      <td>40676.0</td>\n",
       "      <td>6871.0</td>\n",
       "      <td>82523</td>\n",
       "      <td>4525</td>\n",
       "      <td>22689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Higher</td>\n",
       "      <td>Bus_15_30min</td>\n",
       "      <td>28093.0</td>\n",
       "      <td>4855.0</td>\n",
       "      <td>29036</td>\n",
       "      <td>3523</td>\n",
       "      <td>2217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Higher</td>\n",
       "      <td>Bus_31plus_min</td>\n",
       "      <td>23592.0</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>20890</td>\n",
       "      <td>1708</td>\n",
       "      <td>2852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Higher</td>\n",
       "      <td>Bus_&lt;15min</td>\n",
       "      <td>20027.0</td>\n",
       "      <td>5244.0</td>\n",
       "      <td>25494</td>\n",
       "      <td>2032</td>\n",
       "      <td>2482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Higher</td>\n",
       "      <td>No_Fixed_Route_Transit</td>\n",
       "      <td>18530.0</td>\n",
       "      <td>5637.0</td>\n",
       "      <td>36244</td>\n",
       "      <td>1316</td>\n",
       "      <td>6454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Highest</td>\n",
       "      <td>Bus_15_30min</td>\n",
       "      <td>7677.0</td>\n",
       "      <td>2054.0</td>\n",
       "      <td>8326</td>\n",
       "      <td>748</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Highest</td>\n",
       "      <td>Bus_31plus_min</td>\n",
       "      <td>8447.0</td>\n",
       "      <td>2654.0</td>\n",
       "      <td>7668</td>\n",
       "      <td>556</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Highest</td>\n",
       "      <td>Bus_&lt;15min</td>\n",
       "      <td>11220.0</td>\n",
       "      <td>4038.0</td>\n",
       "      <td>18643</td>\n",
       "      <td>1535</td>\n",
       "      <td>3703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Highest</td>\n",
       "      <td>No_Fixed_Route_Transit</td>\n",
       "      <td>6060.0</td>\n",
       "      <td>1543.0</td>\n",
       "      <td>10224</td>\n",
       "      <td>502</td>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Not EPC</td>\n",
       "      <td>Bus_15_30min</td>\n",
       "      <td>361879.0</td>\n",
       "      <td>44184.0</td>\n",
       "      <td>566211</td>\n",
       "      <td>55933</td>\n",
       "      <td>77995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Not EPC</td>\n",
       "      <td>Bus_31plus_min</td>\n",
       "      <td>386825.0</td>\n",
       "      <td>37405.0</td>\n",
       "      <td>597551</td>\n",
       "      <td>48525</td>\n",
       "      <td>81635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Not EPC</td>\n",
       "      <td>Bus_&lt;15min</td>\n",
       "      <td>206476.0</td>\n",
       "      <td>47022.0</td>\n",
       "      <td>265232</td>\n",
       "      <td>38905</td>\n",
       "      <td>25426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Not EPC</td>\n",
       "      <td>No_Fixed_Route_Transit</td>\n",
       "      <td>829272.0</td>\n",
       "      <td>73135.0</td>\n",
       "      <td>731148</td>\n",
       "      <td>39268</td>\n",
       "      <td>151946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coc      service_level_desc     tothh     hhq1  totemp  RETEMPN  \\\n",
       "0      High            Bus_15_30min   48944.0   7523.0   96471    10924   \n",
       "1      High          Bus_31plus_min   52970.0   8322.0   85376     5974   \n",
       "2      High              Bus_<15min   20560.0   7084.0   45339     4119   \n",
       "3      High  No_Fixed_Route_Transit   40676.0   6871.0   82523     4525   \n",
       "4    Higher            Bus_15_30min   28093.0   4855.0   29036     3523   \n",
       "5    Higher          Bus_31plus_min   23592.0   3454.0   20890     1708   \n",
       "6    Higher              Bus_<15min   20027.0   5244.0   25494     2032   \n",
       "7    Higher  No_Fixed_Route_Transit   18530.0   5637.0   36244     1316   \n",
       "8   Highest            Bus_15_30min    7677.0   2054.0    8326      748   \n",
       "9   Highest          Bus_31plus_min    8447.0   2654.0    7668      556   \n",
       "10  Highest              Bus_<15min   11220.0   4038.0   18643     1535   \n",
       "11  Highest  No_Fixed_Route_Transit    6060.0   1543.0   10224      502   \n",
       "12  Not EPC            Bus_15_30min  361879.0  44184.0  566211    55933   \n",
       "13  Not EPC          Bus_31plus_min  386825.0  37405.0  597551    48525   \n",
       "14  Not EPC              Bus_<15min  206476.0  47022.0  265232    38905   \n",
       "15  Not EPC  No_Fixed_Route_Transit  829272.0  73135.0  731148    39268   \n",
       "\n",
       "    MWTEMPN  \n",
       "0     12983  \n",
       "1     12955  \n",
       "2      7683  \n",
       "3     22689  \n",
       "4      2217  \n",
       "5      2852  \n",
       "6      2482  \n",
       "7      6454  \n",
       "8      1005  \n",
       "9       704  \n",
       "10     3703  \n",
       "11     2133  \n",
       "12    77995  \n",
       "13    81635  \n",
       "14    25426  \n",
       "15   151946  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "98d96046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcel_file_name(scenario, year):\n",
    "\n",
    "    for model_year in (2015, 2050):\n",
    "        if model_year == 2050:\n",
    "            if us_runid == us_2050_FBP_Final:\n",
    "                parcel_file = urbansim_runid + \\\n",
    "                    '_parcel_data_{}_UBI.csv'.format(model_year)\n",
    "            else:\n",
    "                parcel_file = urbansim_runid + \\\n",
    "                    '_parcel_data_{}.csv'.format(model_year)\n",
    "        else:\n",
    "            parcel_file = urbansim_runid + \\\n",
    "                '_parcel_data_{}.csv'.format(model_year)\n",
    "    urbansim_runid = os.path.join(urbansim_run_location, us_runid)\n",
    "\n",
    "    return urbansim_runid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d55145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pba_parcel_data(scenario):\n",
    "\n",
    "    column_map = {'tothh_share', 'hhq1_share',\n",
    "                  'totemp_share', 'RETEMPN_share', 'MWTEMPN_share'}\n",
    "\n",
    "    for model_year in (2015, 2050):\n",
    "        if model_year == 2050:\n",
    "            if us_runid == us_2050_FBP_Final:\n",
    "                parcel_file = urbansim_runid + \\\n",
    "                    '_parcel_data_{}_UBI.csv'.format(model_year)\n",
    "            else:\n",
    "                parcel_file = urbansim_runid + \\\n",
    "                    '_parcel_data_{}.csv'.format(model_year)\n",
    "        else:\n",
    "            parcel_file = urbansim_runid + \\\n",
    "                '_parcel_data_{}.csv'.format(model_year)\n",
    "        logger.info('Reading {} parcel data from {}'.format(\n",
    "            model_year, parcel_file))\n",
    "        parcel_output = pd.read_csv(parcel_file, engine='python')\n",
    "\n",
    "        logger.info('  Read {} rows'.format(len(parcel_output)))\n",
    "\n",
    "        # keep essential columns\n",
    "        parcel_output.drop(['geom_id', 'total_job_spaces', 'zoned_du',\n",
    "                            'zoned_du_underbuild', 'zoned_du_underbuild_nodev', 'first_building_type'], axis=1, inplace=True)\n",
    "        logger.info(\"Head:\\n{}\".format(parcel_output.head()))\n",
    "\n",
    "        parcel_output['totemp'] = parcel_output['totemp'].fillna(0)\n",
    "        parcel_output['totemp'] = parcel_output['totemp'].round(\n",
    "            0).astype('int')\n",
    "        parcel_output['RETEMPN'] = parcel_output['RETEMPN'].fillna(0)\n",
    "        parcel_output['RETEMPN'] = parcel_output['RETEMPN'].round(\n",
    "            0).astype('int')\n",
    "        parcel_output['MWTEMPN'] = parcel_output['MWTEMPN'].fillna(0)\n",
    "        parcel_output['MWTEMPN'] = parcel_output['MWTEMPN'].round(\n",
    "            0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "['year','transit','modelrunID','tothh_share'  ,'hhq1_share'  ,'totemp_share' ,'RETEMPN_share','MWTEMPN_share','modelrunID']\n",
    "\n",
    "        prox_sdf_taz['tothh_share'  ] = round(prox_sdf_taz.tothh  / prox_sdf_taz.tothh.sum(),  2)\n",
    "        prox_sdf_taz['hhq1_share'   ] = round(prox_sdf_taz.hhq1   / prox_sdf_taz.hhq1.sum()  , 2)\n",
    "        prox_sdf_taz['totemp_share' ] = round(prox_sdf_taz.totemp / prox_sdf_taz.totemp.sum(), 2)\n",
    "        prox_sdf_taz['RETEMPN_share'] = round(prox_sdf_taz.RETEMPN/prox_sdf_taz.RETEMPN.sum(), 2)\n",
    "        prox_sdf_taz['MWTEMPN_share'] = round(prox_sdf_taz.MWTEMPN/prox_sdf_taz.MWTEMPN.sum(), 2)\n",
    "        prox_sdf_taz['year'] = str(model_year)\n",
    "        prox_sdf_taz['modelrunID'] = us_runid\n",
    "        prox_sdf_taz['transit'] = transit_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9faeb5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56dc79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e3fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b406ca52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/18/2024 05:18:21 PM - INFO - \n",
      "03/18/2024 05:18:21 PM - INFO - ==== Processing UrbanSim run EIR runs/Baseline Large (s25) runs/NP_v8_FINAL/run314 ====\n",
      "03/18/2024 05:18:21 PM - INFO - Reading 2015 parcel data from /Users/aolsen/Box/Modeling and Surveys/Urban Modeling/Bay Area UrbanSim/PBA50/EIR runs/Baseline Large (s25) runs/NP_v8_FINAL/run314_parcel_data_2015.csv\n",
      "03/18/2024 05:18:52 PM - INFO -   Read 1956212 rows\n",
      "03/18/2024 05:18:52 PM - INFO - Head:\n",
      "   parcel_id           x          y         fbpchcat                  juris  \\\n",
      "0     229116 -121.795620  37.655379   NANAHRADISNAin              livermore   \n",
      "1     244166 -121.713004  37.717277    NAtra3DISNAin              livermore   \n",
      "2     202378 -122.014199  37.655260       NANANANAin                hayward   \n",
      "3    2004420 -122.771868  38.727893  NANAHRADISNAout  unincorporated_sonoma   \n",
      "4     340332 -121.974508  37.546277   NANAHRADISNAin                fremont   \n",
      "\n",
      "   hhq1  hhq2  hhq3  hhq4  tothh  ...  preserved_units  inclusionary_units  \\\n",
      "0   NaN   NaN   NaN   NaN    NaN  ...              NaN                 NaN   \n",
      "1   NaN   NaN   NaN   NaN    NaN  ...              NaN                 NaN   \n",
      "2   7.0   6.0   9.0   9.0   31.0  ...              0.0                 0.0   \n",
      "3   NaN   NaN   NaN   NaN    NaN  ...              0.0                 0.0   \n",
      "4   NaN   NaN   NaN   NaN    NaN  ...              NaN                 NaN   \n",
      "\n",
      "   subsidized_units  AGREMPN  MWTEMPN  RETEMPN  FPSEMPN  HEREMPN  OTHEMPN  \\\n",
      "0               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "1               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "2               0.0      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "3               0.0      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "4               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "\n",
      "   totemp  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "03/18/2024 05:18:53 PM - INFO - Reading 2050 parcel data from /Users/aolsen/Box/Modeling and Surveys/Urban Modeling/Bay Area UrbanSim/PBA50/EIR runs/Baseline Large (s25) runs/NP_v8_FINAL/run314_parcel_data_2050.csv\n",
      "03/18/2024 05:19:22 PM - INFO -   Read 1956212 rows\n",
      "03/18/2024 05:19:22 PM - INFO - Head:\n",
      "   parcel_id           x          y         fbpchcat                  juris  \\\n",
      "0     229116 -121.795620  37.655379   NANAHRADISNAin              livermore   \n",
      "1     244166 -121.713004  37.717277    NAtra3DISNAin              livermore   \n",
      "2     202378 -122.014199  37.655260       NANANANAin                hayward   \n",
      "3    2004420 -122.771868  38.727893  NANAHRADISNAout  unincorporated_sonoma   \n",
      "4     340332 -121.974508  37.546277   NANAHRADISNAin                fremont   \n",
      "\n",
      "   hhq1  hhq2  hhq3  hhq4  tothh  ...  preserved_units  inclusionary_units  \\\n",
      "0   NaN   NaN   NaN   NaN    NaN  ...              NaN                 NaN   \n",
      "1   NaN   NaN   NaN   NaN    NaN  ...              NaN                 NaN   \n",
      "2   7.0   5.0   5.0  14.0   31.0  ...              0.0                 0.0   \n",
      "3   NaN   NaN   NaN   NaN    NaN  ...              0.0                 0.0   \n",
      "4   NaN   NaN   NaN   NaN    NaN  ...              NaN                 NaN   \n",
      "\n",
      "   subsidized_units  AGREMPN  MWTEMPN  RETEMPN  FPSEMPN  HEREMPN  OTHEMPN  \\\n",
      "0               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "1               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "2               0.0      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "3               0.0      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "4               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "\n",
      "   totemp  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "03/18/2024 05:19:22 PM - INFO - \n",
      "03/18/2024 05:19:22 PM - INFO - ==== Processing UrbanSim run EIR runs/Alt1 (s26) runs/Alt1_v3_test_far_tiers_FINAL_EIR_ALT/run375 ====\n",
      "03/18/2024 05:19:22 PM - INFO - Reading 2015 parcel data from /Users/aolsen/Box/Modeling and Surveys/Urban Modeling/Bay Area UrbanSim/PBA50/EIR runs/Alt1 (s26) runs/Alt1_v3_test_far_tiers_FINAL_EIR_ALT/run375_parcel_data_2015.csv\n",
      "03/18/2024 05:19:51 PM - INFO -   Read 1956212 rows\n",
      "03/18/2024 05:19:51 PM - INFO - Head:\n",
      "   parcel_id          y           x                           eirzoningmodcat  \\\n",
      "0     229116  37.655379 -121.795620               livermoreNANAHRADISNANAinNA   \n",
      "1     244166  37.717277 -121.713004                livermoreNAtra3DISNANAinNA   \n",
      "2     202378  37.655260 -122.014199                    haywardNANANANANAinres   \n",
      "3    2004420  38.727893 -122.771868  unincorporated_sonomaNANAHRADISNANAoutNA   \n",
      "4     340332  37.546277 -121.974508                 fremontNANAHRADISNANAinNA   \n",
      "\n",
      "                   juris  hhq1  hhq2  hhq3  hhq4  tothh  ...  preserved_units  \\\n",
      "0              livermore   NaN   NaN   NaN   NaN    NaN  ...              NaN   \n",
      "1              livermore   NaN   NaN   NaN   NaN    NaN  ...              NaN   \n",
      "2                hayward   5.0   6.0  12.0   8.0   31.0  ...              0.0   \n",
      "3  unincorporated_sonoma   NaN   NaN   NaN   NaN    NaN  ...              0.0   \n",
      "4                fremont   NaN   NaN   NaN   NaN    NaN  ...              NaN   \n",
      "\n",
      "   inclusionary_units  subsidized_units  AGREMPN  MWTEMPN  RETEMPN  FPSEMPN  \\\n",
      "0                 NaN               NaN      NaN      NaN      NaN      NaN   \n",
      "1                 NaN               NaN      NaN      NaN      NaN      NaN   \n",
      "2                 0.0               0.0      NaN      NaN      NaN      NaN   \n",
      "3                 0.0               0.0      NaN      NaN      NaN      NaN   \n",
      "4                 NaN               NaN      NaN      NaN      NaN      NaN   \n",
      "\n",
      "   HEREMPN  OTHEMPN  totemp  \n",
      "0      NaN      NaN     NaN  \n",
      "1      NaN      NaN     NaN  \n",
      "2      NaN      NaN     NaN  \n",
      "3      NaN      NaN     NaN  \n",
      "4      NaN      NaN     NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "03/18/2024 05:19:52 PM - INFO - Reading 2050 parcel data from /Users/aolsen/Box/Modeling and Surveys/Urban Modeling/Bay Area UrbanSim/PBA50/EIR runs/Alt1 (s26) runs/Alt1_v3_test_far_tiers_FINAL_EIR_ALT/run375_parcel_data_2050.csv\n",
      "03/18/2024 05:20:20 PM - INFO -   Read 1956212 rows\n",
      "03/18/2024 05:20:20 PM - INFO - Head:\n",
      "   parcel_id          y           x                           eirzoningmodcat  \\\n",
      "0     229116  37.655379 -121.795620               livermoreNANAHRADISNANAinNA   \n",
      "1     244166  37.717277 -121.713004                livermoreNAtra3DISNANAinNA   \n",
      "2     202378  37.655260 -122.014199                    haywardNANANANANAinres   \n",
      "3    2004420  38.727893 -122.771868  unincorporated_sonomaNANAHRADISNANAoutNA   \n",
      "4     340332  37.546277 -121.974508                 fremontNANAHRADISNANAinNA   \n",
      "\n",
      "                   juris  hhq1  hhq2  hhq3  hhq4  tothh  ...  preserved_units  \\\n",
      "0              livermore   NaN   NaN   NaN   NaN    NaN  ...              NaN   \n",
      "1              livermore   NaN   NaN   NaN   NaN    NaN  ...              NaN   \n",
      "2                hayward   1.0   6.0  11.0  15.0   33.0  ...              0.0   \n",
      "3  unincorporated_sonoma   NaN   NaN   NaN   NaN    NaN  ...              0.0   \n",
      "4                fremont   NaN   NaN   NaN   NaN    NaN  ...              NaN   \n",
      "\n",
      "   inclusionary_units  subsidized_units  AGREMPN  MWTEMPN  RETEMPN  FPSEMPN  \\\n",
      "0                 NaN               NaN      NaN      NaN      NaN      NaN   \n",
      "1                 NaN               NaN      NaN      NaN      NaN      NaN   \n",
      "2                 0.0               0.0      NaN      NaN      NaN      NaN   \n",
      "3                 0.0               0.0      NaN      NaN      NaN      NaN   \n",
      "4                 NaN               NaN      NaN      NaN      NaN      NaN   \n",
      "\n",
      "   HEREMPN  OTHEMPN  totemp  \n",
      "0      NaN      NaN     NaN  \n",
      "1      NaN      NaN     NaN  \n",
      "2      NaN      NaN     NaN  \n",
      "3      NaN      NaN     NaN  \n",
      "4      NaN      NaN     NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "03/18/2024 05:20:20 PM - INFO - \n",
      "03/18/2024 05:20:20 PM - INFO - ==== Processing UrbanSim run EIR runs/Alt2 (s28) runs/Alt2_v1_FINAL_EIR_ALT/run374 ====\n",
      "03/18/2024 05:20:20 PM - INFO - Reading 2015 parcel data from /Users/aolsen/Box/Modeling and Surveys/Urban Modeling/Bay Area UrbanSim/PBA50/EIR runs/Alt2 (s28) runs/Alt2_v1_FINAL_EIR_ALT/run374_parcel_data_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/18/2024 05:20:48 PM - INFO -   Read 1956212 rows\n",
      "03/18/2024 05:20:49 PM - INFO - Head:\n",
      "   parcel_id          y           x                  juris  \\\n",
      "0     229116  37.655379 -121.795620              livermore   \n",
      "1     244166  37.717277 -121.713004              livermore   \n",
      "2     202378  37.655260 -122.014199                hayward   \n",
      "3    2004420  38.727893 -122.771868  unincorporated_sonoma   \n",
      "4     340332  37.546277 -121.974508                fremont   \n",
      "\n",
      "                            eirzoningmodcat  hhq1  hhq2  hhq3  hhq4  tothh  \\\n",
      "0               livermoreNANAHRADISNANAinNA   NaN   NaN   NaN   NaN    NaN   \n",
      "1                livermoreNAtra3DISNANAinNA   NaN   NaN   NaN   NaN    NaN   \n",
      "2                    haywardNANANANANAinres   7.0   4.0  10.0  10.0   31.0   \n",
      "3  unincorporated_sonomaNANAHRADISNANAoutNA   NaN   NaN   NaN   NaN    NaN   \n",
      "4                 fremontNANAHRADISNANAinNA   NaN   NaN   NaN   NaN    NaN   \n",
      "\n",
      "   ...  preserved_units  inclusionary_units  subsidized_units  AGREMPN  \\\n",
      "0  ...              NaN                 NaN               NaN      NaN   \n",
      "1  ...              NaN                 NaN               NaN      NaN   \n",
      "2  ...              0.0                 0.0               0.0      NaN   \n",
      "3  ...              0.0                 0.0               0.0      NaN   \n",
      "4  ...              NaN                 NaN               NaN      NaN   \n",
      "\n",
      "   MWTEMPN  RETEMPN  FPSEMPN  HEREMPN  OTHEMPN  totemp  \n",
      "0      NaN      NaN      NaN      NaN      NaN     NaN  \n",
      "1      NaN      NaN      NaN      NaN      NaN     NaN  \n",
      "2      NaN      NaN      NaN      NaN      NaN     NaN  \n",
      "3      NaN      NaN      NaN      NaN      NaN     NaN  \n",
      "4      NaN      NaN      NaN      NaN      NaN     NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "03/18/2024 05:20:49 PM - INFO - Reading 2050 parcel data from /Users/aolsen/Box/Modeling and Surveys/Urban Modeling/Bay Area UrbanSim/PBA50/EIR runs/Alt2 (s28) runs/Alt2_v1_FINAL_EIR_ALT/run374_parcel_data_2050.csv\n",
      "03/18/2024 05:21:17 PM - INFO -   Read 1956212 rows\n",
      "03/18/2024 05:21:17 PM - INFO - Head:\n",
      "   parcel_id          y           x                  juris  \\\n",
      "0     229116  37.655379 -121.795620              livermore   \n",
      "1     244166  37.717277 -121.713004              livermore   \n",
      "2     202378  37.655260 -122.014199                hayward   \n",
      "3    2004420  38.727893 -122.771868  unincorporated_sonoma   \n",
      "4     340332  37.546277 -121.974508                fremont   \n",
      "\n",
      "                            eirzoningmodcat  hhq1  hhq2  hhq3  hhq4  tothh  \\\n",
      "0               livermoreNANAHRADISNANAinNA   NaN   NaN   NaN   NaN    NaN   \n",
      "1                livermoreNAtra3DISNANAinNA   NaN   NaN   NaN   NaN    NaN   \n",
      "2                    haywardNANANANANAinres   NaN   7.0   8.0  18.0   33.0   \n",
      "3  unincorporated_sonomaNANAHRADISNANAoutNA   NaN   NaN   NaN   NaN    NaN   \n",
      "4                 fremontNANAHRADISNANAinNA   NaN   NaN   NaN   NaN    NaN   \n",
      "\n",
      "   ...  preserved_units  inclusionary_units  subsidized_units  AGREMPN  \\\n",
      "0  ...              NaN                 NaN               NaN      NaN   \n",
      "1  ...              NaN                 NaN               NaN      NaN   \n",
      "2  ...              0.0                 0.0               0.0      NaN   \n",
      "3  ...              0.0                 0.0               0.0      NaN   \n",
      "4  ...              NaN                 NaN               NaN      NaN   \n",
      "\n",
      "   MWTEMPN  RETEMPN  FPSEMPN  HEREMPN  OTHEMPN  totemp  \n",
      "0      NaN      NaN      NaN      NaN      NaN     NaN  \n",
      "1      NaN      NaN      NaN      NaN      NaN     NaN  \n",
      "2      NaN      NaN      NaN      NaN      NaN     NaN  \n",
      "3      NaN      NaN      NaN      NaN      NaN     NaN  \n",
      "4      NaN      NaN      NaN      NaN      NaN     NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "03/18/2024 05:21:17 PM - INFO - \n",
      "03/18/2024 05:21:17 PM - INFO - ==== Processing UrbanSim run Final Blueprint runs/Final Blueprint (s24)/BAUS v2.25 - FINAL VERSION/run182 ====\n",
      "03/18/2024 05:21:17 PM - INFO - Reading 2015 parcel data from /Users/aolsen/Box/Modeling and Surveys/Urban Modeling/Bay Area UrbanSim/PBA50/Final Blueprint runs/Final Blueprint (s24)/BAUS v2.25 - FINAL VERSION/run182_parcel_data_2015.csv\n",
      "03/18/2024 05:21:46 PM - INFO -   Read 1956212 rows\n",
      "03/18/2024 05:21:46 PM - INFO - Head:\n",
      "   parcel_id           x          y                  juris         fbpchcat  \\\n",
      "0     229116 -121.795620  37.655379              livermore   NANAHRADISNAin   \n",
      "1     244166 -121.713004  37.717277              livermore    NAtra3DISNAin   \n",
      "2     202378 -122.014199  37.655260                hayward       NANANANAin   \n",
      "3    2004420 -122.771868  38.727893  unincorporated_sonoma  NANAHRADISNAout   \n",
      "4     340332 -121.974508  37.546277                fremont   NANAHRADISNAin   \n",
      "\n",
      "   hhq1  hhq2  hhq3  hhq4  tothh  ...  preserved_units  inclusionary_units  \\\n",
      "0   NaN   NaN   NaN   NaN    NaN  ...              NaN                 NaN   \n",
      "1   NaN   NaN   NaN   NaN    NaN  ...              NaN                 NaN   \n",
      "2   2.0   7.0   7.0  14.0   30.0  ...              0.0                 0.0   \n",
      "3   NaN   NaN   NaN   NaN    NaN  ...              0.0                 0.0   \n",
      "4   NaN   NaN   NaN   NaN    NaN  ...              NaN                 NaN   \n",
      "\n",
      "   subsidized_units  AGREMPN  MWTEMPN  RETEMPN  FPSEMPN  HEREMPN  OTHEMPN  \\\n",
      "0               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "1               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "2               0.0      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "3               0.0      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "4               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "\n",
      "   totemp  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "03/18/2024 05:21:47 PM - INFO - Reading 2050 parcel data from /Users/aolsen/Box/Modeling and Surveys/Urban Modeling/Bay Area UrbanSim/PBA50/Final Blueprint runs/Final Blueprint (s24)/BAUS v2.25 - FINAL VERSION/run182_parcel_data_2050_UBI.csv\n",
      "03/18/2024 05:22:17 PM - INFO -   Read 1956212 rows\n",
      "03/18/2024 05:22:17 PM - INFO - Head:\n",
      "   Unnamed: 0  parcel_id           x          y                  juris  \\\n",
      "0           0     229116 -121.795620  37.655379              livermore   \n",
      "1           1     244166 -121.713004  37.717277              livermore   \n",
      "2           2     202378 -122.014199  37.655260                hayward   \n",
      "3           3    2004420 -122.771868  38.727893  unincorporated_sonoma   \n",
      "4           4     340332 -121.974508  37.546277                fremont   \n",
      "\n",
      "          fbpchcat  hhq1  hhq2  hhq3  hhq4  ...  preserved_units  \\\n",
      "0   NANAHRADISNAin   NaN   NaN   NaN   NaN  ...              NaN   \n",
      "1    NAtra3DISNAin   NaN   NaN   NaN   NaN  ...              NaN   \n",
      "2       NANANANAin   2.0   5.0  10.0  16.0  ...              0.0   \n",
      "3  NANAHRADISNAout   NaN   NaN   NaN   NaN  ...              0.0   \n",
      "4   NANAHRADISNAin   NaN   NaN   NaN   NaN  ...              NaN   \n",
      "\n",
      "   inclusionary_units  subsidized_units  AGREMPN  MWTEMPN  RETEMPN  FPSEMPN  \\\n",
      "0                 NaN               NaN      NaN      NaN      NaN      NaN   \n",
      "1                 NaN               NaN      NaN      NaN      NaN      NaN   \n",
      "2                 0.0               0.0      NaN      NaN      NaN      NaN   \n",
      "3                 0.0               0.0      NaN      NaN      NaN      NaN   \n",
      "4                 NaN               NaN      NaN      NaN      NaN      NaN   \n",
      "\n",
      "   HEREMPN  OTHEMPN  totemp  \n",
      "0      NaN      NaN     NaN  \n",
      "1      NaN      NaN     NaN  \n",
      "2      NaN      NaN     NaN  \n",
      "3      NaN      NaN     NaN  \n",
      "4      NaN      NaN     NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Bring in urbansim results\n",
    "all_prox = pd.DataFrame()\n",
    "taz_prox = pd.DataFrame()\n",
    "\n",
    "for us_runid in list_us_runid:\n",
    "    logger.info(\"\")\n",
    "    logger.info(\"==== Processing UrbanSim run {} ====\".format(us_runid))\n",
    "    urbansim_runid = os.path.join(urbansim_run_location, us_runid)\n",
    "\n",
    "    for model_year in (2015, 2050):\n",
    "        if model_year == 2050:\n",
    "            if us_runid == us_2050_FBP_Final:\n",
    "                parcel_file = urbansim_runid + \\\n",
    "                    '_parcel_data_{}_UBI.csv'.format(model_year)\n",
    "            else:\n",
    "                parcel_file = urbansim_runid + \\\n",
    "                    '_parcel_data_{}.csv'.format(model_year)\n",
    "        else:\n",
    "            parcel_file = urbansim_runid + \\\n",
    "                '_parcel_data_{}.csv'.format(model_year)\n",
    "        logger.info('Reading {} parcel data from {}'.format(\n",
    "            model_year, parcel_file))\n",
    "        parcel_output = pd.read_csv(parcel_file, engine='python')\n",
    "\n",
    "        logger.info('  Read {} rows'.format(len(parcel_output)))\n",
    "\n",
    "        # keep essential columns\n",
    "        parcel_output.drop(['geom_id', 'total_job_spaces', 'zoned_du',\n",
    "                            'zoned_du_underbuild', 'zoned_du_underbuild_nodev', 'first_building_type'], axis=1, inplace=True)\n",
    "        logger.info(\"Head:\\n{}\".format(parcel_output.head()))\n",
    "\n",
    "        parcel_output['totemp'] = parcel_output['totemp'].fillna(0)\n",
    "        parcel_output['totemp'] = parcel_output['totemp'].round(\n",
    "            0).astype('int')\n",
    "        parcel_output['RETEMPN'] = parcel_output['RETEMPN'].fillna(0)\n",
    "        parcel_output['RETEMPN'] = parcel_output['RETEMPN'].round(\n",
    "            0).astype('int')\n",
    "        parcel_output['MWTEMPN'] = parcel_output['MWTEMPN'].fillna(0)\n",
    "        parcel_output['MWTEMPN'] = parcel_output['MWTEMPN'].round(\n",
    "            0).astype('int')\n",
    "\n",
    "        # save as table in gdb\n",
    "#         parcel_table = os.path.join(arcpy.env.workspace, \"parcel_table\")\n",
    "#         if arcpy.Exists(parcel_table): arcpy.management.Delete(parcel_table)\n",
    "\n",
    "#         parcel_array = np.array(np.rec.fromrecords(parcel_output.values))\n",
    "#         parcel_array.dtype.names = tuple(parcel_output.dtypes.index.tolist())\n",
    "#         arcpy.da.NumPyArrayToTable(parcel_array, parcel_table)\n",
    "#         logger.info(\"Saved to {} in {}\".format(parcel_table, arcpy.env.workspace))\n",
    "\n",
    "        # convert to point feature class in GDB\n",
    "#         if arcpy.Exists('parcel_fc'): arcpy.management.Delete('parcel_fc')\n",
    "#         arcpy.management.XYTableToPoint(in_table=parcel_table, out_feature_class='parcel_fc',x_field='x',y_field='y')\n",
    "#         logger.info(\"Saved to {} in {}\".format('parcel_fc', arcpy.env.workspace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5302e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_year == 2015:\n",
    "        # current\n",
    "        transit_features = ['trn_cur_cat5']\n",
    "    elif model_year == 2050:\n",
    "        # no plan and blueprint\n",
    "        transit_features = ['trn_np_cat5', 'trn_fp_cat5']\n",
    "\n",
    "    for transit_feature in transit_features:\n",
    "\n",
    "        logger.info('Summarizing {} parcel data proximity to {}'.format(\n",
    "            model_year, transit_feature))\n",
    "        log_workspace_contents(logger)\n",
    "\n",
    "        try:\n",
    "            logger.info(\"feature classes no paths\")\n",
    "            arcpy.SummarizeWithin_analysis(transit_feature, 'parcel_fc', 'prox', keep_all_polygons=\"KEEP_ALL\",\n",
    "                                            sum_fields=[['tothh', 'SUM'], ['hhq1','SUM'],['totemp','SUM'],['RETEMPN','SUM'],['MWTEMPN','SUM']])\n",
    "            # hasn't worked, see comments below\n",
    "            logger.info(\"SUCCESS\")\n",
    "        except:\n",
    "            # Get the tool error messages\n",
    "            msgs = arcpy.GetMessages(2)\n",
    "            logger.error(\"Exception occured; msgs: {}\".format(msgs))\n",
    "\n",
    "            # Get the traceback object\n",
    "            tb = sys.exc_info()[2]\n",
    "            tbinfo = traceback.format_tb(tb)[0]\n",
    "\n",
    "            # Concatenate information together concerning the error into a message string\n",
    "            logger.error(\"Traceback info:\\n{}\\nError Info:\\n{}\".format(\n",
    "                tbinfo, str(sys.exc_info()[1])))\n",
    "            logger.error(\n",
    "                \"It's ok though -- we'll do this another way, but still trying the easy way\")\n",
    "\n",
    "        # Something related to arcpy.SummarizeWithin_analysis() is buggy\n",
    "        # The following attempts have failed with\n",
    "        # ERROR 000187: Only supports Geodatabase tables and feature classes\n",
    "        # * use the method with feature layers as inputs, with full paths and without\n",
    "        # * use the method with feature classes as inputs, with full paths and without\n",
    "        # * call the short script below via subprocess\n",
    "        # * copy feature classes to arcpy.env.scratchGDB and summarizeWithin there\n",
    "        #\n",
    "        # HOWEVER, after this script fails, running the following on the command line succeeds:\n",
    "        #\n",
    "        # >>> import arcpy\n",
    "        # >>> arcpy.env.workspace='M:\\Data\\GIS layers\\JobsHousingTransitProximity\\workspace_2020_1007_1737.gdb'\n",
    "        # >>> arcpy.SummarizeWithin_analysis('trn_cur_cat5', 'parcel_fc', 'prox', keep_all_polygons='KEEP_ALL', sum_fields=[['tothh','SUM'], ['hhq1','SUM'],['totemp','SUM'],['RETEMPN','SUM'],['MWTEMPN','SUM']])\n",
    "        # <Result 'M:\\\\Data\\\\GIS layers\\\\JobsHousingTransitProximity\\\\workspace_2020_1007_1737.gdb\\\\prox'>\n",
    "        # >>> prox_sdf = pd.DataFrame.spatial.from_featureclass('prox')\n",
    "        #\n",
    "        # so we'll summarize within ourselves and use spatial join instead\n",
    "        if arcpy.Exists('parcel_fc_join_trn'):\n",
    "            arcpy.management.Delete('parcel_fc_join_trn')\n",
    "        logger.info(\"spatial joining parcel_fc with {}\".format(transit_feature))\n",
    "        arcpy.SpatialJoin_analysis(target_features='parcel_fc', join_features=transit_feature,\n",
    "                                   out_feature_class='parcel_fc_join_trn')\n",
    "\n",
    "        logger.info(\"spatial joining parcel_fc_join_trn with {}\".format(taz))\n",
    "        arcpy.SpatialJoin_analysis(target_features='parcel_fc_join_trn', join_features=taz,\n",
    "                                   out_feature_class='parcel_fc_join_trn_taz')\n",
    "\n",
    "        logger.info(\n",
    "            \"spatial joining parcel_fc_join_trn_taz with {}\".format(tract))\n",
    "        arcpy.SpatialJoin_analysis(target_features='parcel_fc_join_trn_taz', join_features=tract,\n",
    "                                   out_feature_class='parcel_fc_join_trn_taz_tract')\n",
    "        logger.info(\"    ...complete\")\n",
    "\n",
    "        prox_sdf_ba = pd.DataFrame.spatial.from_featureclass(\n",
    "            'parcel_fc_join_trn_taz_tract')\n",
    "        prox_sdf = prox_sdf_ba.groupby('Service_Level').agg({'tothh': 'sum', 'hhq1':'sum', \n",
    "                                                         'totemp': 'sum', 'RETEMPN':'sum',\n",
    "                                                         'MWTEMPN': 'sum'}).reset_index()\n",
    "\n",
    "        prox_sdf['tothh_share'  ] = round(prox_sdf.tothh  / prox_sdf.tothh.sum(),  2)\n",
    "        prox_sdf['hhq1_share'   ] = round(prox_sdf.hhq1   / prox_sdf.hhq1.sum()  , 2)\n",
    "        prox_sdf['totemp_share' ] = round(prox_sdf.totemp / prox_sdf.totemp.sum(), 2)\n",
    "        prox_sdf['RETEMPN_share'] = round(prox_sdf.RETEMPN/prox_sdf.RETEMPN.sum(), 2)\n",
    "        prox_sdf['MWTEMPN_share'] = round(prox_sdf.MWTEMPN/prox_sdf.MWTEMPN.sum(), 2)\n",
    "        prox_sdf['year'] = str(model_year)\n",
    "        prox_sdf['modelrunID'] = us_runid\n",
    "        prox_sdf['transit'] = transit_feature\n",
    "        prox_sdf['area'] = 'Region'\n",
    "\n",
    "        logger.info(\"prox_sdf:\\n{}\".format(prox_sdf))\n",
    "        all_prox = all_prox.append(prox_sdf)\n",
    "\n",
    "        prox_sdf_epc = prox_sdf_ba[prox_sdf_ba.epc == 1]\n",
    "        prox_sdf_epc = prox_sdf_epc.groupby('Service_Level').agg({'tothh': 'sum', 'hhq1':'sum', \n",
    "                                                         'totemp': 'sum', 'RETEMPN':'sum',\n",
    "                                                         'MWTEMPN': 'sum'}).reset_index()\n",
    "\n",
    "        prox_sdf_epc['tothh_share'  ] = round(prox_sdf_epc.tothh  / prox_sdf_epc.tothh.sum(),  2)\n",
    "        prox_sdf_epc['hhq1_share'   ] = round(prox_sdf_epc.hhq1   / prox_sdf_epc.hhq1.sum()  , 2)\n",
    "        prox_sdf_epc['totemp_share' ] = round(prox_sdf_epc.totemp / prox_sdf_epc.totemp.sum(), 2)\n",
    "        prox_sdf_epc['RETEMPN_share'] = round(prox_sdf_epc.RETEMPN/prox_sdf_epc.RETEMPN.sum(), 2)\n",
    "        prox_sdf_epc['MWTEMPN_share'] = round(prox_sdf_epc.MWTEMPN/prox_sdf_epc.MWTEMPN.sum(), 2)\n",
    "        prox_sdf_epc['year'] = str(model_year)\n",
    "        prox_sdf_epc['modelrunID'] = us_runid\n",
    "        prox_sdf_epc['transit'] = transit_feature\n",
    "        prox_sdf_epc['area'] = 'epcs'\n",
    "\n",
    "        logger.info(\"prox_sdf_epc:\\n{}\".format(prox_sdf_epc))\n",
    "        all_prox = all_prox.append(prox_sdf_epc)\n",
    "\n",
    "        prox_sdf_hra = prox_sdf_ba[prox_sdf_ba.hra == 1]\n",
    "        prox_sdf_hra = prox_sdf_hra.groupby('Service_Level').agg({'tothh': 'sum', 'hhq1':'sum', \n",
    "                                                         'totemp': 'sum', 'RETEMPN':'sum',\n",
    "                                                         'MWTEMPN': 'sum'}).reset_index()\n",
    "\n",
    "        prox_sdf_hra['tothh_share'  ] = round(prox_sdf_hra.tothh  / prox_sdf_hra.tothh.sum(),  2)\n",
    "        prox_sdf_hra['hhq1_share'   ] = round(prox_sdf_hra.hhq1   / prox_sdf_hra.hhq1.sum()  , 2)\n",
    "        prox_sdf_hra['totemp_share' ] = round(prox_sdf_hra.totemp / prox_sdf_hra.totemp.sum(), 2)\n",
    "        prox_sdf_hra['RETEMPN_share'] = round(prox_sdf_hra.RETEMPN/prox_sdf_hra.RETEMPN.sum(), 2)\n",
    "        prox_sdf_hra['MWTEMPN_share'] = round(prox_sdf_hra.MWTEMPN/prox_sdf_hra.MWTEMPN.sum(), 2)\n",
    "        prox_sdf_hra['year'] = str(model_year)\n",
    "        prox_sdf_hra['modelrunID'] = us_runid\n",
    "        prox_sdf_hra['transit'] = transit_feature\n",
    "        prox_sdf_hra['area'] = 'HRAs'\n",
    "\n",
    "        logger.info(\"prox_sdf_hra:\\n{}\".format(prox_sdf_hra))\n",
    "        all_prox = all_prox.append(prox_sdf_hra)\n",
    "\n",
    "        logger.info(\"all_prox:\\n{}\".format(all_prox))\n",
    "\n",
    "        prox_sdf_taz = prox_sdf_ba.groupby(['area_type', 'Service_Level']).agg({'tothh':'sum', 'hhq1':'sum', \n",
    "                                                         'totemp': 'sum', 'RETEMPN':'sum',\n",
    "                                                         'MWTEMPN': 'sum'}).reset_index()\n",
    "\n",
    "        prox_sdf_taz['tothh_share'  ] = round(prox_sdf_taz.tothh  / prox_sdf_taz.tothh.sum(),  2)\n",
    "        prox_sdf_taz['hhq1_share'   ] = round(prox_sdf_taz.hhq1   / prox_sdf_taz.hhq1.sum()  , 2)\n",
    "        prox_sdf_taz['totemp_share' ] = round(prox_sdf_taz.totemp / prox_sdf_taz.totemp.sum(), 2)\n",
    "        prox_sdf_taz['RETEMPN_share'] = round(prox_sdf_taz.RETEMPN/prox_sdf_taz.RETEMPN.sum(), 2)\n",
    "        prox_sdf_taz['MWTEMPN_share'] = round(prox_sdf_taz.MWTEMPN/prox_sdf_taz.MWTEMPN.sum(), 2)\n",
    "        prox_sdf_taz['year'] = str(model_year)\n",
    "        prox_sdf_taz['modelrunID'] = us_runid\n",
    "        prox_sdf_taz['transit'] = transit_feature\n",
    "\n",
    "        logger.info(\"prox_sdf:\\n{}\".format(prox_sdf_taz))\n",
    "        taz_prox = taz_prox.append(prox_sdf_taz)\n",
    "\n",
    "        logger.info(\"taz_prox:\\n{}\".format(taz_prox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6201ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "d727ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# union_1.to_file('/Users/aolsen/Downloads/union_1.geojson', driver='GeoJSON')\n",
    "# union_2.to_file('/Users/aolsen/Downloads/union_2.geojson', driver='GeoJSON')\n",
    "# union_3.to_file('/Users/aolsen/Downloads/union_3.geojson', driver='GeoJSON')\n",
    "# union_4.to_file('/Users/aolsen/Downloads/union_4.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "60e55196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdwy15_buf.to_file(\n",
    "#     '/Users/aolsen/Downloads/hdwy15_buf.geojson', driver='GeoJSON')\n",
    "# hdwy30_buf.to_file(\n",
    "#     '/Users/aolsen/Downloads/hdwy30_buf.geojson', driver='GeoJSON')\n",
    "# hdwy30plus_buf.to_file(\n",
    "#     '/Users/aolsen/Downloads/hdwy30plus_buf.geojson', driver='GeoJSON')\n",
    "# major_buf.to_file(\n",
    "#     '/Users/aolsen/Downloads/major_buf.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "07dfcdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# diff_1 = gpd.overlay(hdwy15_buf,major_buf,how='difference')\n",
    "\n",
    "# diff_2 = gpd.overlay(hdwy30_buf,major_buf,how='difference')\n",
    "# diff_2b = gpd.overlay(diff_2,hdwy15_buf,how='difference')\n",
    "\n",
    "# diff_3 = gpd.overlay(hdwy30plus_buf,major_buf,how='difference')\n",
    "# diff_3b = gpd.overlay(diff_3,hdwy15_buf,how='difference')\n",
    "# diff_3c = gpd.overlay(diff_3b,hdwy30_buf,how='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578c7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check prefix+'_cat5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9cdcda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ea64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e77675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90d5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b877de",
   "metadata": {},
   "outputs": [],
   "source": [
    "    logger.info(\"==== create_transit_features({}) ====\".format(transit_type))\n",
    "    if transit_type == \"current\":\n",
    "        input_layer = \"transit_current\"\n",
    "        prefix = \"trn_cur\"\n",
    "    elif transit_type == \"noplan\":\n",
    "        input_layer = \"transit_potential\"\n",
    "        prefix = \"trn_np\"\n",
    "        curprefix = \"trn_cur\"\n",
    "    elif transit_type == \"blueprint\":\n",
    "        input_layer = \"transit_potential\"\n",
    "        prefix = \"trn_fp\"\n",
    "        curprefix = \"trn_cur\"\n",
    "    else:\n",
    "        logger.fatal(\"Unsupported transit_type {}\".format(transit_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b15792c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_type_config = {\n",
    "    \"current\": {\n",
    "        \"input_layer\": \"transit_current\",\n",
    "        \"prefix\": \"trn_cur\",\n",
    "    },\n",
    "    \"noplan\": {\n",
    "        \"input_layer\": \"transit_potential\",\n",
    "        \"prefix\": \"trn_np\",\n",
    "        \"curprefix\": \"trn_cur\",\n",
    "    },\n",
    "    \"blueprint\": {\n",
    "        \"input_layer\": \"transit_potential\",\n",
    "        \"prefix\": \"trn_fp\",\n",
    "        \"curprefix\": \"trn_cur\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a58e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transit_features_new(logger, transit_type):\n",
    "    \"\"\"\n",
    "    transit_type is one of [current, noplan, blueprint]\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    orig_result = arcpy.GetCount_management(input_layer)\n",
    "    logger.info(\"{} has {} rows\".format(input_layer, orig_result[0]))\n",
    "    \n",
    "    \n",
    "    if transit_type == \"current\":\n",
    "        logger.info('Select buffer for major transit stops => {}_majorbuf'.format(prefix))\n",
    "        major = arcpy.SelectLayerByAttribute_management(input_layer, \"NEW_SELECTION\", '\"major_stop\" = 1')\n",
    "        arcpy.CopyFeatures_management(major, prefix+\"_major\")  # save selection to new feature class\n",
    "        major_result = arcpy.GetCount_management(prefix+\"_major\")\n",
    "        logger.info(\"  {}_major has {} rows\".format(prefix, major_result[0]))\n",
    "        arcpy.Buffer_analysis(prefix+\"_major\", prefix+\"_majorbuf\", \"0.5 Miles\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "   \n",
    "    else:\n",
    "        if transit_type==\"noplan\":\n",
    "            logger.info('Selecting \"Under Construction\" or \"Open\" stops for no plan')\n",
    "            new_major = arcpy.management.SelectLayerByAttribute(input_layer, \"NEW_SELECTION\", \n",
    "                                                                '\"status\" = \\'Under Construction\\' Or status=\\'Open\\'')\n",
    "        elif transit_type==\"blueprint\":\n",
    "            logger.info('Selecting \"Under Construction\" or \"Open\" or \"Final Blueprint\" stops for no plan')\n",
    "            new_major = arcpy.management.SelectLayerByAttribute(input_layer, \"NEW_SELECTION\", \n",
    "                                                                '\"status\" = \\'Under Construction\\' Or status=\\'Open\\' Or status=\\'Final Blueprint\\'')\n",
    "\n",
    "        arcpy.CopyFeatures_management(new_major, prefix+\"_new_major\")  # save selection to new feature class\n",
    "        new_major_result = arcpy.GetCount_management(prefix+\"_new_major\")\n",
    "        logger.info(\"  {}_new_major has {} rows\".format(prefix, new_major_result[0]))\n",
    "        arcpy.Buffer_analysis(prefix+\"_new_major\", prefix+\"_newmajorbuf\", \"0.5 Miles\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "\n",
    "        # merge new major buffered with original major buffered\n",
    "        arcpy.Merge_management([curprefix+\"_majorbuf\",prefix+\"_newmajorbuf\"], prefix+\"_majorbuf_predissolve\")\n",
    "        # dissolve\n",
    "        arcpy.management.Dissolve(prefix+\"_majorbuf_predissolve\", prefix+\"_majorbuf\", \n",
    "                                  dissolve_field=None, statistics_fields=None, multi_part=\"MULTI_PART\", unsplit_lines=\"DISSOLVE_LINES\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transit_features(logger, transit_type):\n",
    "    \"\"\"\n",
    "    transit_type is one of [current, noplan, blueprint]\n",
    "    \"\"\"\n",
    "    logger.info(\"==== create_transit_features({}) ====\".format(transit_type))\n",
    "    if transit_type == \"current\":\n",
    "        input_layer = \"transit_current\"\n",
    "        prefix = \"trn_cur\"\n",
    "    elif transit_type == \"noplan\":\n",
    "        input_layer = \"transit_potential\"\n",
    "        prefix = \"trn_np\"\n",
    "        curprefix = \"trn_cur\"\n",
    "    elif transit_type == \"blueprint\":\n",
    "        input_layer = \"transit_potential\"\n",
    "        prefix = \"trn_fp\"\n",
    "        curprefix = \"trn_cur\"\n",
    "    else:\n",
    "        logger.fatal(\"Unsupported transit_type {}\".format(transit_type))\n",
    "\n",
    "    orig_result = arcpy.GetCount_management(input_layer)\n",
    "    logger.info(\"{} has {} rows\".format(input_layer, orig_result[0]))\n",
    "\n",
    "    # buffered transit_current major stops\n",
    "    if transit_type == \"current\":\n",
    "        logger.info(\n",
    "            'Select buffer for major transit stops => {}_majorbuf'.format(prefix))\n",
    "        major = arcpy.SelectLayerByAttribute_management(\n",
    "            input_layer, \"NEW_SELECTION\", '\"major_stop\" = 1')\n",
    "        # save selection to new feature class\n",
    "        arcpy.CopyFeatures_management(major, prefix+\"_major\")\n",
    "        major_result = arcpy.GetCount_management(prefix+\"_major\")\n",
    "        logger.info(\"  {}_major has {} rows\".format(prefix, major_result[0]))\n",
    "        arcpy.Buffer_analysis(prefix+\"_major\", prefix+\"_majorbuf\",\n",
    "                              \"0.5 Miles\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "\n",
    "    else:\n",
    "        if transit_type == \"noplan\":\n",
    "            logger.info(\n",
    "                'Selecting \"Under Construction\" or \"Open\" stops for no plan')\n",
    "            new_major = arcpy.management.SelectLayerByAttribute(input_layer, \"NEW_SELECTION\",\n",
    "                                                                '\"status\" = \\'Under Construction\\' Or status=\\'Open\\'')\n",
    "        elif transit_type == \"blueprint\":\n",
    "            logger.info(\n",
    "                'Selecting \"Under Construction\" or \"Open\" or \"Final Blueprint\" stops for no plan')\n",
    "            new_major = arcpy.management.SelectLayerByAttribute(input_layer, \"NEW_SELECTION\",\n",
    "                                                                '\"status\" = \\'Under Construction\\' Or status=\\'Open\\' Or status=\\'Final Blueprint\\'')\n",
    "\n",
    "        # save selection to new feature class\n",
    "        arcpy.CopyFeatures_management(new_major, prefix+\"_new_major\")\n",
    "        new_major_result = arcpy.GetCount_management(prefix+\"_new_major\")\n",
    "        logger.info(\"  {}_new_major has {} rows\".format(\n",
    "            prefix, new_major_result[0]))\n",
    "        arcpy.Buffer_analysis(prefix+\"_new_major\", prefix+\"_newmajorbuf\",\n",
    "                              \"0.5 Miles\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "\n",
    "        # merge new major buffered with original major buffered\n",
    "        arcpy.Merge_management(\n",
    "            [curprefix+\"_majorbuf\", prefix+\"_newmajorbuf\"], prefix+\"_majorbuf_predissolve\")\n",
    "        # dissolve\n",
    "        arcpy.management.Dissolve(prefix+\"_majorbuf_predissolve\", prefix+\"_majorbuf\",\n",
    "                                  dissolve_field=None, statistics_fields=None, multi_part=\"MULTI_PART\", unsplit_lines=\"DISSOLVE_LINES\")\n",
    "\n",
    "    # buffered hdway_15min stops\n",
    "    logger.info(\n",
    "        'Creating buffer for stops with headway < 15min => {}_hdwy15buf'.format(prefix))\n",
    "\n",
    "    if transit_type == \"current\":\n",
    "        hdwy15 = arcpy.SelectLayerByAttribute_management(\n",
    "            input_layer, \"NEW_SELECTION\", \"am_av_hdwy <= 15 And pm_av_hdwy <= 15\")\n",
    "        # save selection to new feature class\n",
    "        arcpy.CopyFeatures_management(hdwy15, prefix+\"_hdwy15\")\n",
    "        hdwy15_result = arcpy.GetCount_management(prefix+\"_hdwy15\")\n",
    "        logger.info(\"  {}_hdwy15 has {} rows\".format(prefix, hdwy15_result[0]))\n",
    "        arcpy.Buffer_analysis(prefix+\"_hdwy15\", prefix+\"_hdwy15buf\",\n",
    "                              \"0.25 Miles\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "\n",
    "    else:\n",
    "        # copy current\n",
    "        arcpy.CopyFeatures_management(\n",
    "            curprefix+\"_hdwy15buf\", prefix+\"_hdwy15buf\")\n",
    "\n",
    "    # buffered hdway_30min stops\n",
    "    logger.info(\n",
    "        'Creating buffer for stops with headway 15-30 min => {}_hdwy30buf'.format(prefix))\n",
    "\n",
    "    if transit_type == \"current\":\n",
    "        hdwy30 = arcpy.SelectLayerByAttribute_management(\n",
    "            input_layer, \"NEW_SELECTION\", \"am_av_hdwy > 15 And am_av_hdwy <= 30 And pm_av_hdwy > 15 And pm_av_hdwy <= 30\")\n",
    "        # save selection to new feature class\n",
    "        arcpy.CopyFeatures_management(hdwy30, prefix+\"_hdwy30\")\n",
    "        hdwy30_result = arcpy.GetCount_management(prefix+\"_hdwy30\")\n",
    "        logger.info(\"  {}_hdwy30 has {} rows\".format(prefix, hdwy30_result[0]))\n",
    "        arcpy.Buffer_analysis(prefix+\"_hdwy30\", prefix+\"_hdwy30buf\",\n",
    "                              \"0.25 Miles\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "\n",
    "    else:\n",
    "        # copy current\n",
    "        arcpy.CopyFeatures_management(\n",
    "            curprefix+\"_hdwy30buf\", prefix+\"_hdwy30buf\")\n",
    "\n",
    "    # buffered hdway_30plus stops\n",
    "    logger.info(\n",
    "        'Creating buffer for stops with headway 30+ min => {}_hdwy30plusbuf'.format(prefix))\n",
    "\n",
    "    if transit_type == \"current\":\n",
    "        hdwy30plus = arcpy.SelectLayerByAttribute_management(\n",
    "            input_layer, \"NEW_SELECTION\", \"am_av_hdwy > 30 Or pm_av_hdwy > 30\")\n",
    "        # save selection to new feature class\n",
    "        arcpy.CopyFeatures_management(hdwy30plus, prefix+\"_hdwy30plus\")\n",
    "        hdwy30plus_result = arcpy.GetCount_management(prefix+\"_hdwy30plus\")\n",
    "        logger.info(\"  {}_hdwy30plus has {} rows\".format(\n",
    "            prefix, hdwy30plus_result[0]))\n",
    "        arcpy.Buffer_analysis(prefix+\"_hdwy30plus\", prefix+\"_hdwy30plusbuf\",\n",
    "                              \"0.25 Miles\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "\n",
    "    else:\n",
    "        # copy current\n",
    "        arcpy.CopyFeatures_management(\n",
    "            curprefix+\"_hdwy30plusbuf\", prefix+\"_hdwy30plusbuf\")\n",
    "\n",
    "    # Make them disjoint -- first one wins\n",
    "    logger.info(\n",
    "        'Isolate {}_hdwy15buf => {}_hdwy15buf_only'.format(prefix, prefix))\n",
    "    arcpy.Erase_analysis(in_features=prefix+\"_hdwy15buf\", erase_features=prefix+\"_majorbuf\",\n",
    "                         out_feature_class=prefix+\"_hdwy15buf_only\")\n",
    "\n",
    "    logger.info(\n",
    "        'Isolate {}_hdwy30buf => {}_hdwy30buf_only'.format(prefix, prefix))\n",
    "    arcpy.Erase_analysis(prefix+\"_hdwy30buf\",   prefix +\n",
    "                         \"_majorbuf\",  prefix+\"_hdwy30buf_1\")\n",
    "    arcpy.Erase_analysis(prefix+\"_hdwy30buf_1\", prefix +\n",
    "                         \"_hdwy15buf\", prefix+\"_hdwy30buf_only\")\n",
    "    arcpy.Delete_management([prefix+\"_hdwy30buf_1\"])\n",
    "\n",
    "    logger.info(\n",
    "        'Isolate {}_hdwy30plusbuf  => {}_hdwy30plusbuf_only'.format(prefix, prefix))\n",
    "    arcpy.Erase_analysis(prefix+\"_hdwy30plusbuf\",   prefix +\n",
    "                         \"_majorbuf\",  prefix+\"_hdwy30plusbuf_1\")\n",
    "    arcpy.Erase_analysis(prefix+\"_hdwy30plusbuf_1\", prefix +\n",
    "                         \"_hdwy15buf\", prefix+\"_hdwy30plusbuf_2\")\n",
    "    arcpy.Erase_analysis(prefix+\"_hdwy30plusbuf_2\", prefix +\n",
    "                         \"_hdwy30buf\", prefix+\"_hdwy30plusbuf_only\")\n",
    "    arcpy.Delete_management([prefix+\"_hdwy30plusbuf_1\",\n",
    "                             prefix+\"_hdwy30plusbuf_2\"])\n",
    "\n",
    "    logger.info('Rest of Bay Area => {}_none'.format(prefix))\n",
    "    arcpy.Erase_analysis(\"BAcounty_expand\",   prefix +\n",
    "                         \"_majorbuf\",      \"BAcounty_expand_1\")\n",
    "    arcpy.Erase_analysis(\"BAcounty_expand_1\", prefix +\n",
    "                         \"_hdwy15buf\",     \"BAcounty_expand_2\")\n",
    "    arcpy.Erase_analysis(\"BAcounty_expand_2\", prefix +\n",
    "                         \"_hdwy30buf\",     \"BAcounty_expand_3\")\n",
    "    arcpy.Erase_analysis(\"BAcounty_expand_3\", prefix +\n",
    "                         \"_hdwy30plusbuf\", prefix+\"_none\")\n",
    "    arcpy.Delete_management([\"BAcounty_expand_1\",\n",
    "                             \"BAcounty_expand_2\",\n",
    "                             \"BAcounty_expand_3\"])\n",
    "\n",
    "    logger.info('Merge into one feature class => {}_cat5'.format(prefix))\n",
    "    arcpy.Merge_management([prefix+\"_none\",\n",
    "                            prefix+\"_hdwy30plusbuf_only\",\n",
    "                            prefix+\"_hdwy30buf_only\",\n",
    "                            prefix+\"_hdwy15buf_only\",\n",
    "                            prefix+\"_majorbuf\"],\n",
    "                           prefix+\"_cat5\", add_source=\"ADD_SOURCE_INFO\")\n",
    "    # create Service_Level from MERGE_SRC\n",
    "    arcpy.AddField_management(\n",
    "        prefix + \"_cat5\", \"Service_Level\", \"TEXT\", \"\", \"\", 200)\n",
    "    with arcpy.da.UpdateCursor(prefix + \"_cat5\", [\"Service_Level\", \"MERGE_SRC\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            if 'none' in row[1]:\n",
    "                row[0] = 'No_Fixed_Route_Transit'\n",
    "            elif 'hdwy30plusbuf' in row[1]:\n",
    "                row[0] = 'Bus_31plus_min'\n",
    "            elif 'hdwy30buf' in row[1]:\n",
    "                row[0] = 'Bus_15_30min'\n",
    "            elif 'hdwy15buf' in row[1]:\n",
    "                row[0] = 'Bus_<15min'\n",
    "            elif 'majorbuf' in row[1]:\n",
    "                row[0] = 'Major_Transit_Stop'\n",
    "            cursor.updateRow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6060432f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'else' statement on line 34 (3996946805.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 35\u001b[0;36m\u001b[0m\n\u001b[0;31m    if transit_type == \"noplan\":\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'else' statement on line 34\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point  # for creating point buffers\n",
    "\n",
    "\n",
    "def create_transit_features(logger, transit_type):\n",
    "    \"\"\"\n",
    "    transit_type is one of [current, noplan, blueprint]\n",
    "    \"\"\"\n",
    "    logger.info(\"==== create_transit_features({}) ====\".format(transit_type))\n",
    "\n",
    "    # Input data loading (adjust path and format)\n",
    "    # Replace with correct path and format\n",
    "    input_gdf = gpd.read_file(\"path/to/your/data.shp\")\n",
    "\n",
    "    if transit_type == \"current\":\n",
    "        prefix = \"trn_cur\"\n",
    "        curprefix = \"trn_cur\"\n",
    "    elif transit_type == \"noplan\":\n",
    "        prefix = \"trn_np\"\n",
    "        curprefix = \"trn_cur\"\n",
    "    elif transit_type == \"blueprint\":\n",
    "        prefix = \"trn_fp\"\n",
    "        curprefix = \"trn_cur\"\n",
    "    else:\n",
    "        logger.fatal(\"Unsupported transit_type {}\".format(transit_type))\n",
    "\n",
    "    # Calculate feature counts (use describe method)\n",
    "    feature_counts = input_gdf.describe()\n",
    "    logger.info(f\"{input_layer} has {feature_counts['geometry'].iloc[0]} rows\")\n",
    "\n",
    "    # Select features based on conditions (use query method)\n",
    "    if transit_type == \"current\":\n",
    "        major_gdf = input_gdf.query(\"major_stop == 1\")\n",
    "    else:\n",
    "        if transit_type == \"noplan\":\n",
    "            new_major_gdf = input_gdf.query(\n",
    "              \"(status == 'Under Construction') | (status == 'Open')\"\n",
    "          )\n",
    "    else:\n",
    "        new_major_gdf = input_gdf.query(\n",
    "          \"(status == 'Under Construction') | (status == 'Open') | (status == 'Final Blueprint')\"\n",
    "      )\n",
    "\n",
    "    # Buffer features (use buffer method)\n",
    "    majorbuf_gdf = major_gdf.buffer(distance=0.5, units=\"miles\")\n",
    "    if transit_type != \"current\":\n",
    "        hdwy15buf_gdf = gpd.read_file(\n",
    "            f\"{curprefix}_hdwy15buf.shp\")  # Assuming existing buffer\n",
    "        hdwy30buf_gdf = gpd.read_file(\n",
    "            f\"{curprefix}_hdwy30buf.shp\")  # Assuming existing buffer\n",
    "        hdwy30plusbuf_gdf = gpd.read_file(\n",
    "            f\"{curprefix}_hdwy30plusbuf.shp\")  # Assuming existing buffer\n",
    "\n",
    "    # ... (similar logic for hdwy15, hdwy30, hdwy30plus selections and buffering using query and buffer methods)\n",
    "\n",
    "    # Isolate buffers using difference (use difference method)\n",
    "    if transit_type == \"current\":\n",
    "        hdwy15buf_only_gdf = majorbuf_gdf.difference(hdwy30buf_gdf)\n",
    "        hdwy30buf_only_gdf = (\n",
    "            majorbuf_gdf.difference(\n",
    "                hdwy15buf_gdf).difference(hdwy30plusbuf_gdf)\n",
    "        )\n",
    "        hdwy30plusbuf_only_gdf = majorbuf_gdf.difference(\n",
    "            hdwy15buf_gdf).difference(hdwy30buf_gdf)\n",
    "    else:\n",
    "    # ... (similar logic for isolating buffers using difference for noplan and blueprint)\n",
    "        pass\n",
    "\n",
    "    # Isolate remaining area using difference (use difference method)\n",
    "    none_gdf = gpd.read_file(\"BAcounty_expand.shp\")  # Assuming existing data\n",
    "    none_gdf = none_gdf.difference(majorbuf_gdf)\n",
    "    if transit_type != \"current\":\n",
    "        none_gdf = none_gdf.difference(hdwy15buf_gdf)\n",
    "        none_gdf = none_gdf.difference(hdwy30buf_gdf)\n",
    "        none_gdf = none_gdf.difference(hdwy30plusbuf_gdf)\n",
    "\n",
    "    # Merge into one GeoDataFrame (use concat and GeoDataFrame constructor)\n",
    "    merged_gdf = gpd.GeoDataFrame(pd.concat([\n",
    "      none_gdf, hdwy30plusbuf_only_gdf, hdwy30buf_only_gdf,\n",
    "      hdwy15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e316c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
